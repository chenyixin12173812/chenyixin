



# 0 内存模型

5大区域



# 1.Lock，tryLock，lockInterruptibly区别

https://blog.csdn.net/u013851082/article/details/70140223



# 2.Condition

https://blog.csdn.net/qq_38293564/article/details/80554516#

![img](https://img-blog.csdn.net/20180603113842894?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MjkzNTY0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**1.等待**

Condition的await()方法如下：

```java
public final void await() throws InterruptedException {
    // 检测线程中断状态
    if (Thread.interrupted())
        throw new InterruptedException();
    // 将当前线程包装为Node节点加入等待队列
    Node node = addConditionWaiter();
    // 释放同步状态，也就是释放锁
    int savedState = fullyRelease(node);
    int interruptMode = 0;
    // 检测该节点是否在同步队中，如果不在，则说明该线程还不具备竞争锁的资格，则继续等待
    while (!isOnSyncQueue(node)) {
        // 挂起线程
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    // 竞争同步状态
    if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    // 清理条件队列中的不是在等待条件的节点
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}
```




调用该方法的线程是成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。

加入等待队列是通过addConditionWaiter()方法来完成的：

```java
private Node addConditionWaiter() {
    // 尾节点
    Node t = lastWaiter;
    // 尾节点如果不是CONDITION状态，则表示该节点不处于等待状态，需要清理节点
    if (t != null && t.waitStatus != Node.CONDITION) {
        unlinkCancelledWaiters();
        t = lastWaiter;
    }
    // 根据当前线程创建Node节点
    Node node = new Node(Thread.currentThread(), Node.CONDITION);
    // 将该节点加入等待队列的末尾
    if (t == null)
        firstWaiter = node;
    else
        t.nextWaiter = node;
    lastWaiter = node;
    return node;
}
```



![image-20200403013640942](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200403013640942.png)

将当前线程加入到等待队列之后，需要释放同步状态，该操作通过fullyRelease(Node)方法来完成：

```java
final int fullyRelease(Node node) {
    boolean failed = true;
    try {
        // 获取同步状态
        int savedState = getState();
        // 释放锁
        if (release(savedState)) {
            failed = false;
            return savedState;
        } else {
            throw new IllegalMonitorStateException();
        }
    } finally {
        if (failed)
            node.waitStatus = Node.CANCELLED;
    }
}
//线程释放锁之后，我们需要通过isOnSyncQueue(Node)方法不断自省地检查其对应节点是否在同步队列中：

final boolean isOnSyncQueue(Node node) {
    // 节点状态为CONDITION，或者前驱节点为null，返回false
    if (node.waitStatus == Node.CONDITION || node.prev == null)
        return false;
    // 后继节点不为null，那么肯定在同步队列中
    if (node.next != null) // If has successor, it must be on queue
        return true;
    

    return findNodeFromTail(node);

}
//若节点不在同步队列中，则挂起当前线程，若线程在同步队列中，且获取了同步状态，可能会调用unlinkCancelledWaiters()方法来清理等待队列中不为CONDITION 状态的节点：

private void unlinkCancelledWaiters() {
    Node t = firstWaiter;
    Node trail = null;
    while (t != null) {
        Node next = t.nextWaiter;
        if (t.waitStatus != Node.CONDITION) {
            t.nextWaiter = null;
            if (trail == null)
                firstWaiter = next;
            else
                trail.nextWaiter = next;
            if (next == null)
                lastWaiter = trail;
        }
        else
            trail = t;
        t = next;
    }
}
```

**2.通知**
调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。Condition的signal()方法如下所示：

```java
public final void signal() {
    // 判断是否是当前线程获取了锁
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    // 唤醒等待队列的首节点
    Node first = firstWaiter;
    if (first != null)
        doSignal(first);
}
//该方法最终调用doSignal(Node)方法来唤醒节点：

private void doSignal(Node first) {
    do {
        // 把等待队列的首节点移除之后，要修改首结点
        if ( (firstWaiter = first.nextWaiter) == null)
            lastWaiter = null;
        first.nextWaiter = null;
    } while (!transferForSignal(first) &&
                (first = firstWaiter) != null);
}
将节点移动到同步队列是通过transferForSignal(Node)方法完成的：

final boolean transferForSignal(Node node) {
    // 尝试将该节点的状态从CONDITION修改为0
    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
        return false;
    

    // 将节点加入到同步队列尾部，返回该节点的前驱节点
    Node p = enq(node);
    int ws = p.waitStatus;
    // 如果前驱节点的状态为CANCEL或者修改waitStatus失败，则直接唤醒当前线程
    if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
        LockSupport.unpark(node.thread);
    return true;

}

```



从等待队列移动到同步队列的过程如下图所示：

![image-20200403013901014](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200403013901014.png)

被唤醒后的线程，将从await()方法中的while循环中退出（因为此时isOnSyncQueue(Node)方法返回true），进而调用acquireQueued()方法加入到获取同步状态的竞争中。

成功获取了锁之后，被唤醒的线程将从先前调用的await()方法返回，此时，该线程已经成功获取了锁。

Condition的signalAll()方法，相当于对等待队列的每个节点均执行一次signal()方法，效果就是将等待队列中的所有节点移动到同步队列中。


# 3.Unsafe类



这个类是属于sun.* API中的类，并且它不是J2SE中真正的一部份，因此你可能找不到任何的官方文档，更可悲的是，它也没有比较好的代码文档。

1. Unsafe API的大部分方法都是native实现，它由105个方法组成，主要包括以下几类：

（1）Info相关。主要返回某些低级别的内存信息：addressSize(), pageSize()

（2）Objects相关。主要提供Object和它的域操纵方法：allocateInstance(),objectFieldOffset()

（3）Class相关。主要提供Class和它的静态域操纵方法：staticFieldOffset(),defineClass(),defineAnonymousClass(),ensureClassInitialized()

（4）Arrays相关。数组操纵方法：arrayBaseOffset(),arrayIndexScale()

（5）Synchronization相关。主要提供低级别同步原语（如基于CPU的CAS（Compare-And-Swap）原语）：monitorEnter(),tryMonitorEnter(),monitorExit(),compareAndSwapInt(),putOrderedInt()

（6）Memory相关。直接内存访问方法（绕过JVM堆直接操纵本地内存）：allocateMemory(),copyMemory(),freeMemory(),getAddress(),getInt(),putInt()

2. Unsafe类“有趣”的应用场景

（1）绕过类初始化方法。当你想要绕过对象构造方法、安全检查器或者没有public的构造方法时，allocateInstance()方法变得非常有用。

A o3 = (A) unsafe.allocateInstance(A.class); // unsafe
o3.a(); // prints 0
allocateInstance()根本没有进入构造方法，在单例模式时，我们似乎看到了危机。

（2）内存修改

内存修改在c语言中是比较常见的，在Java中，可以用它绕过安全检查器。

考虑以下简单准入检查规则：

class Guard {
 private int ACCESS_ALLOWED = 1;

 public boolean giveAccess() {
  return 42 == ACCESS_ALLOWED;
 }
}
在正常情况下，giveAccess总会返回false，但事情不总是这样

Guard guard = new Guard();
guard.giveAccess(); // false, no access

// bypass
Unsafe unsafe = getUnsafe();
Field f = guard.getClass().getDeclaredField("ACCESS_ALLOWED");
unsafe.putInt(guard, unsafe.objectFieldOffset(f), 42); // memory corruption

guard.giveAccess(); // true, access granted
通过计算内存偏移，并使用putInt()方法，类的ACCESS_ALLOWED被修改。在已知类结构的时候，数据的偏移总是可以计算出来（与c++中的类中数据的偏移计算是一致的）。

（3）实现类似C语言的sizeOf()函数

通过结合Java反射和objectFieldOffset()函数实现一个C-like sizeOf()函数。

public static long sizeOf(Object o) {
 Unsafe u = getUnsafe();
 HashSet fields = new HashSet();
 Class c = o.getClass();
 while (c != Object.class) {
  for (Field f : c.getDeclaredFields()) {
   if ((f.getModifiers() & Modifier.STATIC) == 0) {
    fields.add(f);
   }
  }
  c = c.getSuperclass();
 }

 // get offset
 long maxSize = 0;
 for (Field f : fields) {
  long offset = u.objectFieldOffset(f);
  if (offset > maxSize) {
   maxSize = offset;
  }
 }
 return ((maxSize/8) + 1) * 8; // padding
}
算法的思路非常清晰：从底层子类开始，依次取出它自己和它的所有超类的非静态域，放置到一个HashSet中（重复的只计算一次，Java是单继承），然后使用objectFieldOffset()获得一个最大偏移，最后还考虑了对齐。

在32位的JVM中，可以通过读取class文件偏移为12的long来获取size。

public static long sizeOf(Object object){
 return getUnsafe().getAddress(
  normalize(getUnsafe().getInt(object, 4L)) + 12L);
}
其中normalize()函数是一个将有符号int转为无符号long的方法

private static long normalize(int value) {
 if(value >= 0) return value;
 return (0L >>> 32) & value;
}
两个sizeOf()计算的类的尺寸是一致的。最标准的sizeOf()实现是使用java.lang.instrument，但是，它需要指定命令行参数-javaagent。

（4）实现Java浅复制

标准的浅复制方案是实现Cloneable接口或者自己实现的复制函数，它们都不是多用途的函数。通过结合sizeOf()方法，可以实现浅复制。

static Object shallowCopy(Object obj) {
 long size = sizeOf(obj);
 long start = toAddress(obj);
 long address = getUnsafe().allocateMemory(size);
 getUnsafe().copyMemory(start, address, size);
 return fromAddress(address);
}
以下的toAddress()和fromAddress()分别将对象转换到它的地址以及相反操作。

static long toAddress(Object obj) {
 Object[] array = new Object[] {obj};
 long baseOffset = getUnsafe().arrayBaseOffset(Object[].class);
 return normalize(getUnsafe().getInt(array, baseOffset));
}

static Object fromAddress(long address) {
 Object[] array = new Object[] {null};
 long baseOffset = getUnsafe().arrayBaseOffset(Object[].class);
 getUnsafe().putLong(array, baseOffset, address);
 return array[0];
}
以上的浅复制函数可以应用于任意java对象，它的尺寸是动态计算的。

（5）消去内存中的密码

密码字段存储在String中，但是，String的回收是受到JVM管理的。最安全的做法是，在密码字段使用完之后，将它的值覆盖。

Field stringValue = String.class.getDeclaredField("value");
stringValue.setAccessible(true);
char[] mem = (char[]) stringValue.get(password);
for (int i=0; i < mem.length; i++) {
 mem[i] = '?';
}
（6）动态加载类

标准的动态加载类的方法是Class.forName()(在编写jdbc程序时，记忆深刻)，使用Unsafe也可以动态加载java 的class文件。

byte[] classContents = getClassContent();
Class c = getUnsafe().defineClass(
    null, classContents, 0, classContents.length);
 c.getMethod("a").invoke(c.newInstance(), null); // 1
getClassContent()方法，将一个class文件，读取到一个byte数组。

private static byte[] getClassContent() throws Exception {
 File f = new File("/home/mishadoff/tmp/A.class");
 FileInputStream input = new FileInputStream(f);
 byte[] content = new byte[(int)f.length()];
 input.read(content);
 input.close();
 return content;
}
动态加载、代理、切片等功能中可以应用。

（7）包装受检异常为运行时异常。

getUnsafe().throwException(new IOException());
当你不希望捕获受检异常时，可以这样做（并不推荐）。

（8）快速序列化

标准的java Serializable速度很慢，它还限制类必须有public无参构造函数。Externalizable好些，它需要为要序列化的类指定模式。流行的高效序列化库，比如kryo依赖于第三方库，会增加内存的消耗。可以通过getInt(),getLong(),getObject()等方法获取类中的域的实际值，将类名称等信息一起持久化到文件。kryo有使用Unsafe的尝试，但是没有具体的性能提升的数据。（http://code.google.com/p/kryo/issues/detail?id=75）

（9）在非Java堆中分配内存

使用java 的new会在堆中为对象分配内存，并且对象的生命周期内，会被JVM GC管理。

class SuperArray {
 private final static int BYTE = 1;

 private long size;
 private long address;

 public SuperArray(long size) {
  this.size = size;
  address = getUnsafe().allocateMemory(size * BYTE);
 }

 public void set(long i, byte value) {
  getUnsafe().putByte(address + i * BYTE, value);
 }

 public int get(long idx) {
  return getUnsafe().getByte(address + idx * BYTE);
 }

 public long size() {
  return size;
 }
}
Unsafe分配的内存，不受Integer.MAX_VALUE的限制，并且分配在非堆内存，使用它时，需要非常谨慎：忘记手动回收时，会产生内存泄露；非法的地址访问时，会导致JVM崩溃。在需要分配大的连续区域、实时编程（不能容忍JVM延迟）时，可以使用它。java.nio使用这一技术。

（10）Java并发中的应用

通过使用Unsafe.compareAndSwap()可以用来实现高效的无锁数据结构。

class CASCounter implements Counter {
 private volatile long counter = 0;
 private Unsafe unsafe;
 private long offset;

 public CASCounter() throws Exception {
  unsafe = getUnsafe();
  offset = unsafe.objectFieldOffset(CASCounter.class.getDeclaredField("counter"));
 }

 @Override
 public void increment() {
  long before = counter;
  while (!unsafe.compareAndSwapLong(this, offset, before, before + 1)) {
   before = counter;
  }
 }

 @Override
 public long getCounter() {
  return counter;
 }
}

# 4.UNSAFE.putOrderedObject

putObjectbu 不保证顺序写入,putOrderedObject, putObjectVolatile

![image-20200316071150137](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200316071150137.png)



# 5..Fork/Join框架

从Java 1.7引入，将大任务拆分成小的子任务，合并。

![image-20200316223358021](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200316223358021.png)

# 6.工作窃取

![image-20200316224216820](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200316224216820.png)

# 7.线程的状态

1. new ：创建尚未启动的线程

2. 运行：包括了runing和ready状态

  3.无期限等待：需要其他线程唤醒。不会被分配时间片。无参数的object.await(),Thread.join()。LockSupport.part()方法。一个线程进入了锁，但是需要等待其他线程执行某些操作。时间不确定 当wait，join，park方法调用时，进入waiting状态。前提是这个线程已经拥有锁了

   4.期限等待：不会分配cpu执行时间，不需要其他线程显示唤醒。Thread.sleep()。设置了Timeout的object.await(),Thread.join()方法，LockSupport.parkNaos()、LockSupport.parkUntil()。一个线程进入了锁，但是需要等待其他线程执行某些操作。时间确定 通过sleep或wait timeout方法进入的限期等待的状态

  5.阻塞：争用排他锁synchornized。与等待的区别是等其他线程唤醒。

  6.结束。

![image-20200404182119906](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200404182119906.png)

# 8 thread类

1. 成员

**name**是表示Thread的名字，可以通过Thread类的构造器中的参数来指定线程名字，

**priority**表示线程的优先级（最大值为10，最小值为1，默认值为5），

**daemon**表示线程是否是守护线程

**target**表示要执行的任务。

2. 方法

   ### （1）start方法：start方法后，系统才会开启一个新的线程来执行用户定义的子任务，在这个过程中，会为相应的线程分配需要的资源

   ### （2）run方法：

   ### （3）sleep方法：进入阻塞状态，不会分cpu时间片，不会释放锁

   （4）**yield()方法**：和sleep()方法有点相似，使线程进入就绪状态，让出时间片，线程优先更高或等于。当前线程放弃CPU，但不会释放锁。**不同操作系统行为不一样，线程优先级也不确定**

   ###     (5) join方法：与 *wait（）\*和*notify（）方法一样*，*join（）*是另一种线程间同步机制。**如果引用的线程被中断，join()方法也可能返回**。在这种情况下，该方法抛出 *InterruptedException*

   public final void join(long millis,int nanos) throws InterruptedException
   最多等待 *millis* 毫秒加上 *nanos* 纳秒该线程死亡。

   除了等到终止之外，调用 *join（）*方法还具有同步效果。**join（）创建一个[before-before](https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4.5)关系：这意味着当线程t1调用t2.join（）时，t2完成的所有更改在返回时在t1中可见**

​    （6）interrupt方法：单独调用interrupt方法可以使得处于阻塞状态的线程抛出一个异常，也就说，它可以用来中断一个正处于阻塞状态的线程；另外，通过interrupt方法和isInterrupted()方法来停止正在运行的线程。不能中断没有阻塞的线程，除非主动使用通过调用isInterrupted()判断中断标志是否被置位来，是否主动结束进程。



- 本线程中断自身是被允许的，且"中断标记"设置为true
- 其它线程调用本线程的interrupt()方法时，会通过checkAccess()检查权限。这有可能抛出SecurityException异常。
  - 若线程在阻塞状态时，调用了它的interrupt()方法，那么它的“中断状态”会被清除并且会收到一个InterruptedException异常。
    - 例如，线程通过wait()进入阻塞状态，此时通过interrupt()中断该线程；调用interrupt()会立即将线程的中断标记设为“true”，但是由于线程处于阻塞状态，所以该“中断标记”会立即被清除为“false”，同时，会产生一个InterruptedException的异常。
  - 如果线程被阻塞在一个Selector选择器中，那么通过interrupt()中断它时；线程的中断标记会被设置为true，并且它会立即从选择操作中返回。
  - 如果不属于前面所说的情况，那么通过interrupt()中断线程时，它的中断标记会被设置为“true”。

   （7）interrupted方法:判断的是当前线程是否处于中断状态。是类的静态方法，同时会清除线程的中断状态。

​     (8) isInterrupted()方法,判断调用线程是否处于中断状态,不会清除中断状态。 

  （9）stop方法：stop方法已经是一个废弃的方法，它是一个不安全的方法。因为调用stop方法会直接终止run方法的调用，并且会抛出一个ThreadDeath错误，如果线程持有某个对象锁的话，会完全释放锁，导致对象状态不一致

​    (10) destroy方法也是废弃的方法。基本不会被使用到。

​    (11)suspend()和resume()
suspend()方法在线程挂起时，并不释放对象锁，因此可能会导致死锁。resume该方法很功能很简单，就是恢复 因suspend()方法挂起的线程，使之重新能够获得CPU执行

```
SecurityException  if the current thread is not allowed taccess this threa
```

（12）public static native boolean holdsLock(Object obj);

# 9 停止一个线程

1.不安全的做法  stop 、suspend

2。 （1） 使用共享变量的方式，（2）中断、（3）使用Feature取消。（4）正常运行结束退出

# 10 乐观锁和悲观锁

**（1）乐观锁：**乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。自旋锁。

**（2）悲观锁：**对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像synchronized，不管三七二十一，直接上了锁就操作资源了。

# 11 实现线程的方式

第一种：继承Thread
第二种：实现Runnable接口，这种方式使用较多，面向接口编程一直是被推崇的开发原则。
第三种：实现Callable接口用来实现返回结果的线程

# 12  怎么唤醒一个阻塞的线程？
1.如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞，可以中断线程，并且通过抛出InterruptedException来唤醒它；

2.如果线程遇到了IO阻塞，无能为力，因为IO是操作系统实现的，Java代码并没有办法直接接触到操作系统。

# 13  volatile关键字的作用

https://cloud.tencent.com/developer/article/1446555

https://cloud.tencent.com/developer/article/1142546

"**volatile关键字只能修饰类变量和实例变量。方法参数、局部变量、实例常量以及类常量都是不能用volatile关键字进行修饰的**"。

volatile 提供 happens-before 的保证，确保一个线程的修改能对其他线程是可见的。某些情况下，volatile 还能提供原子性，如读 64 位数据类型，像 long 和 double 都不是原子的(低32位和高32位)，但 volatile 类型的 double 和 long 就是原子的.

1.保证此变量对所有的线程的可见性，当一个线程修改了这个变量的值，volatile 保证了新值能立即同步到主内存，其它线程每次使用前立即从主内存刷新
但普通变量做不到这点，普通变量的值在线程间传递均需要通过主内存来完成
2.禁止指令重排序。有volatile修饰的变量，赋值后多执行了一个“load addl $0x0, (%esp)”操作，这个操作相当于一个内存屏障（指令重排序时不能把后面的指令重排序到内存屏障之前的位置）
这些操作的目的是用线程中的局部变量维护对该域的精确同步。通过对OpenJDK中的unsafe.cpp源码的分析，会发现被volatile关键字修饰的变量会存在一个“lock:”的前缀。

![img](http://5b0988e595225.cdn.sohucs.com/images/20190416/329eb6285b5c443abbe881afe3c0c4cd.jpeg)

这个实际上相当于是一个内存屏障，该内存屏障会为指令的执行提供如下保障：

确保指令重排序时不会将其后面的代码排到内存屏障之前。

同样也会确保重排序是不会将其前面的代码排到内存屏障之后。

确保在执行到内存屏障修饰的指令时前面的代码全部执行完成。

强制将线程的工作内存中值的修改刷新至主内存中。



**volatile写-读建立的happens before关系** ，volatile对线程的内存可见性的影响比volatile自身的特性更为重要，也更需要我们去关注。

![image-20200406210303818](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200406210303818.png)



volatile 的 happens-before 原则其实就是依赖的 StoreLoad 内存屏障



3.重排序

JMM为volatile定制的重排序规则

![img](https://upload-images.jianshu.io/upload_images/1822938-25ec20abc95ba6e1.png?imageMogr2/auto-orient/strip|imageView2/2/w/908/format/webp)



（1）当第一个操作是 volatile读时,不管第二个操作是什么,都不能重排序.确保volatile读之后的操作不会被重排序到 volatile读之前.

（2）当第二个操作是 volatile写时,不管第一个操作是什么,都不能重排序.确保volatile写之前的操作不会被重排序到volatile写之后.

（3）当第一个操作是 volatile写,第二个操作是 volatile读时,不能重排序.



#### volatile写内存屏障

![image-20200407012625717](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200407012625717.png)



`StoreStore屏障` 可以保证在volatile写之前，其前面的所有普通写操作已经对任
 意处理器可见了。

`StoreLoad屏障` 将 volatile写操作刷新到内存.

由此达到, volatile写 立马刷新到主内存的效果.

#### volatile读内存屏障

![image-20200407012441591](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200407012441591.png)

`LoadLoad屏障` 保障后续是读操作时, volatile读装载到内存数据.
 `LoadStore屏障` 保障后续是写操作时, volatile读装载到内存数据.





# 14 释放锁和不释放锁

1.释放锁：

（1）执行完同步代码块，就会释放锁。（synchronized）
（2）在执行同步代码块的过程中，遇到异常而导致线程终止，锁也会被释放。（exception）
（3）在执行同步代码块的过程中，执行了锁所属对象的wait()方法，这个线程会释放锁，进
    入对象的等待池。(wait)

 （4）Thread。stop

​    5）LOCK.lockInterruptibly可以使用interrupt

2.不会释放锁

（1）Thread.sleep()

  （2）Thread.yield()

 （3）Thread.suspend()

  # 15 **synchronized 的实现原理以及锁优化**



https://www.jianshu.com/p/e62fa839aa41

Java 虚拟机中的同步(Synchronization)基于进入和退出Monitor对象实现， 无论是显式同步(有明确的 monitorenter 和 monitorexit 指令,即同步代码块)还是隐式同步都是如此。在 Java 语言中，同步用的最多的地方可能是被 synchronized 修饰的同步方法。同步方法 并不是由 monitorenter 和 monitorexit 指令来实现同步的，而是由方法调用指令读取运行时常量池中方法表结构的 ACC_SYNCHRONIZED 标志来隐式实现的



# 16 指令重排序

# 17 happens-before  

在Java内存模型中，如果不存在happens-beforejvm可以随意排序。JSR-133S使用happens-before概念阐述了两个操作之间的内存可见性。在JMM中，如果一个操作的结果需要对另一个操作可见，那么这两个操作则存在happens-before关系。

那什么是happens-before呢？在JSR-133中，happens-before关系定义如下：

1. 如果一个操作happens-before另一个操作，那么意味着第一个操作的结果对第二个操作可见，而且第一个操作的执行顺序将排在第二个操作的前面。
2. 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须按照happens-before关系指定的顺序来执行。如果重排序之后的结果，与按照happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）

java天然满足happens-before规则的情况：

1. 程序顺序规则：一个线程中的每一个操作，happens-before于该线程中的任意后续操作。
2. 监视器规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
3. volatile规则：对一个volatile变量的写，happens-before于任意后续对一个volatile变量的读。
4. 传递性：若果A happens-before B，B happens-before C，那么A happens-before C。
5. 线程启动规则：Thread对象的start()方法，happens-before于这个线程的任意后续操作。
6. 线程终止规则：线程中的任意操作，happens-before于该线程的终止监测。我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值等手段检测到线程已经终止执行。
7. 线程中断操作：对线程interrupt()方法的调用，happens-before于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到线程是否有中断发生。
8. 对象终结规则：一个对象的初始化完成，happens-before于这个对象的finalize()方法的开始。

扩展：

任何并发集合的写操作与该集合的后续访问或者删除操作存在happens-before关系；
线程中提交Runnable到Executor之前的代码与Runnable中的代码存在happens-before关系。对提交Callable到ExecutorService也一样；
一个Future代表的异步计算和另一个线程中Future.get()的后续操作存在happens-before关系；
释放同步方法（比如Lock.unlock，Semaphore.release和 CountDownLatch.countDown）之前的代码和随后的在相同对象上的获得方法（比如Lock.lock, Semaphore.acquire, Condition.await和 CountDownLatch.await）存在happens-before关系；
通过Exchanger成功交换对象的线程对，exchange()之前的代码和exchange()之后的代码存在happens-before关系；
调用CyclicBarrier.await和Phaser.awaitAdvance之前的代码和执行barrier操作存在happens-before关系；执行barrier操作和其他线程中对应await返回后的代码存在happens-before关系。





# 18  CompletableFuture

https://mp.weixin.qq.com/s/d_TzKlyxD0RoWb8-UPimSQ



![微信图片_20200418064112](C:\Users\chen\Desktop\微信图片_20200418064112.jpg)

# 19 什么是多线程上下文切换

多线程的上下文切换是指CPU控制权由一个已经正在运行的线程切换到另外一个就绪并等待获取CPU执行权的线程的过程。CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态。



**1 引起线程上下文切换的原因？**

对于我们经常使用的抢占式操作系统而言，引起线程上下文切换的原因大概有以下几种：

1. 当前执行任务的时间片用完之后，系统CPU正常调度下一个任务
2. 当前执行任务碰到IO阻塞，调度器将此任务挂起，继续下一任务
3. 多个任务抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续下一任务
4. 用户代码挂起当前任务，让出CPU时间
5. 硬件中断

2.**上下文切换次数查看**

在Linux系统下可以使用vmstat命令来查看上下文切换的次数，下面是利用vmstat查看上下文切换次数的示例：

![img](https://images2015.cnblogs.com/blog/801753/201602/801753-20160211210110730-840766146.png)

CS（Context Switch）表示上下文切换的次数，从图中可以看到，上下文每秒钟切换500~600次左右。

如果要查看上下文切换的时长，可以利用Lmbench3，这是一个性能分析工具。

3 **如何减少上下文切换**

既然上下文切换会导致额外的开销，因此减少上下文切换次数便可以提高多线程程序的运行效率。减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。

- **无锁并发编程**。多线程竞争时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash取模分段，不同的线程处理不同段的数据
- **CAS算法**。Java的Atomic包使用CAS算法来更新数据，而不需要加锁
- **使用最少线程**。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态
- **协程**。在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换

# 20 Java当中有哪几种锁

- 自旋锁: 自旋锁在JDK1.6之后就默认开启了。基于之前的观察，共享数据的锁定状态只会持续很短的时间，为了这一小段时间而去挂起和恢复线程有点浪费，所以这里就做了一个处理，让后面请求锁的那个线程在稍等一会，但是不放弃处理器的执行时间，看看持有锁的线程能否快速释放。为了让线程等待，所以需要让线程执行一个忙循环也就是自旋操作。在jdk6之后，引入了自适应的自旋锁，也就是等待的时间不再固定了，而是由上一次在同一个锁上的自旋时间及锁的拥有者状态来决定
- 偏向锁: 在JDK1.之后引入的一项锁优化，目的是消除数据在无竞争情况下的同步原语。进一步提升程序的运行性能。 偏向锁就是偏心的偏，意思是这个锁会偏向第一个获得他的线程，如果接下来的执行过程中，改锁没有被其他线程获取，则持有偏向锁的线程将永远不需要再进行同步。偏向锁可以提高带有同步但无竞争的程序性能，也就是说他并不一定总是对程序运行有利，如果程序中大多数的锁都是被多个不同的线程访问，那偏向模式就是多余的，在具体问题具体分析的前提下，可以考虑是否使用偏向锁。
- 轻量级锁: 为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁

# 21 提交任务时，线程池队列已满



如果你使用的LinkedBlockingQueue，也就是×××队列的话，没关系，继续添加任务到阻塞队列中等待执行，因为LinkedBlockingQueue可以近乎认为是一个无穷大的队列，可以无限存放任务；如果你使用的是有界队列比方说ArrayBlockingQueue的话，任务首先会被添加到ArrayBlockingQueue中，ArrayBlockingQueue满了，则会使用拒绝策略RejectedExecutionHandler处理满了的任务，默认是AbortPolicy。

# 22 CyclicBarrier和CountDownLatch区别





# 23 atomic包

atomic包里面一共提供了13个类，分为4种类型，分别是：原子更新基本类型，原子更新数组，原子更新引用，原子更新属性，这13个类都是使用Unsafe实现的包装类。

- 标量类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference
- 数组类：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray
- 更新器类：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater
- 复合变量类：AtomicMarkableReference，AtomicStampedReference

**1.原子更新基本类型**

addAndGet(int delta) ：以原子方式将输入的数值与实例中原本的值相加，并返回最后的结果；

incrementAndGet() ：以原子的方式将实例中的原值进行加1操作，并返回最终相加后的结果；

getAndSet(int newValue)：将实例中的值更新为新值，并返回旧值；

getAndIncrement()：以原子的方式将实例中的原值加1，返回的是自增前的旧值；

**2.原子更新数组类型**

`int base = unsafe.arrayBaseOffset(int[].class);`
Unsafe类的**arraBaseOffset**方法：返回指定类型数组的第一个元素地址相对于数组起始地址的偏移值。

`int scale = unsafe.arrayIndexScale(int[].class);`
Unsafe类的**arrayIndexScale**方法：返回指定类型数组的元素所占用的字节数。比如int[]数组中的每个int元素占用4个字节，就返回4。

那么，通过`base + i * sacle` 其实就可以知道 索引**i**的元素在数组中的内存起始地址。
但是，观察**AtomicIntegerArray**的**byteOffset**方法，是通过`i << shift + base` 的公式计算元素的起始地址的：



地址的：![image-20200321165734027](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200321165734027.png)

这里，![image-20200321165800505](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200321165800505.png)

其实就等于**scale**。

`shift = 31 - Integer.numberOfLeadingZeros(scale)`，`Integer.numberOfLeadingZeros(scale)`是将**scale**转换为2进制，然后从左往右数连续0的个数。

读者可以自己计算下：
`shift = 31 - Integer.numberOfLeadingZeros(4) = 31 - 29 =2`

之所以要这么绕一圈，其实是处于性能的考虑，通过移位计算乘法的效率往往更高。

**3.AtomicReference AtomicStampedReference AtomicMarkableReference**

**4.LongAdder，LongAccumulator DoubleAdder和DoubleAccumulator**

https://segmentfault.com/a/1190000015865714?utm_source=tag-newest

**AtomicLong**是利用了底层的CAS操作来提供并发性的，比如**addAndGet**方法。在并发量较低的环境下，线程冲突的概率比较小，自旋的次数不会很多。但是，高并发环境下，N个线程同时进行自旋操作，会出现大量失败并不断自旋的情况，此时**AtomicLong**的自旋会成为瓶颈。

**AtomicLong**中有个内部变量**value**保存着实际的long值，所有的操作都是针对该变量进行。也就是说，高并发环境下，value变量其实是一个热点，也就是N个线程竞争一个热点。

**LongAdder**的基本思路就是***分散热点\***，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的long值，只要将各个槽中的变量值累加返回。

但是**AtomicLong**提供的功能其实更丰富，尤其是**addAndGet**、**decrementAndGet**、**compareAndSet**这些方法。

**addAndGet**、**decrementAndGet**除了单纯的做自增自减外，还可以立即获取增减后的值，而**LongAdder**则需要做同步控制才能精确获取增减后的值。如果业务需求需要精确的控制计数，做计数比较，**AtomicLong**也更合适。

![image-20200322020614565](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200322020614565.png)

比如有三个ThreadA、ThreadB、ThreadC，每个线程对value增加10。

![image-20200322020413204](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200322020413204.png)

对于**AtomicLong**，最终结果的计算始终是下面这个形式：

但是对于**LongAdder**来说，内部有一个`base`变量，一个`Cell[]`数组。
`base`变量：非竞态条件下，直接累加到该变量上
`Cell[]`数组：竞态条件下，累加个各个线程自己的槽`Cell[i]`中
最终结果的计算是下面这个形式：

![image-20200322020432694](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200322020432694.png)



# 24 locks包

![image-20200322023452517](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200322023452517.png)

# 25 Lock接口.

实现类主要有reentrantLock. WriteLock，WriteLockView

![image-20200322023934937](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200322023934937.png)

# 26 LockSupport

https://www.iteye.com/blog/agapple-970055



LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread)方法来唤醒一个被阻塞的线程，这些方法描述如下：

```java
// 返回提供给最近一次尚未解除阻塞的 park 方法调用的 blocker 对象，如果该调用不受阻塞，则返回 null。
static Object getBlocker(Thread t)
// 为了线程调度，禁用当前线程，除非许可可用。
static void park()
// 为了线程调度，在许可可用之前禁用当前线程。
static void park(Object blocker)
// 为了线程调度禁用当前线程，最多等待指定的等待时间，除非许可可用。
static void parkNanos(long nanos)
// 为了线程调度，在许可可用前禁用当前线程，并最多等待指定的等待时间。
static void parkNanos(Object blocker, long nanos)
// 为了线程调度，在指定的时限前禁用当前线程，除非许可可用。
static void parkUntil(long deadline)
// 为了线程调度，在指定的时限前禁用当前线程，除非许可可用。
static void parkUntil(Object blocker, long deadline)
// 如果给定线程的许可尚不可用，则使其可用。
static void unpark(Thread thread)
```

# 27 AbstractOwnableSynchronizer

该类为创建可能涉及所有权概念的锁和相关同步器提供了基础。`AbstractOwnableSynchronizer`类本身不管理或使用此信息。但是，子类和工具可以使用适当维护的值来帮助控制和监视访问并提供诊断。

```java
private transient Thread exclusiveOwnerThread;

protected final void setExclusiveOwnerThread(Thread thread) {
    exclusiveOwnerThread = thread;
}
protected final Thread getExclusiveOwnerThread() {
    return exclusiveOwnerThread;
}
```

# 28 AbstractQueuedLongSynchronizer

```
this class may be useful when creating synchronizers such as multilevel locks and barriers that require 64 bits of state.
```

# 29 AbstractQueuedSynchronizer

https://www.jianshu.com/p/cc308d82cc71

https://www.jianshu.com/p/279baac48960

AQS则实现了对**同步状态的管理，以及对阻塞线程进行排队，等待通知**等等一些底层的实现处理。AQS的核心也包括了这些方面:**同步队列，独占式锁的获取和释放，共享锁的获取和释放以及可中断锁，超时等待锁获取这些特性的实现**

**独占式锁：**

```java
void acquire(int arg)：独占式获取同步状态，如果获取失败则插入同步队列进行等待；
 void acquireInterruptibly(int arg)：与acquire方法相同，但在同步队列中进行等待的时候可以检测中断；
 boolean tryAcquireNanos(int arg, long nanosTimeout)：在acquireInterruptibly基础上增加了超时等待功能，在超时时间内没有获得同步状态返回false;
 boolean release(int arg)：释放同步状态，该方法会唤醒在同步队列中的下一个节点
```

共享式锁：

```java
void acquireShared(int arg)：共享式获取同步状态，与独占式的区别在于同一时刻有多个线程获取同步状态；
void acquireSharedInterruptibly(int arg)：在acquireShared方法基础上增加了能响应中断的功能；
boolean tryAcquireSharedNanos(int arg, long nanosTimeout)：在acquireSharedInterruptibly基础上增加了超时等待的功能；
boolean releaseShared(int arg)：共享式释放同步状态

```

在AQS有一个静态内部类Node，其中有这样一些属性：

> volatile int waitStatus //节点状态
>  volatile Node prev //当前节点/线程的前驱节点
>  volatile Node next; //当前节点/线程的后继节点
>  volatile Thread thread;//加入同步队列的线程引用
>  Node nextWaiter;//等待队列中的下一个节点

节点的状态有以下这些：

> int CANCELLED =  1//节点从同步队列中取消
>  int SIGNAL    = -1//后继节点的线程处于等待状态，如果当前节点释放同步状态会通知后继节点，使得后继节点的线程能够运行；
>  int CONDITION = -2//当前节点进入等待队列中
>  int PROPAGATE = -3//表示下一次共享式同步状态获取将会无条件传播下去
>  int INITIAL = 0;//初始状态



也就是说AQS实际上通过头尾指针来管理同步队列，同时实现包括获取锁失败的线程进行入队，释放锁时对同步队列中的线程进行通知等核心方法。其示意图如下

![img](https://upload-images.jianshu.io/upload_images/2615789-dbfc975d3601bb52.png?imageMogr2/auto-orient/strip|imageView2/2/w/625/format/webp)

通过对源码的理解以及做实验的方式，现在我们可以清楚的知道这样几点：

1. **节点的数据结构，即AQS的静态内部类Node,节点的等待状态等信息**；
2. **同步队列是一个双向队列，AQS通过持有头尾指针管理同步队列**；

那么，节点如何进行入队和出队是怎样做的了？实际上这对应着锁的获取和释放两个操作：获取锁失败进行入队操作，获取锁成功进行出队操作。

**独占锁**

## 3.1 独占锁的获取（acquire方法）

我们继续通过看源码和debug的方式来看，还是以上面的demo为例，调用lock()方法是获取独占式锁，获取失败就将当前线程加入同步队列，成功则线程执行。而lock()方法实际上会调用AQS的**acquire()**方法，源码如下



```java
public final void acquire(int arg) {
        //先看同步状态是否获取成功，如果成功则方法结束返回
        //若失败则先调用addWaiter()方法再调用acquireQueued()方法
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
}
```

关键信息请看注释，acquire根据当前获得同步状态成功与否做了两件事情：1. 成功，则方法结束返回，2. 失败，则先调用addWaiter()然后在调用acquireQueued()方法。

> **获取同步状态失败，入队操作**

当线程获取独占式锁失败后就会将当前线程加入同步队列，那么加入队列的方式是怎样的了？我们接下来就应该去研究一下addWaiter()和acquireQueued()。addWaiter()源码如下：



```csharp
private Node addWaiter(Node mode) {
        // 1. 将当前线程构建成Node类型
        Node node = new Node(Thread.currentThread(), mode);
        // Try the fast path of enq; backup to full enq on failure
        // 2. 尝试快速添加尾节点
        Node pred = tail;
        if (pred != null) {
            // 2.2 将当前节点尾插入的方式插入同步队列中
            node.prev = pred;
            if (compareAndSetTail(pred, node)) {
                pred.next = node;
                return node;
            }
        }
        // 2.1. 当前同步队列尾节点为null，说明当前线程是第一个加入同步队列进行等待的线程
        enq(node);
        return node;
}
```

分析可以看上面的注释。程序的逻辑主要分为两个部分：**1. 当前同步队列的尾节点为null，调用方法enq()插入;2. 当前队列的尾节点不为null，则采用尾插入（compareAndSetTail（）方法）的方式入队。**另外还会有另外一个问题：如果 `if (compareAndSetTail(pred, node))`为false怎么办？会继续执行到enq()方法，同时很明显compareAndSetTail是一个CAS操作，通常来说如果CAS操作失败会继续自旋（死循环）进行重试。因此，经过我们这样的分析，enq()方法可能承担两个任务：**1. 处理当前同步队列尾节点为null时进行入队操作；2. 如果CAS尾插入节点失败后负责自旋进行尝试。**那么是不是真的就像我们分析的一样了？只有源码会告诉我们答案:),enq()源码如下：



```java
private Node enq(final Node node) {
        for (;;) {
            Node t = tail;
            if (t == null) { // Must initialize
                //1. 构造头结点
                if (compareAndSetHead(new Node()))
                    tail = head;
            } else {
                // 2. 尾插入，CAS操作失败自旋尝试
                node.prev = t;
                if (compareAndSetTail(t, node)) {
                    t.next = node;
                    return t;
                }
            }
        }
}
```

在上面的分析中我们可以看出在第1步中会先创建头结点，说明同步队列是**带头结点的链式存储结构**。带头结点与不带头结点相比，会在入队和出队的操作中获得更大的便捷性，因此同步队列选择了带头结点的链式存储结构。那么带头节点的队列初始化时机是什么？自然而然是在**tail为null时，即当前线程是第一次插入同步队列**。compareAndSetTail(t, node)方法会利用CAS操作设置尾节点，如果CAS操作失败会在`for (;;)`for死循环中不断尝试，直至成功return返回为止。因此，对enq()方法可以做这样的总结：

1. **在当前线程是第一个加入同步队列时，调用compareAndSetHead(new Node())方法，完成链式队列的头结点的初始化**；
2. **自旋不断尝试CAS尾插入节点直至成功为止**。

现在我们已经很清楚获取独占式锁失败的线程包装成Node然后插入同步队列的过程了？那么紧接着会有下一个问题？在同步队列中的节点（线程）会做什么事情了来保证自己能够有机会获得独占式锁了？带着这样的问题我们就来看看acquireQueued()方法，从方法名就可以很清楚，这个方法的作用就是排队获取锁的过程，源码如下：



```java
final boolean acquireQueued(final Node node, int arg) {
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
                // 1. 获得当前节点的先驱节点
                final Node p = node.predecessor();
                // 2. 当前节点能否获取独占式锁                  
                // 2.1 如果当前节点的先驱节点是头结点并且成功获取同步状态，即可以获得独占式锁
                if (p == head && tryAcquire(arg)) {
                    //队列头指针用指向当前节点
                    setHead(node);
                    //释放前驱节点
                    p.next = null; // help GC
                    failed = false;
                    return interrupted;
                }
                // 2.2 获取锁失败，线程进入等待状态等待获取独占式锁
                if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
}
```

程序逻辑通过注释已经标出，整体来看这是一个这又是一个自旋的过程（for (;;)），代码首先获取当前节点的先驱节点，**如果先驱节点是头结点的并且成功获得同步状态的时候（if (p == head && tryAcquire(arg))），当前节点所指向的线程能够获取锁**。反之，获取锁失败进入等待状态。整体示意图为下图：

![img](https:////upload-images.jianshu.io/upload_images/2615789-3fe83cfaf03a02c8.png?imageMogr2/auto-orient/strip|imageView2/2/w/790/format/webp)

> ****

获取锁的节点出队的逻辑是：获取锁成功，前一个节点出队操作。**将当前节点通过setHead()方法设置为队列的头结点**，**也就是说release方法没有释放节点，而是在acquireQueued节点的setHead()方法。**然后将之前的头结点的next域设置为null并且pre域也为null，即与队列断开，无任何引用方便GC时能够将内存进行回收。示意图如下：



```kotlin
//队列头结点引用指向当前节点
setHead(node);
//释放前驱节点
p.next = null; // help GC
failed = false;
return interrupted;
```



![img](https:////upload-images.jianshu.io/upload_images/2615789-13963e1b3bcfe656.png?imageMogr2/auto-orient/strip|imageView2/2/w/877/format/webp)



那么当获取锁失败的时候会调用shouldParkAfterFailedAcquire()方法和parkAndCheckInterrupt()方法，看看他们做了什么事情。shouldParkAfterFailedAcquire()方法源码为：



```java
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL)
        /*
         * This node has already set status asking a release
         * to signal it, so it can safely park.
         */
        return true;
    if (ws > 0) {
        /*
         * Predecessor was cancelled. Skip over predecessors and
         * indicate retry.
         */
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus > 0);
        pred.next = node;
    } else {
        /*
         * waitStatus must be 0 or PROPAGATE.  Indicate that we
         * need a signal, but don't park yet.  Caller will need to
         * retry to make sure it cannot acquire before parking.
         */
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}
```

shouldParkAfterFailedAcquire()方法主要逻辑是使用`compareAndSetWaitStatus(pred, ws, Node.SIGNAL)`使用CAS将节点状态由INITIAL设置成SIGNAL，表示当前线程阻塞。当compareAndSetWaitStatus设置失败则说明shouldParkAfterFailedAcquire方法返回false，然后会在acquireQueued()方法中for (;;)死循环中会继续重试，直至compareAndSetWaitStatus设置节点状态位为SIGNAL时shouldParkAfterFailedAcquire返回true时才会执行方法parkAndCheckInterrupt()方法，该方法的源码为：



```java
private final boolean parkAndCheckInterrupt() {
        //使得该线程阻塞
        LockSupport.park(this);
        return Thread.interrupted();
}
```

该方法的关键是会调用LookSupport.park()方法（关于LookSupport会在以后的文章进行讨论），该方法是用来阻塞当前线程的。因此到这里就应该清楚了，acquireQueued()在自旋过程中主要完成了两件事情：

1. **如果当前节点的前驱节点是头节点，并且能够获得同步状态的话，当前线程能够获得锁该方法执行结束退出**；
2. **获取锁失败的话，先将节点状态设置成SIGNAL，然后调用LookSupport.park方法使得当前线程阻塞**。

经过上面的分析，独占式锁的获取过程也就是acquire()方法的执行流程如下图所示：

![img](https:////upload-images.jianshu.io/upload_images/2615789-a0d913dc40da5629.png?imageMogr2/auto-orient/strip|imageView2/2/w/856/format/webp)

独占式锁获取（acquire()方法）流程图.png

## 3.2 独占锁的释放（release()方法）

独占锁的释放就相对来说比较容易理解了，废话不多说先来看下源码：



```java
public final boolean release(int arg) {
        if (tryRelease(arg)) {
            Node h = head;
            if (h != null && h.waitStatus != 0)
                unparkSuccessor(h);
            return true;
        }
        return false;
}
```

这段代码逻辑就比较容易理解了，如果同步状态释放成功（tryRelease返回true）则会执行if块中的代码，当head指向的头结点不为null，并且该节点的状态值不为0的话才会执行unparkSuccessor()方法。unparkSuccessor方法源码：



```csharp
private void unparkSuccessor(Node node) {
    /*
     * If status is negative (i.e., possibly needing signal) try
     * to clear in anticipation of signalling.  It is OK if this
     * fails or if status is changed by waiting thread.
     */
    int ws = node.waitStatus;
    if (ws < 0)
        compareAndSetWaitStatus(node, ws, 0);

    /*
     * Thread to unpark is held in successor, which is normally
     * just the next node.  But if cancelled or apparently null,
     * traverse backwards from tail to find the actual
     * non-cancelled successor.
     */

    //头节点的后继节点
    Node s = node.next;
    if (s == null || s.waitStatus > 0) {
        s = null;
        for (Node t = tail; t != null && t != node; t = t.prev)
            if (t.waitStatus <= 0)
                s = t;
    }
    if (s != null)
        //后继节点不为null时唤醒该线程
        LockSupport.unpark(s.thread);
}
```

源码的关键信息请看注释，首先获取头节点的后继节点，当后继节点的时候会调用LookSupport.unpark()方法，该方法会唤醒该节点的后继节点所包装的线程。因此，**每一次锁释放后就会唤醒队列中该节点的后继节点所引用的线程，从而进一步可以佐证获得锁的过程是一个FIFO（先进先出）的过程。**

到现在我们终于啃下了一块硬骨头了，通过学习源码的方式非常深刻的学习到了独占式锁的获取和释放的过程以及同步队列。可以做一下总结：

1. **线程获取锁失败，线程被封装成Node进行入队操作，核心方法在于addWaiter()和enq()，同时enq()完成对同步队列的头结点初始化工作以及CAS操作失败的重试**;
2. **线程获取锁是一个自旋的过程，当且仅当 当前节点的前驱节点是头结点并且成功获得同步状态时，节点出队即该节点引用的线程获得锁，否则，当不满足条件时就会调用LookSupport.park()方法使得线程阻塞**；
3. **释放锁的时候会唤醒后继节点；**

总体来说：**在获取同步状态时，AQS维护一个同步队列，获取同步状态失败的线程会加入到队列中进行自旋；移除队列（或停止自旋）的条件是前驱节点是头结点并且成功获得了同步状态。在释放同步状态时，同步器会调用unparkSuccessor()方法唤醒后继节点。**

> **独占锁特性学习**

## 3.3 可中断式获取锁（acquireInterruptibly方法）

我们知道lock相较于synchronized有一些更方便的特性，比如能响应中断以及超时等待等特性，现在我们依旧采用通过学习源码的方式来看看能够响应中断是怎么实现的。可响应中断式锁可调用方法lock.lockInterruptibly();而该方法其底层会调用AQS的acquireInterruptibly方法，源码为：



```java
public final void acquireInterruptibly(int arg)
        throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    if (!tryAcquire(arg))
        //线程获取锁失败
        doAcquireInterruptibly(arg);
}
```

在获取同步状态失败后就会调用doAcquireInterruptibly方法：



```java
private void doAcquireInterruptibly(int arg)
    throws InterruptedException {
    //将节点插入到同步队列中
    final Node node = addWaiter(Node.EXCLUSIVE);
    boolean failed = true;
    try {
        for (;;) {
            final Node p = node.predecessor();
            //获取锁出队
            if (p == head && tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return;
            }
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                //线程中断抛异常
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

关键信息请看注释，现在看这段代码就很轻松了吧:),与acquire方法逻辑几乎一致，唯一的区别是当**parkAndCheckInterrupt**返回true时即线程阻塞时该线程被中断，代码抛出被中断异常。而不想中断异常的acquire方法，主动调用

```java
static void selfInterrupt() {
    Thread.currentThread().interrupt();
}
```

## 3.4 超时等待式获取锁（tryAcquireNanos()方法）

通过调用lock.tryLock(timeout,TimeUnit)方式达到超时等待获取锁的效果，该方法会在三种情况下才会返回：

1. 在超时时间内，当前线程成功获取了锁；
2. 当前线程在超时时间内被中断；
3. 超时时间结束，仍未获得锁返回false。

我们仍然通过采取阅读源码的方式来学习底层具体是怎么实现的，该方法会调用AQS的方法tryAcquireNanos(),源码为：



```java
public final boolean tryAcquireNanos(int arg, long nanosTimeout)
        throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    return tryAcquire(arg) ||
        //实现超时等待的效果
        doAcquireNanos(arg, nanosTimeout);
}
```

很显然这段源码最终是靠doAcquireNanos方法实现超时等待的效果，该方法源码如下：



```java
private boolean doAcquireNanos(int arg, long nanosTimeout)
        throws InterruptedException {
    if (nanosTimeout <= 0L)
        return false;
    //1. 根据超时时间和当前时间计算出截止时间
    final long deadline = System.nanoTime() + nanosTimeout;
    final Node node = addWaiter(Node.EXCLUSIVE);
    boolean failed = true;
    try {
        for (;;) {
            final Node p = node.predecessor();
            //2. 当前线程获得锁出队列
            if (p == head && tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return true;
            }
            // 3.1 重新计算超时时间
            nanosTimeout = deadline - System.nanoTime();
            // 3.2 已经超时返回false
            if (nanosTimeout <= 0L)
                return false;
            // 3.3 线程阻塞等待 
            if (shouldParkAfterFailedAcquire(p, node) &&
                nanosTimeout > spinForTimeoutThreshold)
                LockSupport.parkNanos(this, nanosTimeout);
            // 3.4 线程被中断抛出被中断异常
            if (Thread.interrupted())
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

程序逻辑如图所示：

![img](https:////upload-images.jianshu.io/upload_images/2615789-a80779d4736afb87.png?imageMogr2/auto-orient/strip|imageView2/2/w/704/format/webp)

超时等待式获取锁（doAcquireNanos()方法）

程序逻辑同独占锁可响应中断式获取基本一致，唯一的不同在于获取锁失败后，对超时时间的处理上，在第1步会先计算出按照现在时间和超时时间计算出理论上的截止时间，比如当前时间是8h10min,超时时间是10min，那么根据`deadline = System.nanoTime() + nanosTimeout`计算出刚好达到超时时间时的系统时间就是8h 10min+10min = 8h 20min。然后根据`deadline - System.nanoTime()`就可以判断是否已经超时了，比如，当前系统时间是8h 30min很明显已经超过了理论上的系统时间8h 20min，`deadline - System.nanoTime()`计算出来就是一个负数，自然而然会在3.2步中的If判断之间返回false。如果还没有超时即3.2步中的if判断为true时就会继续执行3.3步通过**LockSupport.parkNanos**使得当前线程阻塞，同时在3.4步增加了对中断的检测，若检测出被中断直接抛出被中断异常。

# 4. 共享锁

## 4.1 共享锁的获取（acquireShared()方法）

ReentrantReadWriteLock 里的sync

在聊完AQS对独占锁的实现后，我们继续一鼓作气的来看看共享锁是怎样实现的？共享锁的获取方法为acquireShared，源码为：



```java
public final void acquireShared(int arg) {
    if (tryAcquireShared(arg) < 0)
        doAcquireShared(arg);
}
```

这段源码的逻辑很容易理解，在该方法中会首先调用tryAcquireShared方法，tryAcquireShared返回值是一个int类型，当返回值为大于等于0的时候方法结束说明获得成功获取锁，否则，表明获取同步状态失败即所引用的线程获取锁失败，会执行doAcquireShared方法，该方法的源码为：



```java
private void doAcquireShared(int arg) {
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) {
                int r = tryAcquireShared(arg);
                if (r >= 0) {
                    // 当该节点的前驱节点是头结点且成功获取同步状态
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    if (interrupted)
                        selfInterrupt();
                    failed = false;
                    return;
                }
            }
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

现在来看这段代码会不会很容易了？逻辑几乎和独占式锁的获取一模一样，这里的自旋过程中能够退出的条件**是当前节点的前驱节点是头结点并且tryAcquireShared(arg)返回值大于等于0即能成功获得同步状态**。

## 4.2 共享锁的释放（releaseShared()方法）

共享锁的释放在AQS中会调用方法releaseShared：



```java
public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) {
        doReleaseShared();
        return true;
    }
    return false;
}
```

当成功释放同步状态之后即tryReleaseShared会继续执行doReleaseShared方法：



```csharp
private void doReleaseShared() {
    /*
     * Ensure that a release propagates, even if there are other
     * in-progress acquires/releases.  This proceeds in the usual
     * way of trying to unparkSuccessor of head if it needs
     * signal. But if it does not, status is set to PROPAGATE to
     * ensure that upon release, propagation continues.
     * Additionally, we must loop in case a new node is added
     * while we are doing this. Also, unlike other uses of
     * unparkSuccessor, we need to know if CAS to reset status
     * fails, if so rechecking.
     */
    for (;;) {
        Node h = head;
        if (h != null && h != tail) {
            int ws = h.waitStatus;
            if (ws == Node.SIGNAL) {
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;            // loop to recheck cases
                unparkSuccessor(h);
            }
            else if (ws == 0 &&
                     !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                continue;                // loop on failed CAS
        }
        if (h == head)                   // loop if head changed
            break;
    }
}
```

这段方法跟独占式锁释放过程有点点不同，**在共享式锁的释放过程中，对于能够支持多个线程同时访问的并发组件，必须保证多个线程能够安全的释放同步状态，这里采用的CAS保证，当CAS操作失败continue**，在下一次循环中进行重试。

## 4.3 可中断（acquireSharedInterruptibly()方法），超时等待（tryAcquireSharedNanos()方法）

关于可中断锁以及超时等待的特性其实现和独占式锁可中断获取锁以及超时等待的实现几乎一致，具体的就不再说了

# 30  ReentrantLock

https://blog.csdn.net/fuyuwei2015/article/details/83719444

```java
public ReentrantLock() {
    sync = new NonfairSync();
}

public ReentrantLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
}
```

**1.NonfairSync**

```java
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}

final boolean nonfairTryAcquire(int acquires) {
    //获取当前线程
    final Thread current = Thread.currentThread();
    //获取state变量值
    int c = getState();
    if (c == 0) { //没有线程占用锁
        if (compareAndSetState(0, acquires)) {
            //占用锁成功,设置独占线程为当前线程
            setExclusiveOwnerThread(current);
            return true;
        }
    } else if (current == getExclusiveOwnerThread()) { //当前线程已经占用该锁
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        // 更新state值为新的重入次数
        setState(nextc);
        return true;
    }
    //获取锁失败
    return false;
}
```



2.**FairSync**

```java
protected final boolean tryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        // 确保了公平性
        if (!hasQueuedPredecessors() &&
            compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0)
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

**3.锁释放**

```java

// 失败则表示没有改完全退出。不唤醒下一个节点的线程
protected final boolean tryRelease(int releases) {
    int c = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}
```



# 31 ReadWriteLock

https://www.jianshu.com/p/4a624281235e

首先明确一下，不是说ReentrantLock不好，只是ReentrantLock某些时候有局限。如果使用ReentrantLock，可能本身是为了防止线程A在写数据、线程B在读数据造成的数据不一致，但这样，如果线程C在读数据、线程D也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。因为这个，才诞生了读写锁ReadWriteLock。ReadWriteLock是一个读写锁接口，ReentrantReadWriteLock是ReadWriteLock接口的一个具体实现，实现了读写的分离， 读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。

1.Java并发库中ReetrantReadWriteLock实现了ReadWriteLock接口并添加了可重入的特性
 2.ReetrantReadWriteLock读写锁的效率明显高于synchronized关键字
 3.ReetrantReadWriteLock读写锁的实现中，读锁使用共享模式；写锁使用独占模式，换句话说，读锁可以在没有写锁的时候被多个线程同时持有，写锁是独占的
 4.ReetrantReadWriteLock读写锁的实现中，需要注意的，当有读锁时，写锁就不能获得；而当有写锁时，除了获得写锁的这个线程可以获得读锁外，其他线程不能获得读锁

```java
public interface ReadWriteLock {
    /**
     * Returns the lock used for reading.
     *
     * @return the lock used for reading
     */
    Lock readLock();

    /**
     * Returns the lock used for writing.
     *
     * @return the lock used for writing
     */
    Lock writeLock();
}
```

ReentrantReadWriteLock有两个构造方法，如下：读写锁公用一把锁

```JAVA
    public ReentrantReadWriteLock() {
        this(false);
    }

    public ReentrantReadWriteLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
        readerLock = new ReadLock(this);
        writerLock = new WriteLock(this);
    }

```

如何保证公平与非公共锁：writerShouldBlock和readerShoudBlock抽象方法

```java
//公平锁永远返回 是否有前节点
static final class FairSync extends Sync {
    private static final long serialVersionUID = -2274990926593161451L;
    final boolean writerShouldBlock() {
        return hasQueuedPredecessors();
    }
    final boolean readerShouldBlock() {
        return hasQueuedPredecessors();
    }
}
//非公平锁 写锁永远返回false，读锁涉及共享，通过检查aqs的clh队列的
    static final class NonfairSync extends Sync {
        private static final long serialVersionUID = -8159625535654395037L;
        final boolean writerShouldBlock() {
            return false; // writers can always barge
        }
        final boolean readerShouldBlock() {
            /* As a heuristic to avoid indefinite writer starvation,
             * block if the thread that momentarily appears to be head
             * of queue, if one exists, is a waiting writer.  This is
             * only a probabilistic effect since a new reader will not
             * block if there is a waiting writer behind other enabled
             * readers that have not yet drained from the queue.
             */
            return apparentlyFirstQueuedIsExclusive();
        }
    }
    final boolean apparentlyFirstQueuedIsExclusive() {
        Node h, s;
        return (h = head) != null &&
            (s = h.next)  != null &&
            !s.isShared()         &&
            s.thread != null;
    }
```



同步状态的高16位用来表示读锁被获取的次数**，低16位为写锁状态。

![img](https://upload-images.jianshu.io/upload_images/2615789-6af1818bbfa83051.png?imageMogr2/auto-orient/strip|imageView2/2/w/868/format/webp)

**1.写锁**

写锁为独占锁

```java
protected final boolean tryAcquire(int acquires) {
    /*
     * Walkthrough:
     * 1. If read count nonzero or write count nonzero
     *    and owner is a different thread, fail.
     * 2. If count would saturate, fail. (This can only
     *    happen if count is already nonzero.)
     * 3. Otherwise, this thread is eligible for lock if
     *    it is either a reentrant acquire or
     *    queue policy allows it. If so, update state
     *    and set owner.
     */
    Thread current = Thread.currentThread();
    // 1. 获取写锁当前的同步状态
    int c = getState();
    // 2. 获取写锁获取的次数
    int w = exclusiveCount(c);
    if (c != 0) {
        // (Note: if c != 0 and w == 0 then shared count != 0)
        // 3.1 w == 0 表面当读锁已被读线程获取
        // 当前线程不是已经获取写锁的线程的话
        // 当前线程获取写锁失败
        if (w == 0 || current != getExclusiveOwnerThread())
            return false;
        if (w + exclusiveCount(acquires) > MAX_COUNT)
            throw new Error("Maximum lock count exceeded");
        // Reentrant acquire
        // 3.2 当前线程重入获写锁 
        setState(c + acquires);
        return true;
    }
    // 3.3 写锁未被任何线程获取，当前线程可获取写锁
    if (writerShouldBlock() ||
        !compareAndSetState(c, c + acquires))
        return false;
    setExclusiveOwnerThread(current);
    return true;
}
```

```java
protected final boolean tryRelease(int releases) {
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    //1. 同步状态减去写状态
    int nextc = getState() - releases;
    //2. 当前写状态是否为0，为0则释放写锁
    boolean free = exclusiveCount(nextc) == 0;
    if (free)
        setExclusiveOwnerThread(null);
    //3. 不为0则更新同步状态
    setState(nextc);
    return free;
}
```

**2.读锁**

读锁为共享锁

```java
protected final int tryAcquireShared(int unused) {
    /*
     * Walkthrough:
     * 1. If write lock held by another thread, fail.
     * 2. Otherwise, this thread is eligible for
     *    lock wrt state, so ask if it should block
     *    because of queue policy. If not, try
     *    to grant by CASing state and updating count.
     *    Note that step does not check for reentrant
     *    acquires, which is postponed to full version
     *    to avoid having to check hold count in
     *    the more typical non-reentrant case.
     * 3. If step 2 fails either because thread
     *    apparently not eligible or CAS fails or count
     *    saturated, chain to version with full retry loop.
     */
    Thread current = Thread.currentThread();
    int c = getState();
    //1. 如果写锁已经被获取并且获取写锁的线程不是当前线程的话，当前
    // 线程获取读锁失败返回-1
    if (exclusiveCount(c) != 0 &&
        getExclusiveOwnerThread() != current)
        return -1;
    int r = sharedCount(c);
    if (!readerShouldBlock() &&
        r < MAX_COUNT &&
        //2. 当前线程获取读锁
        compareAndSetState(c, c + SHARED_UNIT)) {
        //3. 下面的代码主要是新增的一些功能，比如getReadHoldCount()方法
        //返回当前获取读锁的次数
        if (r == 0) {
            firstReader = current;
            firstReaderHoldCount = 1;
        } else if (firstReader == current) {
            firstReaderHoldCount++;
        } else {
            HoldCounter rh = cachedHoldCounter;
            if (rh == null || rh.tid != getThreadId(current))
                cachedHoldCounter = rh = readHolds.get();
            else if (rh.count == 0)
                readHolds.set(rh);
            rh.count++;
        }
        return 1;
    }
    //4. 处理在第二步中CAS操作失败的自旋已经实现重入性
    return fullTryAcquireShared(current);
}

protected final boolean tryReleaseShared(int unused) {
    Thread current = Thread.currentThread();
    // 前面还是为了实现getReadHoldCount等新功能
    if (firstReader == current) {
        // assert firstReaderHoldCount > 0;
        if (firstReaderHoldCount == 1)
            firstReader = null;
        else
            firstReaderHoldCount--;
    } else {
        HoldCounter rh = cachedHoldCounter;
        if (rh == null || rh.tid != getThreadId(current))
            rh = readHolds.get();
        int count = rh.count;
        if (count <= 1) {
            readHolds.remove();
            if (count <= 0)
                throw unmatchedUnlockException();
        }
        --rh.count;
    }
    for (;;) {
        int c = getState();
        // 读锁释放 将同步状态减去读状态即可
        int nextc = c - SHARED_UNIT;
        if (compareAndSetState(c, nextc))
            // Releasing the read lock has no effect on readers,
            // but it may allow waiting writers to proceed if
            // both read and write locks are now free.
            return nextc == 0;
    }
}

```

# 32 StampedLock

https://segmentfault.com/a/1190000015808032?utm_source=tag-newest

StampedLock类，在JDK1.8时引入，是对读写锁ReentrantReadWriteLock的增强，该类提供了一些功能，优化了读锁、写锁的访问，同时使读写锁之间可以互相转换，更细粒度控制并发。

首先明确下，该类的设计初衷是作为一个内部工具类，用于辅助开发其它线程安全组件，用得好，该类可以提升系统性能，用不好，容易产生死锁和其它莫名其妙的问题。

特点：

1. 所有获取锁的方法，都返回一个邮戳（Stamp），Stamp为0表示获取失败，其余都表示成功；
2. 所有释放锁的方法，都需要一个邮戳（Stamp），这个Stamp必须是和成功获取锁时得到的Stamp一致；
3. StampedLock是不可重入的；（如果一个线程已经持有了写锁，再去获取写锁的话就会造成死锁）
4. StampedLock有三种访问模式：
   ①Reading（读模式）：功能和ReentrantReadWriteLock的读锁类似
   ②Writing（写模式）：功能和ReentrantReadWriteLock的写锁类似
   ③Optimistic reading（乐观读模式）：这是一种优化的读模式。
5. StampedLock支持读锁和写锁的相互转换
   我们知道RRW中，当线程获取到写锁后，可以降级为读锁，但是读锁是不能直接升级为写锁的。
   StampedLock提供了读锁和写锁相互转换的功能，使得该类支持更多的应用场景。
6. 无论写锁还是读锁，都不支持Conditon等待

在Optimistic reading中，即使读线程获取到了读锁，写线程尝试获取写锁也不会阻塞，这相当于对读模式的优化，但是可能会导致数据不一致的问题。所以，当使用Optimistic reading获取到读锁时，必须对获取结果进行校验。

# 33 CountDownLatch

```java
private static final class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = 4982264981922014374L;

    Sync(int count) {
        setState(count);
    }

    int getCount() {
        return getState();
    }

    protected int tryAcquireShared(int acquires) {
        return (getState() == 0) ? 1 : -1;
    }

    protected boolean tryReleaseShared(int releases) {
        // Decrement count; signal when transition to zero
        for (;;) {
            int c = getState();
            //调用countDown次数大于，设定值，直接返回false
            if (c == 0)
                return false;
            int nextc = c-1;
            if (compareAndSetState(c, nextc))
                return nextc == 0;
        }
    }
    
    //主线程 多次调用，会怎样？tryAcquireShared返回1，直接返回，不会阻塞。
    //其他线程调用共享的CountDownLatch对象的await，不会阻塞，因为对象初始化时，设置当前线程状态为count，其他线程还是0，会直接返回。
    public void await() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }
    // 多次调用，会怎样？调用countDown次数大于，设定值，直接返回false
    public void countDown() {
        sync.releaseShared(1);
    }
    
```

# 34 CyclicBarrier

基于ReenTrantLock

```java
//Generation，该类的对象代表栅栏的当前代，就像玩游戏时代表的本局游戏，利用它可以实现循环等待。barrierCommand表示换代前执行的任务，当count减为0时表示本局游戏结束，需要转到下一局。在转到下一局游戏之前会将所有阻塞的线程唤醒，在唤醒所有线程之前你可以通过指定barrierCommand来执行自己的任务..

private static class Generation {
        boolean broken = false;
    }

//CyclicBarrier构造方法1
public CyclicBarrier(int parties, Runnable barrierAction) {
    if (parties <= 0) throw new IllegalArgumentException();
    // parties表示“必须同时到达barrier的线程个数”。
    this.parties = parties;
    // count表示“处在等待状态的线程个数”。
    this.count = parties;
    // barrierCommand表示“parties个线程到达barrier时，会执行的动作”。
    this.barrierCommand = barrierAction;
}
//CyclicBarrier构造方法2
public CyclicBarrier(int parties) {
        this(parties, null);
    }
//核心等待方法
private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException {
  final ReentrantLock lock = this.lock;
  lock.lock();
  try {
    final Generation g = generation;
    //检查当前栅栏是否被打翻
    if (g.broken) {
      throw new BrokenBarrierException();
    }
    //检查当前线程是否被中断
    if (Thread.interrupted()) {
      //如果当前线程被中断会做以下三件事
      //1.打翻当前栅栏
      //2.唤醒拦截的所有线程
      //3.抛出中断异常
      breakBarrier();
      throw new InterruptedException();
    }
    //每次都将计数器的值减1
    int index = --count;
    //计数器的值减为0则需唤醒所有线程并转换到下一代
    if (index == 0) {
      boolean ranAction = false;
      try {
        //唤醒所有线程前先执行指定的任务
        final Runnable command = barrierCommand;
        if (command != null) {
          command.run();
        }
        ranAction = true;
        //唤醒所有线程并转到下一代
        nextGeneration();
        return 0;
      } finally {
        //确保在任务未成功执行时能将所有线程唤醒
        if (!ranAction) {
          breakBarrier();
        }
      }
    }
 
    //如果计数器不为0则执行此循环
    for (;;) {
      try {
        //根据传入的参数来决定是定时等待还是非定时等待
        if (!timed) {
          trip.await();
        }else if (nanos > 0L) {
          nanos = trip.awaitNanos(nanos);
        }
      } catch (InterruptedException ie) {
        //若当前线程在等待期间被中断则打翻栅栏唤醒其他线程
        if (g == generation && ! g.broken) {
          breakBarrier();
          throw ie;
        } else {
          //若在捕获中断异常前已经完成在栅栏上的等待, 则直接调用中断操作
          Thread.currentThread().interrupt();
        }
      }
      //如果线程因为打翻栅栏操作而被唤醒则抛出异常
      if (g.broken) {
        throw new BrokenBarrierException();
      }
      //如果线程因为换代操作而被唤醒则返回计数器的值
      if (g != generation) {
        return index;
      }
      //如果线程因为时间到了而被唤醒则打翻栅栏并抛出异常
      if (timed && nanos <= 0L) {
        breakBarrier();
        throw new TimeoutException();
      }
    }
  } finally {
    lock.unlock();
  }
//切换栅栏到下一代
private void nextGeneration() {
  //唤醒条件队列所有线程
  trip.signalAll();
  //设置计数器的值为需要拦截的线程数
  count = parties;
  //重新设置栅栏代次
  generation = new Generation();
}
 
//打翻当前栅栏
private void breakBarrier() {
  //将当前栅栏状态设置为打翻
  generation.broken = true;
  //设置计数器的值为需要拦截的线程数
  count = parties;
  //唤醒所有线程
  trip.signalAll();
}
    
public void reset() {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        breakBarrier();   // break the current generation
        nextGeneration(); // start a new generation
    } finally {
        lock.unlock();
    }
}

```



# 35 Semaphore



```java
    public Semaphore(int permits) {
        sync = new NonfairSync(permits);
    }
    public Semaphore(int permits, boolean fair) {
        sync = fair ? new FairSync(permits) : new NonfairSync(permits);
    }
    /**
     * NonFair version
     */
    static final class NonfairSync extends Sync {
        private static final long serialVersionUID = -2694183684443567898L;

        NonfairSync(int permits) {
            super(permits);
        }

        protected int tryAcquireShared(int acquires) {
            return nonfairTryAcquireShared(acquires);
        }
    }

    /**
     * Fair version
     */
    static final class FairSync extends Sync {
        private static final long serialVersionUID = 2014338818796000944L;

        FairSync(int permits) {
            super(permits);
        }

        protected int tryAcquireShared(int acquires) {
            for (;;) {
                // CAS自旋 确保公平性
                if (hasQueuedPredecessors())
                    return -1;
                int available = getState();
                int remaining = available - acquires;
                if (remaining < 0 ||
                    compareAndSetState(available, remaining))
                    return remaining;
            }
        }
    }

//=========Sync类========

        final int nonfairTryAcquireShared(int acquires) {
            // CAS自旋 不直接返回失败呢？确保不公平性
            for (;;) {
                int available = getState();
                int remaining = available - acquires;
                if (remaining < 0 ||
                    compareAndSetState(available, remaining))
                    return remaining;
            }
        }
        // CAS自旋 没有重入  必须返回true，唤醒下一个节点线程。
        protected final boolean tryReleaseShared(int releases) {
            for (;;) {
                int current = getState();
                int next = current + releases;
                if (next < current) // overflow
                    throw new Error("Maximum permit count exceeded");
                if (compareAndSetState(current, next))
                    return true;
            }
        }


public int drainPermits() {
    return sync.drainPermits();
}


final int drainPermits() {
    for (;;) {
        int current = getState();
        if (current == 0 || compareAndSetState(current, 0))
            return current;
    }
}

```

# 36 Exchanger  

可用于两个线程之间交换信息。可简单地将Exchanger对象理解为一个包含两个格子的容器，通过exchanger方法可以向两个格子中填充信息。当两个格子中的均被填充时，该对象会自动将两个格子的信息交换，然后返回给线程，从而实现两个线程的信息交换，**Exchanger类仅可用作两个线程的信息交换，当超过两个线程调用同一个exchanger对象时，得到的结果是随机的**，**exchanger对象仅关心其包含的两个“格子”是否已被填充数据，当两个格子都填充数据完成时（调用exchange方法），该对象就认为线程之间已经配对成功，然后开始执行数据交换操作**



# 37 Phaser

https://www.jianshu.com/p/a9a713cba61a

  1）两个计数器：分别表示parties个数和当前phase。register和deregister会触发parties变更（CAS），全部parties到达（arrive）会触发phase变更。

  2）一个主要的阻塞队列：非AQS实现，对于arriveAndWait的线程，会被添加到队列中并被park阻塞，知道当前phase中最后一个party到达后触发唤醒。



# 40 线程池体系

![ThreadPoolExecutor](https://img2018.cnblogs.com/blog/1648938/201910/1648938-20191014235212898-1737390136.png)





![å¾2 ThreadPoolExecutorè¿è¡æµç¨](https://p0.meituan.net/travelcube/77441586f6b312a54264e3fcf5eebe2663494.png)



## Executor

线程池顶级接口，只定义了一个执行无返回值任务的方法。

```java
public interface Executor {
    // 执行无返回值任务【本篇文章由公众号“彤哥读源码”原创】
    void execute(Runnable command);
}
```

## ExecutorService

线程池次级接口，对Executor做了一些扩展，主要增加了关闭线程池、执行有返回值任务、批量执行任务的方法。

```java
public interface ExecutorService extends Executor {
    // 关闭线程池，不再接受新任务，但已经提交的任务会执行完成
    void shutdown();

    // 立即关闭线程池，尝试停止正在运行的任务，未执行的任务将不再执行
    // 被迫停止及未执行的任务将以列表的形式返回
    List<Runnable> shutdownNow();

    // 检查线程池是否已关闭
    boolean isShutdown();

    // 检查线程池是否已终止，只有在shutdown()或shutdownNow()之后调用才有可能为true
    boolean isTerminated();
    
    // 在指定时间内线程池达到终止状态了才会返回true
    boolean awaitTermination(long timeout, TimeUnit unit)
        throws InterruptedException;
    
    // 执行有返回值的任务，任务的返回值为task.call()的结果
    <T> Future<T> submit(Callable<T> task);

    // 执行有返回值的任务，任务的返回值为这里传入的result
    // 当然只有当任务执行完成了调用get()时才会返回
    <T> Future<T> submit(Runnable task, T result);
    
    // 执行有返回值的任务，任务的返回值为null
    // 当然只有当任务执行完成了调用get()时才会返回
    Future<?> submit(Runnable task);

    // 批量执行任务，只有当这些任务都完成了这个方法才会返回
    <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)
        throws InterruptedException;

    // 在指定时间内批量执行任务，未执行完成的任务将被取消
    // 这里的timeout是所有任务的总时间，不是单个任务的时间
    <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks,
                                  long timeout, TimeUnit unit)
        throws InterruptedException;
    
    // 返回任意一个已完成任务的执行结果，未执行完成的任务将被取消
    <T> T invokeAny(Collection<? extends Callable<T>> tasks)
        throws InterruptedException, ExecutionException;

    // 在指定时间内如果有任务已完成，则返回任意一个已完成任务的执行结果，未执行完成的任务将被取消
    <T> T invokeAny(Collection<? extends Callable<T>> tasks,
                    long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException;
}
```

## ScheduledExecutorService

对ExecutorService做了一些扩展，增加一些定时任务相关的功能，主要包含两大类：执行一次，重复多次执行。

```java
public interface ScheduledExecutorService extends ExecutorService {

    // 在指定延时后执行一次
    public ScheduledFuture<?> schedule(Runnable command,
                                       long delay, TimeUnit unit);
    // 在指定延时后执行一次
    public <V> ScheduledFuture<V> schedule(Callable<V> callable,
                                           long delay, TimeUnit unit);
                                           
    // 在指定延时后开始执行，并在之后以指定时间间隔重复执行（间隔不包含任务执行的时间）
    // 相当于之后的延时以任务开始计算【本篇文章由公众号“彤哥读源码”原创】
    public ScheduledFuture<?> scheduleAtFixedRate(Runnable command,
                                                  long initialDelay,
                                                  long period,
                                                  TimeUnit unit);

    // 在指定延时后开始执行，并在之后以指定延时重复执行（间隔包含任务执行的时间）
    // 相当于之后的延时以任务结束计算
    public ScheduledFuture<?> scheduleWithFixedDelay(Runnable command,
                                                     long initialDelay,
                                                     long delay,
                                                     TimeUnit unit);

}
```

## AbstractExecutorService

抽象类，运用模板方法设计模式实现了一部分方法，主要为执行有返回值任务、批量执行任务的方法。

```java
public abstract class AbstractExecutorService implements ExecutorService {

    protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {
        return new FutureTask<T>(runnable, value);
    }

    protected <T> RunnableFuture<T> newTaskFor(Callable<T> callable) {
        return new FutureTask<T>(callable);
    }

    public Future<?> submit(Runnable task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<Void> ftask = newTaskFor(task, null);
        execute(ftask);
        return ftask;
    }

    public <T> Future<T> submit(Runnable task, T result) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<T> ftask = newTaskFor(task, result);
        execute(ftask);
        return ftask;
    }

    public <T> Future<T> submit(Callable<T> task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<T> ftask = newTaskFor(task);
        execute(ftask);
        return ftask;
    }

    public <T> T invokeAny(Collection<? extends Callable<T>> tasks)
        throws InterruptedException, ExecutionException {
        // 略...
    }

    public <T> T invokeAny(Collection<? extends Callable<T>> tasks,
                           long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException {
        // 略...
    }

    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)
        throws InterruptedException {
        // 略...
    }

    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks,
                                         long timeout, TimeUnit unit)
        throws InterruptedException {
        // 略...
    }

}
```

可以看到，这里的submit()方法对传入的任务都包装成了FutureTask来进行处理，这是什么东西呢？欢迎关注后面的章节。

## ThreadPoolExecutor

普通线程池类，这也是我们通常所说的线程池，包含最基本的一些线程池操作相关的方法实现。

线程池的主要实现逻辑都在这里面，比如线程的创建、任务的处理、拒绝策略等，我们后面单独分析这个类。

## ScheduledThreadPoolExecutor

定时任务线程池类，用于实现定时任务相关功能，将任务包装成定时任务，并按照定时策略来执行，我们后面单独分析这个类。

*问题：你知道定时任务线程池类使用的是什么队列吗？*

答：延时队列。定时任务线程池中并没有直接使用并发集合中的DelayQueue，而是自己又实现了一个DelayedWorkQueue，不过跟DelayQueue的实现原理是一样的。

## Executors

线程池工具类，定义了一系列快速实现线程池的方法——newXXX()，不过阿里手册是不建议使用这个类来新建线程池的，彤哥我并不这么认为，只要能掌握其源码，知道其利敝偶尔还是可以用的，后面我们再来说这个事。



##  ExecutorCompletionService

ExecutorCompletionService用于有返回值，必须take，不然将造成内存泄漏



```java
    CompletionService<Integer> exec = new ExecutorCompletionService<>(
        ExecutorUtils.getMultiLiveCacheThreadPool());
    List<Future<Integer>> results = Lists.newArrayList();
    for (Map.Entry<String, GroupQueue> entry : queues.entrySet()) {
        try {
            entry.getValue().setAlertState(alertState);   
            results.add(exec.submit(new Sender(entry.getValue())));
        } catch (Exception e) {
            logger.error("send task error", e);
        }
    }
    int sendSuccessCount = 0;
 
//bug
    for (Future<Integer> fs : results) {
        try {
            //问题
            sendSuccessCount = sendSuccessCount + fs.get(20, TimeUnit.SECONDS);
        } catch (Exception e) {
            logger.error("get data error", e);
        }
 
    }

//前面保持一致
        for (Future<Integer> fs : results) {
            try {
                //用exec.take方法去队列
                sendSuccessCount = sendSuccessCount + exec.take().get(20, TimeUnit.SECONDS);
            } catch (Exception e) {
                logger.error("get data error", e);
            }
 
        }


```






# 41 自旋锁、排队自旋锁、MCS锁、CLH锁

https://blog.csdn.net/fei33423/article/details/30316377

# 42 ForkJoinPool

1.线程池默认数量Math.min(MAX_CAP, Runtime.getRuntime().availableProcessors()）。



```java
    public ForkJoinPool() {
        this(Math.min(MAX_CAP, Runtime.getRuntime().availableProcessors()),
             defaultForkJoinWorkerThreadFactory, null, false);
    }
```

2线程池数量

```java
    public ForkJoinPool(int parallelism,
                        ForkJoinWorkerThreadFactory factory,
                        UncaughtExceptionHandler handler,
                        boolean asyncMode) {
        this(checkParallelism(parallelism),
             checkFactory(factory),
             handler,
             asyncMode ? FIFO_QUEUE : LIFO_QUEUE,
             "ForkJoinPool-" + nextPoolId() + "-worker-");
        checkPermission();
    }
```



FIFO: First in, First out.先进先出。bai
LIFO: Last in, First out.后进先出。

demo

```java

public class ForkJoinPoolAction {
    public static void main(String[] args) throws Exception{
        PrintTask task = new PrintTask(0, 300);
        //创建实例，并执行分割任务
        ForkJoinPool pool = new ForkJoinPool();
        pool.submit(task);
         //线程阻塞，等待所有任务完成
        pool.awaitTermination(2, TimeUnit.SECONDS);
        pool.shutdown();
    }
}
 
/**
 * ClassName: PrintTask <br/>
 * Function: 继承RecursiveAction来实现“可分解”的任务。
 */
class PrintTask extends RecursiveAction{
    private static final int THRESHOLD = 50; //最多只能打印50个数
    private int start;
    private int end;
    
    public PrintTask(int start, int end) {
        super();
        this.start = start;
        this.end = end;
    }
 
    @Override
    protected void compute() {        
        if(end - start < THRESHOLD){
            for(int i=start;i<end;i++){
                System.out.println(Thread.currentThread().getName()+"的i值："+i);
            }
        }else {
            int middle =(start+end)/2;
            PrintTask left = new PrintTask(start, middle);
            PrintTask right = new PrintTask(middle, end);
            //并行执行两个“小任务”
            left.fork();
            right.fork();
        }        
    }    
}
```

submit采用了适配器

```java
   public <T> ForkJoinTask<T> submit(ForkJoinTask<T> task) {
        if (task == null)
            throw new NullPointerException();
        externalPush(task);
        return task;
    }

    /**
     * @throws NullPointerException if the task is null
     * @throws RejectedExecutionException if the task cannot be
     *         scheduled for execution
     */
    public <T> ForkJoinTask<T> submit(Callable<T> task) {
        ForkJoinTask<T> job = new ForkJoinTask.AdaptedCallable<T>(task);
        externalPush(job);
        return job;
    }

    /**
     * @throws NullPointerException if the task is null
     * @throws RejectedExecutionException if the task cannot be
     *         scheduled for execution
     */
    public <T> ForkJoinTask<T> submit(Runnable task, T result) {
        ForkJoinTask<T> job = new ForkJoinTask.AdaptedRunnable<T>(task, result);
        externalPush(job);
        return job;
    }
```











# 101并发良好的实践?

- 给线程命名
- 最小化同步范围
- 优先使用volatile
- 尽可能使用更高层次的并发工具而非wait和notify()来实现线程通信,如BlockingQueue,Semeaphore
- 优先使用并发容器而非同步容器.
- 考虑使用线程池
- 不使用Executors
- 不使用Timer
- ThreadLocal 清空



# 102如何合理配置线程池大小
首先，需要考虑到线程池所进行的工作的性质：IO密集型？CPU密集型？
简单的分析来看，如果是CPU密集型的任务，我们应该设置数目较小的线程数，比如CPU数目加1。如果是IO密集型的任务，则应该设置可能多的线程数，由于IO操作不占用CPU，所以，不能让CPU闲下来。当然，如果线程数目太多，那么线程切换所带来的开销又会对系统的响应时间带来影响。
在《linux多线程服务器端编程》中有一个思路，CPU计算和IO的阻抗匹配原则。如果线程池中的线程在执行任务时，密集计算所占的时间比重为P(0 下面验证一下边界条件的正确性：

假设C = 8，P = 1.0，线程池的任务完全是密集计算，那么T = 8。只要8个活动线程就能让8个CPU饱和，再多也没用了，因为CPU资源已经耗光了。
假设C = 8，P = 0.5，线程池的任务有一半是计算，有一半在等IO上，那么T = 16.考虑操作系统能灵活，合理调度sleeping/writing/running线程，那么大概16个“50%繁忙的线程”能让8个CPU忙个不停。启动更多的线程并不能提高吞吐量，反而因为增加上下文切换的开销而降低性能。


如果P < 0.2，这个公式就不适用了，T可以取一个固定值，比如 5*C。另外公式里的C不一定是CPU总数，可以是“分配给这项任务的CPU数目”，比如在8核机器上分出4个核来做一项任务，那么C=4
文章如何合理设置线程池大小里面提到了一个公式：
最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目


比如平均每个线程CPU运行时间为0.5s，而线程等待时间（非CPU运行时间，比如IO）为1.5s，CPU核心数为8，那么根据上面这个公式估算得到：((0.5+1.5)/0.5)*8=32。这个公式进一步转化为：

最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目
可以得出一个结论：
线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。
以上公式与之前的CPU和IO密集型任务设置线程数基本吻合。

![img](https://p0.meituan.net/travelcube/23a44974ff68a08261fb675242b83648181953.png)

# 103 线程池8大参数 ?

```java
    public ThreadPoolExecutor(int corePoolSize, //核心线程数
                              int maximumPoolSize,//最大线程数
                              long keepAliveTime, //线程空闲时间，如果线程池当前拥有超过corePoolSize的线程，那么多余的线程在空闲时间超过
                              TimeUnit unit,//单位
                              BlockingQueue<Runnable> workQueue,//阻塞队列 主要有3种类型的BlockingQueue可供选择：无界队列，有界队列和同步移交
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
```

## 拒绝策略

```java

private static final RejectedExecutionHandler defaultHandler =
        new AbortPolicy();
AbortPolicy //AbortPolicy
该策略是线程池的默认策略。使用该策略时，如果线程池队列满了丢掉这个任务,RejectedExecutionException异常。
CallerRunsPolicy//
DiscardOldestPolicy// 这个策略从字面上也很好理解，丢弃最老的。也就是说如果队列满了，会将最早进入队列的任务删掉腾出空间，再尝试加入队列
DiscardPolicy // DiscardPolicy的slient版本，如果线程池队列满了，会直接丢掉这个任务并且不会有任何异常
    
CallerRunsPolicy
使用此策略，如果添加到线程池失败，那么主线程会自己去执行该任务，不会等待线程池中的线程去执行。就像是个急脾气的人，我等不到别人来做这件事就干脆自己干。
源码如下：
public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            if (!e.isShutdown()) {
                //直接执行run方法
                r.run();
            }
        }

自定义
如果以上策略都不符合业务场景，那么可以自己定义一个拒绝策略，只要实现RejectedExecutionHandler接口，并且实现rejectedExecution方法就可以了。具体的逻辑就在rejectedExecution方法里去定义就OK了。
例如：我定义了我的一个拒绝策略，叫做MyRejectPolicy，里面的逻辑就是打印处理被拒绝的任务内容
public class MyRejectPolicy implements RejectedExecutionHandler{
    public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
        //Sender是我的Runnable类，里面有message字段
        if (r instanceof Sender) {
            Sender sender = (Sender) r;
            //直接打印
            System.out.println(sender.getMessage());
        }
    }
    
    
```



## 线程默认工厂:

## DefaultThreadFactory：设置线程优先级为5，生成线程名字setDaemon(false)。

## PrivilegedThreadFactory：这些新线程与当前线程具有相同的权限，用有当前线程的ClassLoader。

此工厂创建具有与 [`defaultThreadFactory()`](http://tool.oschina.net/uploads/apidocs/jdk-zh/java/util/concurrent/Executors.html#defaultThreadFactory())相同设置的线程，新线程的 AccessControlContext 和 contextClassLoader 的其他设置与调用此 privilegedThreadFactory 方法的线程相同。可以在 [`AccessController.doPrivileged(java.security.PrivilegedAction ) `](http://tool.oschina.net/uploads/apidocs/jdk-zh/java/security/AccessController.html#doPrivileged(java.security.PrivilegedAction))操作中创建一个新 privilegedThreadFactory，设置当前线程的访问控制上下文，以便创建具有该操作中保持的所选权限的线程。

**注意**，虽然运行在此类线程中的任务具有与当前线程相同的访问控制和类加载器，但是它们无需具有相同的 [`ThreadLocal`](http://tool.oschina.net/uploads/apidocs/jdk-zh/java/lang/ThreadLocal.html)或 [`InheritableThreadLocal`](http://tool.oschina.net/uploads/apidocs/jdk-zh/java/lang/InheritableThreadLocal.html) 值。如有必要，使用 [`ThreadPoolExecutor.beforeExecute(java.lang.Thread, java.lang.Runnable)`](http://tool.oschina.net/uploads/apidocs/jdk-zh/java/util/concurrent/ThreadPoolExecutor.html#beforeExecute(java.lang.Thread, java.lang.Runnable)) 在 [`ThreadPoolExecutor`](http://tool.oschina.net/uploads/apidocs/jdk-zh/java/util/concurrent/ThreadPoolExecutor.html) 子类中运行任何任务前，可以设置或重置线程局部变量的特定值。另外，如果必须初始化 worker 线程，以具有与某些其他指定线程相同的 InheritableThreadLocal 设置，则可以在线程等待和服务创建请求的环境中创建自定义的 ThreadFactory，而不是继承其值





```java
 static class DefaultThreadFactory implements ThreadFactory {
        private static final AtomicInteger poolNumber = new AtomicInteger(1);
        private final ThreadGroup group;
        private final AtomicInteger threadNumber = new AtomicInteger(1);
        private final String namePrefix;

        DefaultThreadFactory() {
            SecurityManager s = System.getSecurityManager();
            group = (s != null) ? s.getThreadGroup() :
            Thread.currentThread().getThreadGroup();
            namePrefix = "pool-" +
                poolNumber.getAndIncrement() +
                "-thread-";
        }

        public Thread newThread(Runnable r) {
            Thread t = new Thread(group, r,
                                  namePrefix + threadNumber.getAndIncrement(),
                                  0);
            if (t.isDaemon())
                t.setDaemon(false);
            if (t.getPriority() != Thread.NORM_PRIORITY)
                t.setPriority(Thread.NORM_PRIORITY);
            return t;
        }
    }

    /**
     * Thread factory capturing access control context and class loader
     */
    static class PrivilegedThreadFactory extends DefaultThreadFactory {
        private final AccessControlContext acc;
        private final ClassLoader ccl;

        PrivilegedThreadFactory() {
            super();
            SecurityManager sm = System.getSecurityManager();
            if (sm != null) {
                // Calls to getContextClassLoader from this class
                // never trigger a security check, but we check
                // whether our callers have this permission anyways.
                sm.checkPermission(SecurityConstants.GET_CLASSLOADER_PERMISSION);

                // Fail fast
                sm.checkPermission(new RuntimePermission("setContextClassLoader"));
            }
            this.acc = AccessController.getContext();
            this.ccl = Thread.currentThread().getContextClassLoader();
        }

        public Thread newThread(final Runnable r) {
            return super.newThread(new Runnable() {
                public void run() {
                    AccessController.doPrivileged(new PrivilegedAction<Void>() {
                        public Void run() {
                            Thread.currentThread().setContextClassLoader(ccl);
                            r.run();
                            return null;
                        }
                    }, acc);
                }
            });
        }
    }    
    
```

##  默认的线程名是如何命名的 ？

```java
class NameTheadFactory implements ThreadFactory{
   private static final AtomicInteger poolNumber = new AtomicInteger(1);
   private final ThreadGroup group;
   private final AtomicInteger threadNumber = new AtomicInteger(1);
   private final String namePrefix;
 
   NameTheadFactory() {
      //默认namePrefix = default-name-pool
      this("default-name-pool");
   }
 
   NameTheadFactory(String name){
      SecurityManager s = System.getSecurityManager();
      group = (s != null) ? s.getThreadGroup() :
            Thread.currentThread().getThreadGroup();
//此时namePrefix就是 name + 第几个用这个工厂创建线程池的
      this.namePrefix = name +
            poolNumber.getAndIncrement();
   }
 
   public Thread newThread(Runnable r) {
      //此时线程的名字 就是 namePrefix + -thread- + 这个线程池中第几个执行的线程
      Thread t = new Thread(group, r,
            namePrefix + "-thread-"+threadNumber.getAndIncrement(),
            0);
      if (t.isDaemon())
         t.setDaemon(false);
      if (t.getPriority() != Thread.NORM_PRIORITY)
         t.setPriority(Thread.NORM_PRIORITY);
      return t;
   }
}
```











**线程池按以下行为执行任务：**
（1）当线程数小于核心线程数时，创建线程。
（2）当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。
（3）当线程数大于等于核心线程数，且任务队列已满
     若线程数小于最大线程数，创建线程
     若线程数等于最大线程数，抛出异常，拒绝任务



# 104 使用ScheduledExecutorService代替Timer

1、管理并发任务的缺陷

timer有且仅有一个线程去执行定时任务，如果存在多个任务，且任务时间过长，会导致执行效果与预期不符。

2、当任务抛出异常时的缺陷

如果TimerTask抛出RuntimeException,Timer会停止所有任务的运行

3、不能满足对时效性要求较高的多任务并发作业，Timer背后只有一个线程串行的执行任务调度

4、不能满足对复杂任务的调度

5 Timer 是基于绝对时间的，对系统时间比较敏感，而 ScheduledThreadPoolExecutor 则是基于相对时间；

Timer 是内部是单一线程，而 ScheduledThreadPoolExecutor 内部是个线程池，所以可以支持多个任务并发执行。

6 。Timer 运行多个 TimeTask 时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用 ScheduledExecutorService 则没有这个问题。

使用 ScheduledExecutorService 更容易明确任务实际执行策略，更方便自行控制。

7。 默认 Timer 执行线程不是 daemon 线程, 任务执行完，主线程（或其他启动定时器的线程）结束时，task 线程并没有结束。需要注意潜在内存泄漏问题。

# 105 线程优先级

1-10，默认为5

# 106 Executors弊端

Executors返回的线程池对象的弊端如下：

​    1）FixedThreadPool 和 SingleThreadPool：

​      允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。

​    2）CachedThreadPool 和 ScheduledThreadPool :

​     允许创建的线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。

 # 107 ReentrantLock 保证可见性？

http://ifeve.com/java%E9%94%81%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%81%E6%80%A7%E7%9A%84/

# 108 CyclicBarrier与CountDownLatch的区别
至此我们难免会将CyclicBarrier与CountDownLatch进行一番比较。这两个类都可以实现一组线程在到达某个条件之前进行等待，它们内部都有一个计数器，当计数器的值不断的减为0的时候所有阻塞的线程将会被唤醒。

有区别的是CyclicBarrier的计数器由自己控制，而CountDownLatch的计数器则由使用者来控制，在CyclicBarrier中线程调用await方法不仅会将自己阻塞还会将计数器减1，而在CountDownLatch中线程调用await方法只是将自己阻塞而不会减少计数器的值。

另外，CountDownLatch只能拦截一轮，而CyclicBarrier可以实现循环拦截。一般来说用CyclicBarrier可以实现CountDownLatch的功能，而反之则不能，例如上面的赛马程序就只能使用CyclicBarrier来实现。总之，这两个类的异同点大致如此，至于何时使用CyclicBarrier，何时使用CountDownLatch，还需要读者自己去拿捏。

除此之外，CyclicBarrier还提供了：resert()、getNumberWaiting()、isBroken()等比较有用的方法。

# 109 Thread.sleep()和Object.wait()的区别

（1）Thread.sleep()不会释放占有的锁，Object.wait()会释放占有的锁；

（2）Thread.sleep()必须传入时间，Object.wait()可传可不传，不传表示一直阻塞下去；

（3）Thread.sleep()到时间了会自动唤醒，然后继续执行；

（4）Object.wait()不带时间的，需要另一个线程使用Object.notify()唤醒；

（5）Object.wait()带时间的，假如没有被notify，到时间了会自动唤醒，这时又分好两种情况，一是立即获取到了锁，线程自然会继续执行；二是没有立即获取锁，线程进入同步队列等待获取锁；

其实，他们俩最大的区别就是Thread.sleep()不会释放锁资源，Object.wait()会释放锁资源。

# 110 Thread.sleep()和Condition.await()的区别





这个题目的回答思路跟Object.wait()是基本一致的，不同的是Condition.await()底层是调用LockSupport.park()来实现阻塞当前线程的。

实际上，它在阻塞当前线程之前还干了两件事，一是把当前线程添加到条件队列中，二是“完全”释放锁，也就是让state状态变量变为0，然后才是调用LockSupport.park()阻塞当前线程，可以参考之前彤哥写的《死磕 java同步系列之ReentrantLock源码解析（二）——条件锁》这篇文章。

看到这里，今天开篇提的那个问题是不是就有答案了呢【本文由公从号“彤哥读源码”原创】？

# 111 Thread.sleep()和LockSupport.park()的区别



LockSupport.park()还有几个兄弟方法——parkNanos()、parkUtil()等，我们这里说的park()方法统称这一类方法。

（1）从功能上来说，Thread.sleep()和LockSupport.park()方法类似，都是阻塞当前线程的执行，且**都不会释放当前线程占有的锁资源**；

（2）Thread.sleep()没法从外部唤醒，只能自己醒过来；

（3）LockSupport.park()方法可以被另一个线程调用LockSupport.unpark()方法唤醒；

（4）Thread.sleep()方法声明上抛出了InterruptedException中断异常，所以调用者需要捕获这个异常或者再抛出；

（5）LockSupport.park()方法不需要捕获中断异常；

（6）Thread.sleep()本身就是一个native方法；

（7）LockSupport.park()底层是调用的Unsafe的native方法；

#  112 Object.wait()和LockSupport.park()的区别





二者都会阻塞当前线程的运行，他们有什么区别呢？经过上面的分析相信你一定很清楚了，真的吗？往下看！

（1）Object.wait()方法需要在synchronized块中执行；

（2）LockSupport.park()可以在任意地方执行；

（3）Object.wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出；

（4）LockSupport.park()不需要捕获中断异常【本文由公从号“彤哥读源码”原创】；

（5）Object.wait()不带超时的，需要另一个线程执行notify()来唤醒，但不一定继续执行后续内容；

（6）LockSupport.park()不带超时的，需要另一个线程执行unpark()来唤醒，一定会继续执行后续内容；

（7）**如果在wait()之前执行了notify()会怎样？抛出IllegalMonitorStateException异常**；

（8）**如果在park()之前执行了unpark()会怎样？线程不会被阻塞，直接跳过park()，继续执行后续内容；**





![image-20200405110038245](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\image-20200405110038245.png)

# 113 CAS同时具有Volatile读写的语义？

JAVA实现CAS的原理：

compareAndSwapInt是借助C来调用CPU底层指令实现的。下面从分析比较常用的CPU（intel x86）来解释CAS的实现原理。下面是sun.misc.Unsafe类的compareAndSwapInt()方法的源代码：

```c++
public final native boolean compareAndSwapInt(Object o, long offset,
                                               int expected, int x);
再看下在JDK中依次调用的C++代码为：

#define LOCK_IF_MP(mp) __asm cmp mp, 0  \
                       __asm je L0      \
                       __asm _emit 0xF0 \
                       __asm L0:

inline jint     Atomic::cmpxchg    (jint     exchange_value, volatile jint*     dest, jint     compare_value) {
  // alternative for InterlockedCompareExchange
  int mp = os::is_MP();
  __asm {
    mov edx, dest
    mov ecx, exchange_value
    mov eax, compare_value
    LOCK_IF_MP(mp)
    cmpxchg dword ptr [edx], ecx
  }
}
```


如上面源代码所示，程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略lock前缀（单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果）。

# 114 concurrent包的实现?



由于java的CAS同时具有 volatile 读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式：

1. A线程写volatile变量，随后B线程读这个volatile变量。
2. A线程写volatile变量，随后B线程用CAS更新这个volatile变量。
3. A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。
4. A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。

Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式：

1. 首先，声明共享变量为volatile；
2. 然后，使用CAS的原子条件更新来实现线程之间的同步；
3. 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信

# 115 final重排序规则

为何引入final重排序？为了是final域成为同步一种手段。final修饰的字段与不能幸免于对象溢出。

1. `在构造方法内对一个final字段的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。`
2. `初次读一个包含final字段对象的引用，与随后初次读这个final字段，这两个操作不能重排序。`

# 116 安全的发布对象

1. 使用volatile或原子引用
2. 静态初始化初始化一个对象引用
3. 正确构造的final域中
4. 将对象引用保存在一个锁保护的域中。

# 117 动态线程池



## 1 整体设计

动态化线程池的核心设计包括以下三个方面：

1. 简化线程池配置：线程池构造参数有8个，但是最核心的是3个：corePoolSize、maximumPoolSize，workQueue，它们最大程度地决定了线程池的任务分配和线程分配策略。考虑到在实际应用中我们获取并发性的场景主要是两种：（1）并行执行子任务，提高响应速度。这种情况下，应该使用同步队列，没有什么任务应该被缓存下来，而是应该立即执行。（2）并行执行大批次任务，提升吞吐量。这种情况下，应该使用有界队列，使用队列去缓冲大批量的任务，队列容量必须声明，防止任务无限制堆积。所以线程池只需要提供这三个关键参数的配置，并且提供两种队列的选择，就可以满足绝大多数的业务需求，Less is More。
2. 参数可动态修改：为了解决参数不好配，修改参数成本高等问题。在Java线程池留有高扩展性的基础上，封装线程池，允许线程池监听同步外部的消息，根据消息进行修改配置。将线程池的配置放置在平台侧，允许开发同学简单的查看、修改线程池配置。
3. 增加线程池监控：对某事物缺乏状态的观测，就对其改进无从下手。在线程池执行任务的生命周期添加监控能力，帮助开发同学了解线程池状态。

![图17 动态化线程池整体设计](https://p1.meituan.net/travelcube/4d5c410ad23782350cc9f980787151fd54144.png)

图17 动态化线程池整体设计



## 2 功能架构



动态化线程池提供如下功能：

**动态调参**：支持线程池参数动态调整、界面化操作；包括修改线程池核心大小、最大核心大小、队列长度等；参数修改后及时生效。 **任务监控**：支持应用粒度、线程池粒度、任务粒度的Transaction监控；可以看到线程池的任务执行情况、最大任务执行时间、平均任务执行时间、95/99线等。 **负载告警**：线程池队列任务积压到一定值的时候会通过大象（美团内部通讯工具）告知应用开发负责人；当线程池负载数达到一定阈值的时候会通过大象告知应用开发负责人。 **操作监控**：创建/修改和删除线程池都会通知到应用的开发负责人。 **操作日志**：可以查看线程池参数的修改记录，谁在什么时候修改了线程池参数、修改前的参数值是什么。 **权限校验**：只有应用开发负责人才能够修改应用的线程池参数。

![图18 动态化线程池功能架构](https://p0.meituan.net/travelcube/6c0091e92e90f50f89fd83f3b9eb5472135718.png)

图18 动态化线程池功能架构



**参数动态化**

JDK原生线程池ThreadPoolExecutor提供了如下几个public的setter方法，如下图所示：

![图19 JDK 线程池参数设置接口](https://p1.meituan.net/travelcube/efd32f1211e9cf0a3ca9d35b0dc5de8588353.png)

图19 JDK 线程池参数设置接口



JDK允许线程池使用方通过ThreadPoolExecutor的实例来动态设置线程池的核心策略，以**setCorePoolSize为方法例，在运行期线程池使用方调用此方法设置corePoolSize之后，线程池会直接覆盖原来的corePoolSize值，并且基于当前值和原始值的比较结果采取不同的处理策略。对于当前值小于当前工作线程数的情况，说明有多余的worker线程，此时会向当前idle的worker线程发起中断请求以实现回收**，多余的worker在下次idel的时候也会被回收；对于当前值大于原始值且当前队列中有待执行任务，则线程池会创建新的worker线程来执行队列任务，setCorePoolSize具体流程如下：

![图20 setCorePoolSize方法执行流程](https://p0.meituan.net/travelcube/9379fe1666818237f842138812bf63bd85645.png)

图20 setCorePoolSize方法执行流程



线程池内部会处理好当前状态做到平滑修改，其他几个方法限于篇幅，这里不一一介绍。重点是基于这几个public方法，我们只需要维护ThreadPoolExecutor的实例，并且在需要修改的时候拿到实例修改其参数即可。基于以上的思路，我们实现了线程池参数的动态化、线程池参数在管理平台可配置可修改，其效果图如下图所示：

![图21 可动态修改线程池参数](https://p0.meituan.net/travelcube/414ba7f3abd11e5f805c58635ae10988166121.png)

图21 可动态修改线程池参数



用户可以在管理平台上通过线程池的名字找到指定的线程池，然后对其参数进行修改，保存后会实时生效。目前支持的动态参数包括核心数、最大值、队列长度等。除此之外，在界面中，我们还能看到用户可以配置是否开启告警、队列等待任务告警阈值、活跃度告警等等。关于监控和告警，我们下面一节会对齐进行介绍。

**线程池监控**

除了参数动态化之外，为了更好地使用线程池，我们需要对线程池的运行状况有感知，比如当前线程池的负载是怎么样的？分配的资源够不够用？任务的执行情况是怎么样的？是长任务还是短任务？基于对这些问题的思考，动态化线程池提供了多个维度的监控和告警能力，包括：线程池活跃度、任务的执行Transaction（频率、耗时）、Reject异常、线程池内部统计信息等等，既能帮助用户从多个维度分析线程池的使用情况，又能在出现问题第一时间通知到用户，从而避免故障或加速故障恢复。

#### 1. 负载监控和告警

线程池负载关注的核心问题是：基于当前线程池参数分配的资源够不够。对于这个问题，我们可以从事前和事中两个角度来看。事前，线程池定义了“活跃度”这个概念，来让用户在发生Reject异常之前能够感知线程池负载问题，线程池活跃度计算公式为：线程池活跃度 = activeCount/maximumPoolSize。这个公式代表当活跃线程数趋向于maximumPoolSize的时候，代表线程负载趋高。事中，也可以从两方面来看线程池的过载判定条件，一个是发生了Reject异常，一个是队列中有等待任务（支持定制阈值）。以上两种情况发生了都会触发告警，告警信息会通过大象推送给服务所关联的负责人。

![图22 大象告警通知](https://p0.meituan.net/travelcube/04e73f7186a91d99181e1b5615ce9e4a318600.png)

图22 大象告警通知



#### 2. 任务级精细化监控

在传统的线程池应用场景中，线程池中的任务执行情况对于用户来说是透明的。比如在一个具体的业务场景中，业务开发申请了一个线程池同时用于执行两种任务，一个是发消息任务、一个是发短信任务，这两类任务实际执行的频率和时长对于用户来说没有一个直观的感受，很可能这两类任务不适合共享一个线程池，但是由于用户无法感知，因此也无从优化。动态化线程池内部实现了任务级别的埋点，且允许为不同的业务任务指定具有业务含义的名称，线程池内部基于这个名称做Transaction打点，基于这个功能，用户可以看到线程池内部任务级别的执行情况，且区分业务，任务监控示意图如下图所示：

![图23 线程池任务执行监控](https://p1.meituan.net/travelcube/cd0b9445c3c93a866201b7cfb24d2ce7214776.png)

图23 线程池任务执行监控



#### 3. 运行时状态实时查看

用户基于JDK原生线程池ThreadPoolExecutor提供的几个public的getter方法，可以读取到当前线程池的运行状态以及参数，如下图所示：

![图24 线程池实时运行情况](https://p0.meituan.net/travelcube/aba8d9c09e6f054c7061ddd720a04a26147951.png)

图24 线程池实时运行情况



动态化线程池基于这几个接口封装了运行时状态实时查看的功能，用户基于这个功能可以了解线程池的实时状态，比如当前有多少个工作线程，执行了多少个任务，队列中等待的任务数等等。效果如下图所示：

![图25 线程池实时运行情况](https://p1.meituan.net/travelcube/38d5fbeaebd4998f3a30d44bd20b996f113233.png)



# 118 ThreadLocal泄漏？

每个Thread线程内部都有一个Map。
 Map里面存储线程本地对象（key）和线程的变量副本（value）
 但是，Thread内部的Map是由ThreadLocal维护的，由ThreadLocal负责向map获取和设置线程的变量值。
 所以对于不同的线程，每次获取副本值时，别的线程并不能获取到当前线程的副本值，形成了副本的隔离，互不干扰。

 Entry继承自WeakReference（弱引用，生命周期只能存活到下次GC前），但只有Key是弱引用类型的，Value并非弱引用。（问题马上就来了） 

缺陷:可能会引起内存泄漏;ThreadLocalMap中key维护着一个weakReference,它在下次GC之前会被清理,如果Value仍然保持着外部的强引用,该ThreadLocal没有再进行set,get或者remove操作,时间长了就可能导致OutOfMemoryError 

**如何避免泄漏:**

1、使用完线程共享变量后，显示调用ThreadLocalMap.remove方法清除线程共享变量；
 既然Key是弱引用，那么我们要做的事，就是在调用ThreadLocal的get()、set()方法时完成后再调用remove方法，将Entry节点和Map的引用关系移除，这样整个Entry对象在GC Roots分析后就变成不可达了，下次GC的时候就可以被回收。

2、JDK建议ThreadLocal定义为private static，这样ThreadLocal的弱引用问题则不存在了。

# 119如果是线程池里的线程用ThreadLocal会有什么问题？

# 120   sleep、wait、yield、join区别

1.sleep 方法是属于 Thread 类中的，sleep 过程中线程不会释放锁，只会阻塞线程，让出cpu给其他线程，但是他的监控状态依然保持着，当指定的时间到了又会自动恢复运行状态，可中断，sleep 给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机

2 wait 方法是属于 Object 类中的，wait 过程中线程会释放对象锁，只有当其他线程调用 notify 才能唤醒此线程。wait 使用时必须先获取对象锁，即必须在 synchronized 修饰的代码块中使用，那么相应的 notify 方法同样必须在 synchronized 修饰的代码块中使用，如果没有在synchronized 修饰的代码块中使用时运行时会抛出IllegalMonitorStateException的异常

3 yield暂停当前正在执行的线程对象，不会释放资源锁，和 sleep 不同的是 **yield方法并不会让线程进入阻塞状态，而是让线程重回就绪状态，它只需要等待重新获取CPU执行时间**，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。还有一点和 sleep 不同的是 yield 方法只能使同优先级或更高优先级的线程有执行的机会

4.join  等待调用join方法的线程结束之后，程序再继续执行，一般用于***\*等待异步线程执行完结果之后才能继续运行的场景\****。例如：主线程创建并启动了子线程，如果子线程中药进行大量耗时运算计算某个数据值，而主线程要取得这个数据值才能运行，这时就要用到 join 方法了 



# 121  [Java对象的内存分配过程是如何保证线程安全的？](https://www.cnblogs.com/wyf0518/p/11461944.html) 

一般有两种解决方案：

- 1、对分配内存空间的动作做同步处理，采用CAS机制，配合失败重试的方式保证更新操作的线程安全性。
- 2、每个线程在Java堆中预先分配一小块内存，然后再给对象分配内存的时候，直接在自己这块"私有"内存中分配，当这部分区域用完之后，再分配新的"私有"内存。

方案1在每次分配时都需要进行同步控制，这种是比较低效的。

方案2是**HotSpot虚拟机中采用的，这种方案被称之为TLAB分配**，即Thread Local Allocation Buffer。这部分Buffer是从堆中划分出来的，但是是本地线程独享的。

这里值得注意的是，我们说TLAB时线程独享的，但是只是在“分配”这个动作上是线程独占的，至于在读取、垃圾回收等动作上都是线程共享的。而且在使用上也没有什么区别。

另外，**TLAB仅作用于新生代的Eden Space，对象被创建的时候首先放到这个区域，但是新生代分配不了内存的大对象会直接进入老年代。因此在编写Java程序时，通常多个小的对象比大的对象分配起来更加高效**。

所以，虽然对象刚开始可能通过TLAB分配内存，存放在Eden区，但是还是会被垃圾回收或者被移到Survivor Space、Old Gen等。

不知道大家有没有想过，我们使用了TLAB之后，在TLAB上给对象分配内存时线程独享的了，这就没有冲突了，但是，TLAB这块内存自身从堆中划分出来的过程也可能存在内存安全问题啊。

所以，**在对于TLAB的分配过程，还是需要进行同步控制的。但是这种开销相比于每次为单个对象划分内存时候对进行同步控制的要低的多**。

虚拟机是否使用TLAB是可以选择的，可以通过设置-XX:+/-UseTLAB参数来指定。



可以通过设置-XX:+/-UseTLAB参数来指定是否开启TLAB分配 



# 122 栈上分配对象

### **栈上分配**

在JVM中，堆是线程共享的，因此堆上的对象对于各个线程都是共享和可见的，只要持有对象的引用，就可以访问堆中存储的对象数据。虚拟机的垃圾收集系统可以回收堆中不再使用的对象，但对于垃圾收集器来说，无论筛选可回收对象，还是回收和整理内存都需要耗费时间。

如果确定一个对象的作用域不会逃逸出方法之外，那可以将这个对象分配在栈上，这样，对象所占用的内存空间就可以随栈帧出栈而销毁。在一般应用中，不会逃逸的局部对象所占的比例很大，如果能使用栈上分配，那大量的对象就会随着方法的结束而自动销毁了，无须通过垃圾收集器回收，可以减小垃圾收集器的负载。

JVM允许将线程私有的对象打散分配在栈上，而不是分配在堆上。分配在栈上的好处是可以在函数调用结束后自行销毁，而不需要垃圾回收器的介入，从而提高系统性能。 
**栈上分配的技术基础：** 
**一是逃逸分析：**逃逸分析的目的是判断对象的作用域是否有可能逃逸出函数体。关于逃逸分析的问题可以看我另一篇文章：

**二是标量替换：**允许将对象打散分配在栈上，比如若一个对象拥有两个字段，会将这两个字段视作局部变量进行分配。

只能在server模式下才能启用逃逸分析，参数-XX:DoEscapeAnalysis启用逃逸分析，参数-XX:+EliminateAllocations开启标量替换（默认打开）。Java SE 6u23版本之后，HotSpot中默认就开启了逃逸分析，可以通过选项-XX:+PrintEscapeAnalysis查看逃逸分析的筛选结果。

### **TLAB**

TLAB的全称是Thread Local Allocation Buffer，即线程本地分配缓存区，这是一个线程专用的内存分配区域。 
由于对象一般会分配在堆上，而堆是全局共享的。因此在同一时间，可能会有多个线程在堆上申请空间。因此，每次对象分配都必须要进行同步（虚拟机采用CAS配上失败重试的方式保证更新操作的原子性），而在竞争激烈的场合分配的效率又会进一步下降。

1 JVM使用TLAB来避免多线程冲突，在给对象分配内存时，每个线程使用自己的TLAB，这样可以避免线程同步，提高了对象分配的效率。 
2 TLAB本身占用eEden区空间，在开启TLAB的情况下，虚拟机会为**每个Java线程分配一块TLAB空间**。参数-XX:+UseTLAB开启TLAB，默认是开启的。

3 TLAB空间的内存非常小，缺省情况下仅占有整个Eden空间的1%，当然可以通过选项-XX:TLABWasteTargetPercent设置TLAB空间所占用Eden空间的百分比大小。 

4 由于TLAB空间一般不会很大，因此大对象无法在TLAB上进行分配，总是会直接分配在堆上。TLAB空间由于比较小，因此很容易装满。比如，一个100K的空间，已经使用了80KB，当需要再分配一个30KB的对象时，肯定就无能为力了。这时虚拟机会有两种选择，**第一，废弃当前TLAB**，这样就会浪费20KB空间；第二，**将这30KB的对象直接分配在堆上，保留当前的TLAB**，这样可以希望将来有小于20KB的对象分配请求可以直接使用这块空间。实际上虚拟机内部会**维护一个叫作refill_waste的值，当请求对象大于refill_waste时，会选择在堆中分配，若小于该值，则会废弃当前TLAB，新建TLAB来分配对象。这个阈值可以使用TLABRefillWasteFraction来调整，它表示TLAB中允许产生这种浪费的比例。默认值为64，即表示使用约为1/64的TLAB空间作为refill_waste。默认情况下，TLAB和refill_waste都会在运行时不断调整的，使系统的运行状态达到最优**。如果想要禁用自动调整TLAB的大小，可以使用-XX:-ResizeTLAB禁用ResizeTLAB，并使用-XX:TLABSize手工指定一个TLAB的大小。 
-XX:+PrintTLAB可以跟踪TLAB的使用情况。一般不建议手工修改TLAB相关参数，推荐使用虚拟机默认行为。

### **对象内存分配的两种方法**

为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。

**指针碰撞**(Serial、ParNew等带Compact过程的收集器) 
假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump the Pointer）。 
**空闲列表**(CMS这种基于Mark-Sweep算法的收集器) 
如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”（Free List）。 
  

### **总结**

**总体流程** 
![这里写图片描述](https://img-blog.csdn.net/20170829215419709?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlhb21pbmdkZXRpYW54aWE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

**对象分配流程** 
![这里写图片描述](https://img-blog.csdn.net/20170719184539534?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlhb21pbmdkZXRpYW54aWE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast) 
如果开启栈上分配，JVM会先进行栈上分配，如果没有开启栈上分配或则不符合条件的则会进行TLAB分配，如果TLAB分配不成功，再尝试在eden区分配，如果对象满足了直接进入老年代的条件，那就直接分配在老年代。

**对象在内存的引用方式** 
![这里写图片描述](https://img-blog.csdn.net/20170829221005602?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlhb21pbmdkZXRpYW54aWE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

**对象在内存中的结构** 
![这里写图片描述](https://img-blog.csdn.net/20170829221133522?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlhb21pbmdkZXRpYW54aWE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)



# 123 锁升级过程

### 1. 重量级锁

monitor 监视器锁本质上是依赖操作系统的 Mutex Lock 互斥量 来实现的，我们一般称之为重量级锁。因为 OS 实现线程间的切换需要从用户态转换到核心态，这个转换过程成本较高，耗时相对较长，因此 synchronized 效率会比较低。

### 2. 轻量级锁

轻量级锁，其性能提升的依据是`对于绝大部分的锁，在整个生命周期内都是不会存在竞争的`，如果没有竞争，轻量级锁就可以使用 CAS 操作避免互斥量的开销，从而提升效率。
 如果打破这个依据则除了互斥的开销外，还有额外的CAS操作，因此在有多线程竞争的情况下，轻量级锁比重量级锁更慢。

- 轻量级锁的加锁过程： 

  1. 线程在进入到同步代码块的时候，JVM 会先在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象当前 Mark Word 的拷贝（官方称为 Displaced Mark Word），owner 指针指向对象的 Mark Word。此时堆栈与对象头的状态如图所示：

     ![img](https:////upload-images.jianshu.io/upload_images/43652-87293031e1ce2fb9.png?imageMogr2/auto-orient/strip|imageView2/2/w/1058/format/webp)

     image.png

  2. JVM 使用 CAS 操作尝试将对象头中的 Mark Word 更新为指向 Lock Record 的指针。如果更新成功，则执行步骤3；更新失败，则执行步骤4

  3. 如果更新成功，那么这个线程就拥有了该对象的锁，对象的 Mark Word 的锁状态为轻量级锁（标志位转变为'00'）。此时线程堆栈与对象头的状态如图所示：

     ![img](https:////upload-images.jianshu.io/upload_images/43652-2fb0e0b432478c73.png?imageMogr2/auto-orient/strip|imageView2/2/w/1064/format/webp)

     轻量级锁

  4. 如果更新失败，JVM 首先检查对象的 Mark Word 是否指向当前线程的栈帧
      如果是，就说明当前线程已经拥有了该对象的锁，那就可以直接进入同步代码块继续执行
      如果不是，就说明这个锁对象已经被其他的线程抢占了，当前线程会尝试自旋一定次数来获取锁。如果自旋一定次数 CAS 操作仍没有成功，那么轻量级锁就要升级为重量级锁（锁的标志位转变为'10'），Mark Word 中存储的就是指向重量级锁的指针，后面等待锁的线程也就进入阻塞状态

- 轻量级锁的解锁过程： 
  1. 通过 CAS 操作用线程中复制的 Displaced Mark Word 中的数据替换对象当前的 Mark Word
  2. 如果替换成功，整个同步过程就完成了
  3. 如果替换失败，说明有其他线程尝试过获取该锁，那就在释放锁的同时，唤醒被挂起的线程

### 3. 偏向锁

依据：`对于绝大部分锁，在整个同步周期内不仅不存在竞争，而且总由同一线程多次获得。`
 在一些情况下总是同一线程多次获得锁，此时第二次再重新做CAS修改对象头中的Mark Word这样的操作，有些多余。所以就有了偏向锁，只需要检查是否为偏向锁、锁标识为以及ThreadID即可，只要是同一线程就不再修改对象头。其目的为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径。

- 偏向锁枷锁过程：
  1. 检测Mark Word是否为可偏向状态，即是否为偏向锁1，锁标识位为01；
  2. 若为可偏向状态，则测试线程ID是否为当前线程ID，如果是，则执行步骤（5），否则执行步骤（3）；
  3. 如果线程ID不为当前线程ID，则通过CAS操作竞争锁，竞争成功，则将Mark Word的线程ID替换为当前线程ID，否则执行线程（4）；
  4. 通过CAS竞争锁失败，证明当前存在多线程竞争情况，当到达全局安全点，获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码块；
  5. 执行同步代码块
- 偏向锁释放过程：
  1. 当一个线程已经持有偏向锁，而另外一个线程尝试竞争偏向锁时，CAS 替换 ThreadID 操作失败，则开始撤销偏向锁。偏向锁的撤销，需要等待原持有偏向锁的线程到达全局安全点（在这个时间点上没有字节码正在执行），暂停该线程，并检查其状态
  2. 如果原持有偏向锁的线程不处于活动状态或已退出同步代码块，则该线程释放锁。将对象头设置为无锁状态（锁标志位为'01'，是否偏向标志位为'0'）
  3. 如果原持有偏向锁的线程未退出同步代码块，则升级为轻量级锁（锁标志位为'00'）

## 其他优化

- 自旋锁：
   互斥同步时，挂起和恢复线程都需要切换到内核态完成，这对性能并发带来了不少的压力。同时在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段较短的时间而去挂起和恢复线程并不值得。那么如果有多个线程同时并行执行，可以让后面请求锁的线程通过自旋（CPU忙循环执行空指令）的方式稍等一会儿，看看持有锁的线程是否会很快的释放锁，这样就不需要放弃 CPU 的执行时间了。
- 适应性自旋：
   自旋时如果锁被占用的时间比较短，那么自旋等待的效果就会比较好，而如果锁占用的时间很长，自旋的线程则会白白浪费 CPU 资源。解决这个问题的最简答的办法就是：指定自旋的次数，如果在限定次数内还没获取到锁（例如10次），就按传统的方式挂起线程进入阻塞状态。
   JDK1.6 之后引入了自适应性自旋的方式，如果在同一锁对象上，一线程自旋等待刚刚成功获得锁，并且持有锁的线程正在运行中，那么 JVM 会认为这次自旋也有可能再次成功获得锁，进而允许自旋等待相对更长的时间（例如100次）。另一方面，如果某个锁自旋很少成功获得，那么以后要获得这个锁时将省略自旋过程，以避免浪费 CPU。
- 锁消除
   虚拟机即时编译器(JIT)运行时，依据逃逸分析的数据检测到不可能存在竞争的锁，就自动将该锁消除)。锁消除的依据是逃逸分析的数据支持。
   如果判断一段代码中，堆上的数据不会逃逸出去从而被其他线程访问到，则可以把他们当做栈上的数据对待，认为它们是线程私有的，不必要加锁。
   如下所示，在 StringBuffer.append() 方法中有一个同步代码块，锁就是sb对象，但 sb 的所有引用不会逃逸到 concatString() 方法外部，其他线程无法访问它。因此这里有锁，但是在即时编译之后，会被安全的消除掉，忽略掉同步而直接执行了。

- 锁粗化
   锁粗化就是 JVM 检测到一串零碎的操作都对同一个对象加锁，则会把加锁同步的范围粗化到整个操作序列的外部。
   以上述 concatString() 方法为例，内部的 StringBuffer.append() 每次都会加锁，将会锁粗化，在第一次 append() 前至 最后一个 append() 后只需要加一次锁就可以了





<img src="G:\面试\java\锁升级.webp" alt="锁升级" style="zoom:200%;" />

```java

```

# 124  消费者-生产者模型

 

# 125 线程与进程的区别

 1调度

2 并发

3 拥有资源

4系统开销



- 进程是资源的分配和调度的一个独立单元，而线程是CPU调度的基本单元
- 同一个进程中可以包括多个线程，并且线程共享整个进程的资源（寄存器、堆栈、上下文），一个进行至少包括一个线程。
- 进程的创建调用fork或者vfork，而线程的创建调用pthread_create，进程结束后它拥有的所有线程都将销毁，而线程的结束不会影响同个进程中的其他线程的结束
- 线程是轻量级的进程，它的创建和销毁所需要的时间比进程小很多，所有操作系统中的执行功能都是创建线程去完成的
- 线程中执行时一般都要进行同步和互斥，因为他们共享同一进程的所有资源
- 线程有自己的私有属性TCB，线程id，寄存器、硬件上下文，而进程也有自己的私有属性进程控制块PCB，这些私有属性是不被共享的，用来标示一个进程或一个线程的标志
- 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动
- 线程是进程的一个实体, 是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源
- 一个线程可以创建和撤销另一个线程，同一个进程中的多个线程之间可以并发执行

进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序 健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。







# 126 线程池调优

- 属于计算型程序（CPU密集型） ：线程数=CPU核数+1
- 处理I/O多的程序(I/O密集型) ： 线程数=CPU核数*（1+平均等待时间/平均工作时间）

  1如果这个时候当前池子中的工作线程数小于corePoolSize，则新创建一个新的工作线程来执行这个任务，不管工作线程集合中有没有线程是处于空闲状态。

  2如果池子中有比corePoolSize大的但是比maximumPoolSize小的工作线程，任务会首先被尝试着放入队列，这里有两种情况需要单独说一下：a、如果任务被成功的放入队列，则看看是否需要开启新的线程来执行任务，只有当当前工作线程数为0的时候才会创建新的线程，因为之前的线程有可能因为都处于空闲状态或因为工作结束而被移除。

b、如果放入队列失败，则才会去创建新的工作线程。

3 如果corePoolSize和maximumPoolSize相同，则线程池的大小是固定的。

4 通过将maximumPoolSize设置为无限大，我们可以得到一个无上限的线程池。

5 除了通过构造参数设置这几个线程池参数之外我们还可以在运行时设置。

## 1核心线程WarmUp优化



默认情况下，**核心工作线程值在初始的时候被创建，当新任务来到的时候被启动**，但是我们可以通过重写prestartCoreThread或prestartCoreThreads方法来改变这种行为。**通常场景我们可以在应用启动的时候来WarmUp核心线程，从而达到任务过来能够立马执行的结果，使得初始任务处理的时间得到一定优化**。



## 2定制工作线程的创建优化



新的线程是通过ThreadFactory来创建的，如果没有指定，默认的Executors#defaultThreadFactory将被使用，**这个时候创建的线程将都属于同一个线程组，拥有同样的优先级和daemon状态。扩展配置ThreadFactory，我们可以配置线程的名字、线程组合daemon状态。如果调用ThreadFactory#createThread的时候失败，将返回null，executor将不会执行任何任务。**





## 3核心线程回收



如果当前池子中的工作线程数大于corePoolSize，如果超过这个数字的线程处于空闲的时间大于keepAliveTime，则这些线程将会被终止，这是一种减少不必要资源消耗的策略。这个参数可以在运行时被改变，**我们同样可以将这种策略应用给核心线程，我们可以通过调用allowCoreThreadTimeout**来实现。







## 4正确的选择队列



下面主要是不同队列策略表现:

**无界队列**

使用无界队列如LinkedBlockingQueue没有指定最大容量的时候，将会引起当核心线程都在忙的时候，新的任务被放在队列上，因此，**永远不会有大于corePoolSize的线程被创建，因此maximumPoolSize参数将失效**。**这种策略比较适合所有的任务都不相互依赖，独立执行**。举个例子，如网页服务器中，每个线程独立处理请求。但是当任务处理速度小于任务进入速度的时候会引起队列的无限膨胀。使用该**队列做为阻塞队列时要尤其当心，当任务耗时较长时可能会导致大量新任务在队列中堆积最终导致OOM。**阅读代码发现，Executors.newFixedThreadPool 采用就是 LinkedBlockingQueue，而楼主踩到的就是这个坑，当QPS很高，发送数据很大，大量的任务被添加到这个无界LinkedBlockingQueue 中，导致cpu和内存飙升服务器挂掉。

**有界队列**

常用的有两类，一类是遵循FIFO原则的队列如ArrayBlockingQueue，另一类是优先级队列如PriorityBlockingQueue。PriorityBlockingQueue中的优先级由任务的Comparator决定。 
使用有界队列时队列大小需和线程池大小互相配合，线程池较小有界队列较大时可减少内存消耗，降低cpu使用率和上下文切换，但是可能会限制系统吞吐量。**帮助限制资源的消耗，但是不容易控制**。队列长度和maximumPoolSize这两个值会相互影响，**使用大的队列和小maximumPoolSize会减少CPU的使用、操作系统资源、上下文切换的消耗，但是会降低吞吐量**，如果任务被频繁的阻塞如IO线程，系统其实可以调度更多的线程。使用小的队列通常需要大maximumPoolSize，从而使得CPU更忙一些，但是又会增加降低吞吐量的线程调度的消耗。总结一下是IO密集型可以考虑多些线程来平衡CPU的使用，CPU密集型可以考虑少些线程减少线程调度的消耗。

在我们的修复方案中，选择的就是这个类型的队列，**虽然会有部分任务被丢失，但是我们线上是排序日志搜集任务，所以对部分对丢失是可以容忍的**。

**同步移交队列**

一种比较好的默认选择是使用SynchronousQueue，这种策略会将提交的任务直接传送给工作线程，而不持有。如果当前没有工作线程来处理，即任务放入队列失败，则根据线程池的实现，会引发新的工作线程创建，因此新提交的任务会被处理。这种策略在当提交的一批任务之间有依赖关系的时候避免了锁竞争消耗。值得一提的是，这种策略最好是配合unbounded线程数来使用，从而避免任务被拒绝。同时我们必须要考虑到一种场景，当任务到来的速度大于任务处理的速度，将会引起无限制的线程数不断的增加。如果不希望任务在队列中等待而是希望将任务直接移交给工作线程，可使用SynchronousQueue作为等待队列。SynchronousQueue不是一个真正的队列，而是一种线程之间移交的机制。要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接收这个元素。**只有在使用无界线程池或者有饱和策略时才建议使用该队列**。

## 5合理的配置线程池

要想合理的配置线程池，就必须首先分析任务特性，可以从以下几个角度来进行分析：

1. 任务的性质：CPU密集型任务，IO密集型任务和混合型任务。
2. 任务的优先级：高，中和低。
3. 任务的执行时间：长，中和短。
4. 任务的依赖性：是否依赖其他系统资源，如数据库连接。

任务性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务配置尽可能小的线程，如配置Ncpu+1个线程的线程池。IO密集型任务则由于线程并不是一直在执行任务，则配置尽可能多的线程，如2*Ncpu。混合型的任务，如果可以拆分，则将其拆分成一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐率要高于串行执行的吞吐率，如果这两个任务执行时间相差太大，则没必要进行分解。我们可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。

优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先得到执行，需要注意的是如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。

执行时间不同的任务可以交给不同规模的线程池来处理，或者也可以使用优先级队列，让执行时间短的任务先执行。

依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，如果等待的时间越长CPU空闲时间就越长，那么线程数应该设置越大，这样才能更好的利用CPU。

建议使用有界队列，有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点，比如几千。有一次我们组使用的后台任务线程池的队列和线程池全满了，不断的抛出抛弃任务的异常，通过排查发现是数据库出现了问题，导致执行SQL变得非常缓慢，因为后台任务线程池里的任务全是需要向数据库查询和插入数据的，所以导致线程池里的工作线程全部阻塞住，任务积压在线程池里。如果当时我们设置成无界队列，线程池的队列就会越来越多，有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。当然我们的系统所有的任务是用的单独的服务器部署的，而我们使用不同规模的线程池跑不同类型的任务，但是出现这样问题时也会影响到其他任务。

## 6 线程池的监控

通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用

- taskCount：线程池需要执行的任务数量。
- completedTaskCount：线程池在运行过程中已完成的任务数量。小于或等于taskCount。
- largestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。
- getPoolSize:线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不+ getActiveCount：获取活动的线程数。

**通过扩展线程池进行监控。通过继承线程池并重写线程池的beforeExecute，afterExecute和terminated方法，我们可以在任务执行前，执行后和线程池关闭前干一些事情。如监控任务的平均执行时间，最大执行时间和最小执行时间等。这几个方法在线程池里是空方法**。如：

```
protected void beforeExecute(Thread t, Runnable r) { }
```



# 127 线程池原理



 https://www.cnblogs.com/xxj-bigshow/p/10375695.html 

Java中的线程池核心实现类是ThreadPoolExecutor，本章基于JDK 1.8的源码来分析Java线程池的核心设计与实现。我们首先来看一下ThreadPoolExecutor的UML类图，了解下ThreadPoolExecutor的继承关系。

![img](https://picb.zhimg.com/80/v2-e3ba513194a1f918b0abfc42b6fecd0a_720w.jpg)

ThreadPoolExecutor实现的顶层接口是Executor，顶层接口Executor提供了一种思想：将任务提交和任务执行进行解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。ExecutorService接口增加了一些能力：（1）扩充执行任务的能力，补充可以为一个或一批异步任务生成Future的方法；（2）提供了管控线程池的方法，比如停止线程池的运行。

AbstractExecutorService则是上层的抽象类，将执行任务的流程串联了起来，保证下层的实现只需关注一个执行任务的方法即可。最下层的实现类ThreadPoolExecutor实现最复杂的运行部分，ThreadPoolExecutor将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。

ThreadPoolExecutor是如何运行，如何同时维护线程和执行任务的呢？其运行机制如下图所示：

![img](https://pic1.zhimg.com/80/v2-4e788c3de25c337889e31ca0e77ceabd_720w.jpg)

线程池在内部实际上构建了一个生产者消费者模型，将线程和任务两者解耦，并不直接关联，从而良好的缓冲任务，复用线程。线程池的运行主要分成两部分：任务管理、线程管理。任务管理部分充当生产者的角色，当任务提交后，线程池会判断该任务后续的流转：（1）直接申请线程执行该任务；（2）缓冲到队列中等待线程执行；（3）拒绝该任务。线程管理部分是消费者，它们被统一维护在线程池内，根据任务请求进行线程的分配，当线程执行完任务后则会继续获取新的任务去执行，最终当线程获取不到任务的时候，线程就会被回收。

接下来，我们会按照以下三个部分去详细讲解线程池运行机制：

1. 线程池如何维护自身状态。
2. 线程池如何管理任务。
3. 线程池如何管理线程。

**2.2 生命周期管理**

线程池运行的状态，并不是用户显式设置的，而是伴随着线程池的运行，由内部来维护。线程池内部使用一个变量维护两个值：运行状态(runState)和线程数量 (workerCount)。在具体实现中，**线程池将运行状态(runState)、线程数量 (workerCount)两个关键参数的维护放在了一起**，如下代码所示：

```text
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
```

`ctl`这个AtomicInteger类型，是对线程池的运行状态和线程池中有效线程的数量进行控制的一个字段， 它同时包含两部分的信息：**线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，高3位保存runState，低29位保存workerCount**，两个变量之间互不干扰。用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源。通过阅读线程池源代码也可以发现，经常出现要同时判断线程池运行状态和线程数量的情况。线程池也提供了若干方法去供用户获得线程池当前的运行状态、线程个数。这里都使用的是位运算的方式，相比于基本运算，速度也会快很多。

关于内部封装的获取生命周期状态、获取线程池线程数量的计算方法如以下代码所示：

```text
private static int runStateOf(int c)     { return c & ~CAPACITY; } //计算当前运行状态
private static int workerCountOf(int c)  { return c & CAPACITY; }  //计算当前线程数量
private static int ctlOf(int rs, int wc) { return rs | wc; }   //通过状态和线程数生成ctl
```

ThreadPoolExecutor的运行状态有5种，分别为：

![img](https://pic2.zhimg.com/80/v2-9ff88b126bf859ccb751ee1526e97f8c_720w.jpg)

其生命周期转换如下入所示：

![img](https://picb.zhimg.com/80/v2-1ec0ca2f5213af7e504847dc1d7a9ccb_720w.jpg)



**2.3 任务执行机制**

**2.3.1 任务调度**

任务调度是线程池的主要入口，当用户提交了一个任务，接下来这个任务将如何执行都是由这个阶段决定的。了解这部分就相当于了解了线程池的核心运行机制。

首先，所有任务的调度都是由execute方法完成的，这部分完成的工作是：检查现在线程池的运行状态、运行线程数、运行策略，决定接下来执行的流程，是直接申请线程执行，或是缓冲到队列中执行，亦或是直接拒绝该任务。其执行过程如下：

1. **首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。**
2. **如果workerCount < corePoolSize，则创建并启动一个线程来执行新提交的任务。**
3. **如果workerCount >= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。**
4. **如果workerCount >= corePoolSize && workerCount < maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。**
5. **如果workerCount >= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。**

其执行流程如下图所示：

![img](https://pic1.zhimg.com/80/v2-b06a332965a66469ac512d92ff70e2db_720w.jpg)

**2.3.2 任务缓冲**

任务缓冲模块是线程池能够管理任务的核心部分**。线程池的本质是对任务和线程的管理，而做到这一点最关键的思想就是将任务和线程两者解耦，不让两者直接关联，才可以做后续的分配工作**。线程池中是以生产者消费者模式，通过一个阻塞队列来实现的。**阻塞队列缓存任务，工作线程从阻塞队列中获取任务**。

阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。

下图中展示了线程1往阻塞队列中添加元素，而线程2从阻塞队列中移除元素：

![img](https://pic3.zhimg.com/80/v2-d95aaa14dc625aa364bb9383ed9dd53d_720w.jpg)

使用不同的队列可以实现不一样的任务存取策略。在这里，我们可以再介绍下阻塞队列的成员：

![img](https://pic2.zhimg.com/80/v2-2a502a31771713d4f631034485b8b796_720w.jpg)

**2.3.3 任务申请**

由上文的任务分配部分可知，任务的执行有两种可能：一种是任务直接由新创建的线程执行。另一种是线程从任务队列中获取任务然后执行，执行完任务的空闲线程会再次去从队列中申请任务再去执行。第一种情况仅出现在线程初始创建的时候，第二种是线程获取任务绝大多数的情况。

线程需要从任务缓存模块中不断地取任务执行，帮助线程从阻塞队列中获取任务，实现线程管理模块和任务管理模块之间的通信。这部分策略由getTask方法实现，其执行流程如下图所示：

![img](https://pic2.zhimg.com/80/v2-88ce9b604268e9e98c455bbdbaa1fcd0_720w.jpg)

getTask这部分进行了多次判断，为的是控制线程的数量，使其符合线程池的状态。如果线程池现在不应该持有那么多线程，则会返回null值。工作线程Worker会不断接收新任务去执行，而当工作线程Worker接收不到任务的时候，就会开始被回收。

**2.4 Worker线程管理**

**2.4.1 Worker线程**

**线程池为了掌握线程的状态并维护线程的生命周期，设计了线程池内的工作线程Worker**。我们来看一下它的部分代码：

```text
private final class Worker extends AbstractQueuedSynchronizer implements Runnable{
    final Thread thread;//Worker持有的线程
    Runnable firstTask;//初始化的任务，可以为null
}
```

Worker这个工作线程，实现了Runnable接口，并持有一个线程thread，一个初始化的任务firstTask。thread是在调用构造方法时通过ThreadFactory来创建的线程，可以用来执行任务；firstTask用它来保存传入的第一个任务，这个任务可以有也可以为null。如果这个值是非空的，那么线程就会在启动初期立即执行这个任务，也就对应核心线程创建时的情况；如果这个值是null，那么就需要创建一个线程去执行任务列表（workQueue）中的任务，也就是非核心线程的创建。

Worker执行任务的模型如下图所示：

![img](https://picb.zhimg.com/80/v2-8b9dde8b5f4b7c1cce2fe9701444779c_720w.jpg)

线程池需要管理线程的生命周期，需要在线程长时间不运行的时候进行回收。线程池使用一张Hash表去持有线程的引用，这样可以通过添加引用、移除引用这样的操作来控制线程的生命周期。这个时候重要的就是如何判断线程是否在运行。

Worker是通过继承AQS，使用AQS来实现独占锁这个功能。没有使用可重入锁ReentrantLock，而是使用AQS，**为的就是实现不可重入的特性去反应线程现在的执行状态**。

1. **lock方法一旦获取了独占锁，表示当前线程正在执行任务中**。
2. **如果正在执行任务，则不应该中断线程**。
3. **如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断**。
4. 线程池在执行shutdown方法或**tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收**。

在线程回收过程中就使用到了这种特性，回收过程如下图所示：

![img](https://picb.zhimg.com/80/v2-3f0278cea6d3f910d5f9b5149125c57a_720w.jpg)

**2.4.2 Worker线程增加**

增加线程是通过线程池中的addWorker方法，该方法的功能就是增加一个线程，该方法不考虑线程池是在哪个阶段增加的该线程，这个分配线程的策略是在上个步骤完成的，该步骤仅仅完成增加线程，并使它运行，最后返回是否成功这个结果。**addWorker方法有两个参数：firstTask、core。firstTask参数用于指定新增的线程执行的第一个任务，该参数可以为空；core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize**，其执行流程如下图所示：

![img](https://pic4.zhimg.com/80/v2-2f26c7fbe07edf47a861b84a7c100530_720w.jpg)

**2.4.3 Worker线程回收**

线程池中线程的销毁依赖JVM自动的回收，线程池做的工作是根据当前线程池的状态维护一定数量的线程引用，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可。Worker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用。

```text
try {
  while (task != null || (task = getTask()) != null) {
    //执行任务
  }
} finally {
  processWorkerExit(w, completedAbruptly);//获取不到任务时，主动回收自己
}
```

线程回收的工作是在processWorkerExit方法完成的。

![img](https://pic3.zhimg.com/80/v2-0d9370779a75f96deabdc4c028b85009_720w.png)

事实上，在这个方法中，将线程引用移出线程池就已经结束了线程销毁的部分。但由于引起线程销毁的可能性有很多，线程池还要判断是什么引发了这次销毁，是否要改变线程池的现阶段状态，是否要根据新状态，重新分配线程。

**2.4.4 Worker线程执行任务**

在Worker类中的run方法调用了runWorker方法来执行任务，runWorker方法的执行过程如下：

1. while循环不断地通过getTask()方法获取任务。
2. getTask()方法从阻塞队列中取任务。
3. 如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态。
4. 执行任务。
5. 如果getTask结果为null则跳出循环，执行processWorkerExit()方法，销毁线程。

执行流程如下图所示：

![img](https://pic3.zhimg.com/80/v2-39e62ca6c230d48549f08092d29ab547_720w.jpg)







# 128  给定一个进程，有多个线程，其中一个线程出现OOM异常，判断所有线程的状态 

# 129、原子类实现

# 130、volatile实现原理 



# 131死锁的四个条件：

1互斥使用，即当资源被一个线程使用(占有)时，别的线程不能使用

2 不可抢占，资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占用者

  主动释放

3 请求和保持，即当资源的请求者在请求其他的资源的同时保持对原有资源的占有

4循环等待，即存在一个等待队列: P1占有P2的资源，P2占有P3的资源，P3占有P1的资源。

  这样就形成了一个等待环路。





# 132、什么是多线程中的上下文切换 

# 133、死锁与活锁的区别，死锁与饥饿的区别 

 **死锁**：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。
死锁发生的四个条件
1、互斥条件：线程对资源的访问是排他性的，如果一个线程对占用了某资源，那么其他线程必须处于等待状态，直到资源被释放。
2、请求和保持条件：线程T1至少已经保持了一个资源R1占用,但又提出对另一个资源R2请求，而此时，资源R2被其他线程T2占用，于是该线程T1也必须等待，但又对自己保持的资源R1不释放。
3、不剥夺条件：线程已获得的资源，在未使用完之前，不能被其他线程剥夺，只能在使用完以后由自己释放。
4、环路等待条件：在死锁发生时，必然存在一个“进程-资源环形链”，即：{p0,p1,p2,...pn},进程p0（或线程）等待p1占用的资源，p1等待p2占用的资源，pn等待p0占用的资源。（最直观的理解是，p0等待p1占用的资源，而p1而在等待p0占用的资源，于是两个进程就相互等待）

**活锁**：是指线程1可以使用资源，但它很礼貌，让其他线程先使用资源，线程2也可以使用资源，但它很绅士，也让其他线程先使用资源。这样你让我，我让你，最后两个线程都无法使用资源。

关于“死锁与活锁”的比喻：
死锁：迎面开来的汽车A和汽车B过马路，汽车A得到了半条路的资源（满足死锁发生条件1：资源访问是排他性的，我占了路你就不能上来，除非你爬我头上去），汽车B占了汽车A的另外半条路的资源，A想过去必须请求另一半被B占用的道路（死锁发生条件2：必须整条车身的空间才能开过去，我已经占了一半，尼玛另一半的路被B占用了），B若想过去也必须等待A让路，A是辆兰博基尼，B是开奇瑞QQ的屌丝，A素质比较低开窗对B狂骂：快给老子让开，B很生气，你妈逼的，老子就不让（死锁发生条件3：在未使用完资源前，不能被其他线程剥夺），于是两者相互僵持一个都走不了（死锁发生条件4：环路等待条件），而且导致整条道上的后续车辆也走不了。
例如：马路中间有条小桥，只能容纳一辆车经过，桥两头开来两辆车A和B，A比较礼貌，示意B先过，B也比较礼貌，示意A先过，结果两人一直谦让谁也过不去。

**饥饿：**是指如果线程T1占用了资源R，线程T2又请求封锁R，于是T2等待。T3也请求资源R，当T1释放了R上的封锁后，系统首先批准了T3的请求，T2仍然等待。然后T4又请求封锁R，当T3释放了R上的封锁之后，系统又批准了T4的请求......，T2可能永远等待。

关于”饥饿“的比喻：
在“首堵”北京的某一天，天气阴沉，空气中充斥着雾霾和地沟油的味道，某个苦逼的临时工交警正在处理塞车，有两条道A和B上都堵满了车辆，其中A道堵的时间最长，B相对相对堵的时间较短，这时，前面道路已疏通，交警按照最佳分配原则，示意B道上车辆先过，B道路上过了一辆又一辆，A道上排队时间最长的确没法通过，只能等B道上没有车辆通过的时候再等交警发指令让A道依次通过，这也就是ReentrantLock显示锁里提供的不公平锁机制（当然了，ReentrantLock也提供了公平锁的机制，由用户根据具体的使用场景而决定到底使用哪种锁策略），不公平锁能够提高吞吐量但不可避免的会造成某些线程的饥饿。 

# 134JMM模型是什么

  https://zhuanlan.zhihu.com/p/258393139 

#  13 5、Java中用到的线程调度[算法]()是什么 



抢占式。一个线程用完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。

操作系统中可能会出现某条线程常常获取到VPU控制权的情况，为了让某些优先级比较低的线程也能获取到CPU控制权，可以使用Thread.sleep(0)手动触发一次操作系统分配时间片的操作，这也是平衡CPU控制权的一种操作。

抢占式调度：
抢占式调度指的是每条线程执行的时间、线程的切换都由系统控制，系统控制指的是在系统某种
运行机制下，可能每条线程都分同样的执行时间片，也可能是某些线程执行的时间片较长，甚至
某些线程得不到执行的时间片。在这种机制下，一个线程的堵塞不会导致整个进程堵塞。

协同式调度：
协同式调度指某一线程执行完后主动通知系统切换到另一线程上执行，这种模式就像接力赛一样，
一个人跑完自己的路程就把接力棒交接给下一个人，下个人继续往下跑。线程的执行时间由线程
本身控制，线程切换可以预知，不存在多线程同步问题，但它有一个致命弱点：如果一个线程编
写有问题，运行到一半就一直堵塞，那么可能导致整个系统崩溃。

![img](https://img-blog.csdnimg.cn/20200309001124727.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25pdXhpa3Vu,size_16,color_FFFFFF,t_70)

**JVM 的线程调度实现（抢占式调度）**
java 使用的线程调使用抢占式调度，Java 中线程会按优先级分配 CPU 时间片运行，且优先级越高
越优先执行，但优先级高并不代表能独自占用执行时间片，可能是优先级高得到越多的执行时间
片，反之，优先级低的分到的执行时间少但不会分配不到执行时间。

线程让出 cpu 的情况：
\1.  当前运行线程主动放弃 CPU，JVM 暂时放弃 CPU 操作（基于时间片轮转调度的 JVM 操作系
统不会让线程永久放弃 CPU，或者说放弃本次时间片的执行权），例如调用 yield()方法。
\2.  当前运行线程因为某些原因进入阻塞状态，例如阻塞在 I/O 上。
\3.  当前运行线程结束，即运行完 run()方法里面的任务。

# 13 6、什么是线程组，为什么在Java中不推荐使用



- 线程组ThreadGroup对象中的stop，resume，suspend会导致安全问题，主要是死锁问题，已经被官方废弃，多以价值已经大不如以前。
- 线程组ThreadGroup不是线程安全的，在使用过程中不能及时获取安全的信息。

来自







一段苹果的广告语，致疯狂的人 

      他们特立独行。他们桀骜不驯。他们惹是生非。他们格格不入。他们用与众不同的眼光看待事物。他们不喜欢墨守成规。他们也不愿安于现状。你可以认同他们，反对他们，颂扬或是诋毁他们。但唯独不能漠视他们。因为他们改变了寻常事物。他们推动人类向前迈进。或许他们是别人眼里的疯子，但他们却是我们眼中的天才。因为只有那些疯狂到以为自己能够改变世界的人，才能真正改变世界。






