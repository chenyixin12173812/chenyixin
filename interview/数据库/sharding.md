# sharding

# 2 数据分片

我们的系统是否需要分库分表吗？

一般MySQL单表1000W左右的数据是没有问题的（前提是应用系统和数据库等层面设计和优化的比较好）。当然，除了考虑当前的数据量和性能情况时，作为架构师，我们需要提前考虑系统半年到一年左右的业务增长情况，对数据库服务器的QPS、连接数、容量等做合理评估和规划，并提前做好相应的准备工作。如果单机无法满足，且很难再从其他方面优化，那么说明是需要考虑分片的。这种情况可以先去掉数据库中自增ID，为分片和后面的数据迁移工作提前做准备。

很多人觉得“分库分表”是宜早不宜迟，应该尽早进行。

基于水平分库分表，拆分策略为常用的一致性hash法。

## 2.1 整体方案

### 2.1.0 水平分表、水平分库、垂直分库分表

垂直分库：把不同的表分到不同的数据库里。

垂直分表：把一张表的不同字段，放在不同的数据库，冷热隔离。

水平分库: 把一个大表拆分成多个小表（user分为user_1， user_2），不在同一个数据库内

水平分表:把一个大表拆分成多个小表（user分为user_1， user_2），在同一个数据库内。

### 2.1.1水平切分，到底是分库还是分表？

强烈建议分库，而不是分表，因为：

- 分表依然公用一个数据库文件，仍然有磁盘IO的竞争
- 分库能够很容易的将数据迁移到不同数据库实例，甚至数据库机器上，扩展性更好

### 2.1.2 为什么不分区？

所有数据逻辑上还在一个表中，但物理上，可以根据一定的规则放在不同的文件中。这是MySQL5.1之后支持的功能，业务代码无需改动。

**分区表看上去很帅气，为什么大部分互联网公司不使用，而更多的选择分库分表来进行水平切分呢？**

分区表的一些缺点，是大数据量，高并发量的业务难以接受的：

（1）如果SQL不走分区键，很容易出现全表锁；

（2）在分区表实施关联查询，就是一个灾难；

（3）分库分表，自己掌控业务场景与访问模式，可控；分区表，工程师写了一个SQL，自己无法确定MySQL是怎么玩的，不可控；

*画外音：类似于，不要把业务逻辑实现在存储过程，用户自定义函数，触发器里，而要实现在业务代码里一样。*

（4）DBA给OP埋坑，容易大打出手，造成同事矛盾；

（5）…

当然，在数据量和并发量不太大，或者按照时间来存储冷热数据或归档数据的一些特定场景下，分区表还是有上场机会的

## 2.2 分片规则和策略

### 2.2 .1分片字段该如何选择

在开始分片之前，我们首先要确定分片字段（也可称为“片键”）。很多常见的例子和场景中是采用ID或者时间字段进行拆分。这也并不绝对的，我的建议是结合实际业务，通过对系统中执行的sql语句进行统计分析，选择出需要分片的那个表中最频繁被使用，或者最重要的字段来作为分片字段。

### 2.2 .2常见分片规则

常见的分片策略有**随机分片**和**连续分片**这两种，如下图所示：

 ![æ°´å¹³ååºåè¡¨çå³é®æ­¥éª¤ä»¥åå¯è½éå°çé®é¢](https://static001.infoq.cn/resource/image/b7/45/b7be0f4a8b7ca71657ade77253a3ba45.png) 

1 当需要使用分片字段进行范围查找时，连续分片可以快速定位分片进行高效查询，大多数情况下可以有效避免跨分片查询的问题。后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移。但是，连续分片也有可能存在数据热点的问题，就像图中按时间字段分片的例子，有些节点可能会被频繁查询压力较大，热数据节点就成为了整个集群的瓶颈。而有些节点可能存的是历史数据，很少需要被查询到。

2 随机分片其实并不是随机的，也遵循一定规则。通常，我们会采用Hash取模的方式进行分片拆分，所以有些时候也被称为离散分片。随机分片的数据相对比较均匀，不容易出现**热点和并发访问**的瓶颈。但是，后期分片集群扩容起来需要迁移旧的数据。**使用一致性Hash算法能够很大程度的避免这个问题，**所以很多中间件的分片集群都会采用一致性Hash算法。离散分片也很容易面临跨分片查询的复杂问题。

### 2.2 .3数据迁移，容量规划，扩容等问题

很少有项目会在初期就开始考虑分片设计的，一般都是在业务高速发展面临性能和存储的瓶颈时才会提前准备。因此，不可避免的就需要考虑历史数据迁移的问题。一般做法就是通过程序先读出历史数据，然后按照指定的分片规则再将数据写入到各个分片节点中。

此外，我们需要根据当前的数据量和QPS等进行容量规划，综合成本因素，推算出大概需要多少分片（一般建议单个分片上的单表数据量不要超过1000W）。

如果是采用随机分片，则需要考虑后期的扩容问题，相对会比较麻烦。如果是采用的范围分片，只需要添加节点就可以自动扩容。

### 2.2.X 美团的方案 https://tech.meituan.com/2016/11/18/dianping-order-db-sharding.html 





## 2.4 分割后的sql

### 2.4.1禁止使用：

a）各种联合查询

b）子查询

c）触发器

d）用户自定义函数

e）“事务”都用的很少

原因：对数据库性能影响极大

### 2.4.2 IN查询



### 2.4.3 非Partition key的查询

**1 端上除了partition key只有一个非partition key作为条件查询**

（1）映射法

key与查询时段的 redis缓存关系，做一次映射。

![img](https://mmbiz.qpic.cn/mmbiz_png/qibDtCQTAY1CJXhCdWfn4Qp67wFfoJcm4NrWKQic95p7XvaOOY03nna2fMH1uJ9gM50tAyzlxW0ANGsgah4oyrLQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

基因法

![img](https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbueICb608XJDZq0C1ZUG2E94XwMw5PkDx2icPHfEuzoC4ww9epk30u2co9Cxoqj9w9drrngvGZyNNOw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> 注：写入时，基因法生成user_id，如图。关于xbit基因，例如要分8张表，23=8，故x取3，即3bit基因。根据user_id查询时可直接取模路由到对应的分库或分表。
>
> 
>
> 根据user_name查询时，先通过user_name_code生成函数生成user_name_code再对其取模路由到对应的分库或分表。id生成常用snowflake算法。

**端上除了partition key不止一个非partition key作为条件查询**

映射法

![img](https://mmbiz.qpic.cn/mmbiz_png/qibDtCQTAY1CJXhCdWfn4Qp67wFfoJcm485zcSMZeEicibNvpZAlVeSTSlysGPiaYicwIxWbFcVQrONFhP2RfMerG4Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

冗余法

![img](https://mmbiz.qpic.cn/mmbiz_png/qibDtCQTAY1CJXhCdWfn4Qp67wFfoJcm4dYadXuia2KPjxwJ0GlpH9G6FWPFfGgSibDZtXo28ZkjBvVxLbTJV4bkw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> 注：按照order_id或buyer_id查询时路由到db_o_buyer库中，按照seller_id查询时路由到db_o_seller库中。感觉有点本末倒置！有其他好的办法吗？改变技术栈呢？

**后台除了partition key还有各种非partition key组合条件查询**

NoSQL法

![img](https://mmbiz.qpic.cn/mmbiz_png/eQPyBffYbueICb608XJDZq0C1ZUG2E9476Mmle7AVZNia9SWLKMuMyFciaHNemsBMo6huZ8W5zNby5ge09wxPqJQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

冗余法

![img](https://mmbiz.qpic.cn/mmbiz_png/qibDtCQTAY1CJXhCdWfn4Qp67wFfoJcm46bDSxkPLnV3pVON40vRO1GlZe1SqK1CSH0hcyLONgQYmd3VgO51Ong/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 非partition key跨库跨表分页查询问题



> 注：用NoSQL法解决（ES等）。



### 2.4.4 夸库分页怎么玩？

### 2.4.5. ORDER BY xxx OFFSET xxx LIMIT xxx

分库后的难题：如何确认全局偏移量

分库后传统解决方案：查询改写+内存排序

a）ORDER BY time OFFSET 0 LIMIT 10000+100

b）对20200条记录进行排序

c）返回第10000至10100条记录

优化方案一：增加辅助id，以减少查询量

优化方案二：模糊查询

a）业务上：禁止查询XX页之后的数据

b）业务上：允许模糊返回 => 第100页数据的精确性真这么重要么？

最后的大招！！！（由于时间问题，只在DTCC2015上分享了哟）

**优化方案三：终极方案，业务无损，查询改写与两段查询**

需求：ORDER BY x OFFSET 10000 LIMIT 4; 如何在分库下实现（假设分3库）

**步骤一、查询改写**： ORDER BY x OFFSET **3333** LIMIT 4

[4,7,9,10] <= 1库返回

[3,5,6,7] <= 2库返回

[6,8,9,11] <= 3库返回

**步骤二、找到步骤一返回的min和max**，即3和11

**步骤三、通过min和max二次查询**：ORDER BY x WHERE x **BETWEEN** 3 AND 11

[3,4,7,9,10] <= 1库返回，4在1库offset是3333，于是3在1库的offset是3332

[3,5,6,7,11] <= 2库返回，3在2库offset是3333

[3,5,6,8,9,11] <= 3库返回，6在3库offset是3333，于是3在3库的offset是3331

**步骤四、找出全局OFFSET**

3是全局offset3332+3333+3331=9996

当当当当，跳过3,3,3,4，于是全局OFFSET 10000 LIMIT 4是[5,5,6,6]

## 2.5 分片后的问题

### 2.5 .1跨分片join

Join是关系型数据库中最常用的特性，但是在分片集群中，join也变得非常复杂。应该尽量避免跨分片的join查询（这种场景，比上面的跨分片分页更加复杂，而且对性能的影响很大）。通常有以下几种方式来避免：

### 1.全局表

全局表的概念之前在“垂直分库”时提过。基本思想一致，就是把一些类似数据字典又可能会产生join查询的表信息放到各分片中，从而避免跨分片的join。

### 2.ER分片

在关系型数据库中，表之间往往存在一些关联的关系。如果我们可以先确定好关联关系，并将那些存在关联关系的表记录存放在同一个分片上，那么就能很好的避免跨分片join问题。在一对多关系的情况下，我们通常会选择按照数据较多的那一方进行拆分。如下图所示：

 ![æ°´å¹³ååºåè¡¨çå³é®æ­¥éª¤ä»¥åå¯è½éå°çé®é¢](https://static001.infoq.cn/resource/image/bc/3b/bc29ebe33477fedaeedac4838acd413b.jpg) 

这样一来，Data Node1上面的订单表与订单详细表就可以直接关联，进行局部的join查询了，Data Node2上也一样。基于ER分片的这种方式，能够有效避免大多数业务场景中的跨分片join问题。

### 3.内存计算

随着spark内存计算的兴起，理论上来讲，很多跨数据源的操作问题看起来似乎都能够得到解决。可以将数据丢给spark集群进行内存计算，最后将计算结果返回。

### 2.5.2 跨分片的排序分页

一般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：

 ![æ°´å¹³ååºåè¡¨çå³é®æ­¥éª¤ä»¥åå¯è½éå°çé®é¢](https://static001.infoq.cn/resource/image/2a/cc/2a7c92a59ae17c99c68b2e6d8ffee3cc.jpg) 

上面图中所描述的只是最简单的一种情况（取第一页数据），看起来对性能的影响并不大。但是，如果想取出第10页数据，情况又将变得复杂很多，如下图所示：

 ![æ°´å¹³ååºåè¡¨çå³é®æ­¥éª¤ä»¥åå¯è½éå°çé®é¢](https://static001.infoq.cn/resource/image/2a/cc/2a7c92a59ae17c99c68b2e6d8ffee3cc.jpg) 

有些读者可能并不太理解，为什么不能像获取第一页数据那样简单处理（排序取出前10条再合并、排序）。其实并不难理解，因为各分片节点中的数据可能是随机的，为了排序的准确性，必须把所有分片节点的前N页数据都排序好后做合并，最后再进行整体的排序。很显然，这样的操作是比较消耗资源的，用户越往后翻页，系统性能将会越差

### 2.5.3 跨分片的函数处理

 在使用Max、Min、Sum、Count之类的函数进行统计和计算的时候，需要先在每个分片数据源上执行相应的函数处理，然后再将各个结果集进行二次处理，最终再将处理结果返回。如下图所示： 

 ![æ°´å¹³ååºåè¡¨çå³é®æ­¥éª¤ä»¥åå¯è½éå°çé®é¢](https://static001.infoq.cn/resource/image/e0/09/e054a401d37415e90687e5cb4ebe1009.jpg) 

### 2.5.4 跨分片事务问题

### 2.5.5 扩容问题



**水平扩容库（升级从库法）**

**![img](https://mmbiz.qpic.cn/mmbiz_png/qibDtCQTAY1CJXhCdWfn4Qp67wFfoJcm4CObBX3TiaLnJDvGp8xe0q0arAbgz4A8PpXqLhgicVopbyyBHyfCxaCJQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)**

> 注：扩容是成倍的。

**水平扩容表（双写迁移法）**

**![img](https://mmbiz.qpic.cn/mmbiz_png/qibDtCQTAY1CJXhCdWfn4Qp67wFfoJcm4YEH6MHuicvf3icEMXIcHZNgbibnw5VkMZCjKJHEac7TBP0KKxJ0arT7eQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)**

- 第一步：（同步双写）修改应用配置和代码，加上双写，部署；
- 第二步：（同步双写）将老库中的老数据复制到新库中；
- 第三步：（同步双写）以老库为准校对新库中的老数据；
- 第四步：（同步双写）修改应用配置和代码，去掉双写，部署；

> 注：双写是通用方案。