分布事物

架构师  https://www.infoq.cn/article/solution-of-distributed-system-transaction-consistency/ 

 https://www.cnblogs.com/jajian/p/10014145.html 

# 分布式事务

阿里分布式事务框架GTS（**Seata**） fescar TXC

LCN分布式事务框架

分布式事务Saga框架

ByteTCC

spring使用 第三方Jotm和Automikos实现

https://recomm.cnblogs.com/blogpost/12567070

阿里Fescar（GTS开源版本，GTS有阿里云服务）官方中文：https://github.com/alibaba/fescar/wiki/Home_Chinese

开源消息和与其他分布式框架（ByteTCC、LCN）对比：https://blog.csdn.net/xlgen157387/article/details/86289066

介绍和对比：https://blog.csdn.net/weixin_39800144/article/details/86498296



两种开源解决方案框架介绍：

https://blog.csdn.net/zyndev/article/details/79604395#_97

LCN：

https://www.jianshu.com/p/73beee3c70e9

https://www.txlcn.org/

ByteTCC:

https://www.bytesoft.org/

开源中国问题讨论：

https://www.oschina.net/question/2265860_2191017

https://www.infoq.cn/article/solution-of-distributed-system-transaction-consistency

https://my.oschina.net/rock912/blog/717826

码云分布式事务框架搜索相关：

[https://gitee.com/search?q=%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1&type=&utf8=%E2%9C%93](https://gitee.com/search?q=分布式事务&type=&utf8=✓)

myth:

https://blog.csdn.net/qqxixy/article/details/80133345

阿里GTS:

https://www.cnblogs.com/jiangyu666/p/8522547.html

tcc-transaction:

https://blog.csdn.net/l1028386804/article/details/73731363

解决方案参考文章：

https://blog.csdn.net/congyihao/article/details/70195154

https://www.jianshu.com/p/16b1baf015e8

https://www.jianshu.com/p/453c6e7ff81c

http://www.cnblogs.com/uttu/p/6553307.html

https://www.cnblogs.com/savorboard/p/distributed-system-transaction-consistency.html

http://www.codeceo.com/article/distributed-transaction.html

https://blog.csdn.net/bjweimengshu/article/details/79607522

https://blog.csdn.net/u010425776/article/details/79516298

JTA相关：

https://www.ibm.com/developerworks/cn/java/j-lo-jta/

https://www.breakyizhan.com/springboot/3413.html

https://www.aliyun.com/jiaocheng/topic_53038.html

https://blog.csdn.net/tr1912/article/details/55001831

https://www.cnblogs.com/drizzlewithwind/p/5711653.html

# 1 基础

## 1.1 2pc

 XA 协议指的是 TM（事务管理器）和 RM（资源管理器）之间的接口。目前主流的关系型数据库产品都是实现了 XA 接口的。JTA(Java Transaction API) 是符合 X/Open DTP 模型的，事务管理器和资源管理器之间也使用了 XA 协议。 本质上也是借助两阶段提交协议来实现分布式事务的，下面分别来看看 XA 事务成功和失败的模型图： 

阶段提交2PC是分布式事务中最强大的事务类型之一，两段提交就是分两个阶段提交，第一阶段询问各个事务数据源是否准备好，第二阶段才真正将数据提交给事务数据源。

为了保证该事务可以满足ACID，就要引入一个协调者（Cooradinator）。其他的节点被称为参与者（Participant）。协调者负责调度参与者的行为，并最终决定这些参与者是否要把事务进行提交。处理流程如下：

![5种分布式事务解决方案优缺点对比](https://imgconvert.csdnimg.cn/aHR0cDovL3AxLnBzdGF0cC5jb20vbGFyZ2UvcGdjLWltYWdlL2NhZDg5YzY5MDk2ZDQwNGU5ZjhmYzExYjhiNGQxOWNk)

 

**阶段一**

a) 协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待答复。

b) 各参与者执行事务操作，将 undo 和 redo 信息记入事务日志中（但不提交事务）。

c) 如参与者执行成功，给协调者反馈 yes，否则反馈 no。

**阶段二**

如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(rollback)消息；否则，发送提交(commit)消息。两种情况处理如下：

**情况1：**当所有参与者均反馈 yes，提交事务

a) 协调者向所有参与者发出正式提交事务的请求（即 commit 请求）。

b) 参与者执行 commit 请求，并释放整个事务期间占用的资源。

c) 各参与者向协调者反馈 ack(应答)完成的消息。

d) 协调者收到所有参与者反馈的 ack 消息后，即完成事务提交。

**情况2：**当有一个参与者反馈 no，回滚事务

a) 协调者向所有参与者发出回滚请求（即 rollback 请求）。

b) 参与者使用阶段 1 中的 undo 信息执行回滚操作，并释放整个事务期间占用的资源。

c) 各参与者向协调者反馈 ack 完成的消息。

d) 协调者收到所有参与者反馈的 ack 消息后，即完成事务。



存在的问题：

**1) 性能问题**：所有参与者在事务提交阶段处于同步阻塞状态，占用系统资源，容易导致性能瓶颈。

**2) 可靠性问题：**如果协调者存在单点故障问题，或出现故障，提供者将一直处于锁定状态。

**3) 数据一致性问题：**在阶段 2 中，如果出现协调者和参与者都挂了的情况，有可能导致数据不一致。

4)  XA的性能很低。一个数据库的事务和多个数据库间的XA事务性能对比可发现，性能差10倍左右。因此要尽量避免XA事务，例如可以将数据写入本地，用高性能的消息系统分发数据。或使用数据库复制等技术。 只有在这些都无法实现，且性能不是瓶颈时才应该使用XA。 

**优点：**尽量保证了数据的强一致，适合对数据强一致要求很高的关键领域。（其实也不能100%保证强一致）。

**缺点：**实现复杂，牺牲了可用性，对性能影响较大，不适合高并发高性能场景。

在 JavaEE 平台下，WebLogic、Webshare 等主流商用的应用服务器提供了 JTA 的实现和支持。而在 Tomcat 下是没有实现的（其实笔者并不认为 Tomcat 能算是 JavaEE 应用服务器），这就需要借助第三方的框架**Jotm\**\**、Automikos（分布式事务） 等来实现，两者均支持 spring 事务整合。**

**而在 Windows .NET 平台中，则可以借助 ado.net 中的***TransactionScop* API 来编程实现，还必须配置和借助 Windows 操作系统中的 MSDTC 服务。如果你的数据库使用的 mysql，并且 mysql 是部署在 Linux 平台上的，那么是无法支持分布式事务的。 由于篇幅关系，这里不展开，感兴趣的读者可以自行查阅相关资料并实践。

**总结：这种方式实现难度不算太高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况。但分布式事务对性能的影响会比较大，不适合高并发和高性能要求的场景。**

## 1.2 3pc

三阶段提交是在二阶段提交上的改进版本，3PC最关键要解决的就是协调者和参与者同时挂掉的问题，所以3PC把2PC的准备阶段再次一分为二，这样三阶段提交。处理流程如下：

![5种分布式事务解决方案优缺点对比](https://imgconvert.csdnimg.cn/aHR0cDovL3AxLnBzdGF0cC5jb20vbGFyZ2UvcGdjLWltYWdlLzNkOTVmMjQxMzEwYzRmZDg4MGFhYjE2NTdhMjNiYWU2)

 

**阶段一**

a) 协调者向所有参与者发出包含事务内容的 canCommit 请求，询问是否可以提交事务，并等待所有参与者答复。

b) 参与者收到 canCommit 请求后，如果认为可以执行事务操作，则反馈 yes 并进入预备状态，否则反馈 no。

**阶段二**

协调者根据参与者响应情况，有以下两种可能。

**情况1：**所有参与者均反馈 yes，协调者预执行事务

a) 协调者向所有参与者发出 preCommit 请求，进入准备阶段。

b) 参与者收到 preCommit 请求后，执行事务操作，将 undo 和 redo 信息记入事务日志中（但不提交事务）。

c) 各参与者向协调者反馈 ack 响应或 no 响应，并等待最终指令。

**情况2：**只要有一个参与者反馈 no，或者等待超时后协调者尚无法收到所有提供者的反馈，即中断事务

a) 协调者向所有参与者发出 abort 请求。

b) 无论收到协调者发出的 abort 请求，或者在等待协调者请求过程中出现超时，参与者均会中断事务。

**阶段三**

该阶段进行真正的事务提交，也可以分为以下两种情况。

**情况 1：**所有参与者均反馈 ack 响应，执行真正的事务提交

a) 如果协调者处于工作状态，则向所有参与者发出 do Commit 请求。

b) 参与者收到 do Commit 请求后，会正式执行事务提交，并释放整个事务期间占用的资源。

c) 各参与者向协调者反馈 ack 完成的消息。

d) 协调者收到所有参与者反馈的 ack 消息后，即完成事务提交。

**情况2：**只要有一个参与者反馈 no，或者等待超时后协调组尚无法收到所有提供者的反馈，即回滚事务。

a) 如果协调者处于工作状态，向所有参与者发出 rollback 请求。

b) 参与者使用阶段 1 中的 undo 信息执行回滚操作，并释放整个事务期间占用的资源。

c) 各参与者向协调组反馈 ack 完成的消息。

d) 协调组收到所有参与者反馈的 ack 消息后，即完成事务回滚。

**优点：**相比二阶段提交，**三阶段提交降低了阻塞范围，在等待超时后协调者或参与者会中断事务。避免了协调者单点问题。阶段 3 中协调者出现问题时，参与者会继续提交事务**。

**缺点：**数据不一致问题依然存在，当在参与者收到 preCommit 请求后等待 do commite 指令时，此时如果协调者请求中断事务，而协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。

总结： XA三阶段提交在两阶段提交的基础上增加了CanCommit阶段，并且引入了超时机制。一旦事物参与者迟迟没有接到协调者的commit请求，会自动进行本地commit。这样有效解决了协调者单点故障的问题。但是性能问题和不一致的问题仍然没有根本解决 。

##  1.3 TCC

是业务级别的事物，除了数据库外还有发短信等等， 



TCC事务补偿是基于2PC实现的业务层事务控制方案，引入了自定义的补偿方案，它是Try、Confirm和Cancel三个单词的首字母，含义如下：
1、Try 检查及预留业务资源完成提交事务前的检查，并预留好资源。
2、Confirm 确定执行业务操作
对try阶段预留的资源正式执行。
3、Cancel 取消执行业务操作
对try阶段预留的资源释放，回滚。

具体实现：

- ByteTCC，[github.com/liuyangming](https://link.zhihu.com/?target=http%3A//github.com/liuyangming)
- tcc-transaction：[github.com/changmingxi](https://link.zhihu.com/?target=http%3A//github.com/changmingxi)

 总结：这种方式实现难度不算太高，自己实现 回滚操作，**对业务侵入性太大**。

## 1.4 柔性事物（实际使用）

柔性事务满足BASE理论（基本可用，最终一致）

刚性事务满足ACID理论

## 1.4.1本地消息表

这种实现方式的思路，其实是源于 ebay，后来通过支付宝等公司的布道，在业内广泛使用。其基本的设计思想是将远程分布式事务拆分成一系列的本地事务。如果不考虑性能及设计优雅，借助关系型数据库中的表即可实现。

举个经典的跨行转账的例子来描述。

第一步伪代码如下，扣款 1W，通过本地事务保证了凭证消息插入到消息表中。

![分布式系统事务一致性解决方案](https://static001.infoq.cn/resource/image/61/5c/61337ee75b0c2a66c06e99fc2ba2505c.png)

第二步，通知对方银行账户上加 1W 了。那问题来了，如何通知到对方呢？

通常采用两种方式：

1. 采用时效性高的 MQ，由对方订阅消息并监听，有消息时自动触发事件
2. 采用定时轮询扫描的方式，去检查消息表的数据。

两种方式其实各有利弊，仅仅依靠 MQ，可能会出现通知失败的问题。而过于频繁的定时轮询，效率也不是最佳的（90% 是无用功）。所以，我们一般会把两种方式结合起来使用。

解决了通知的问题，又有新的问题了。万一这消息有重复被消费，往用户帐号上多加了钱，那岂不是后果很严重？

仔细思考，其实我们可以消息消费方，也通过一个“消费状态表”来记录消费状态。在执行“加款”操作之前，检测下该消息（提供标识）是否已经消费过，消费完成后，通过本地事务控制来更新这个“消费状态表”。这样子就避免重复消费的问题。

总结：上诉的方式是一种非常经典的实现，基本避免了分布式事务，实现了“最终一致性”。但是，关系型数据库的吞吐量和性能方面存在瓶颈，频繁的读写消息会给数据库造成压力。所以，在真正的高并发场景下，该方案也会有瓶颈和限制的。

优点： **一种非常经典的实现，避免了分布式事务，实现了最终一致性**。

缺点： **消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理**。

## 1.4.2 MQ（非事务消息， **最大努力通知**  ）

通常情况下，在使用非事务消息支持的 MQ 产品时，我们很难将业务操作与对 MQ 的操作放在一个本地事务域中管理。通俗点描述，还是以上述提到的“跨行转账”为例，我们很难保证在扣款完成之后对 MQ 投递消息的操作就一定能成功。这样一致性似乎很难保证。

先从消息生产者这端来分析，请看伪代码：

![分布式系统事务一致性解决方案](https://static001.infoq.cn/resource/image/3f/b8/3f58a1db213072629f911585c3425ab8.png)

根据上述代码及注释，我们来分析下可能的情况：

1. 操作数据库成功，向 MQ 中投递消息也成功，皆大欢喜
2. 操作数据库失败，（）不会向 MQ 中投递消息了
3. 操作数据库成功，但是向 MQ 中投递消息时失败，向外抛出了异常，刚刚执行的更新数据库的操作将被回滚

从上面分析的几种情况来看，貌似问题都不大的。那么我们来分析下消费者端面临的问题：

1. 消息出列后，消费者对应的业务操作要执行成功。如果业务执行失败，消息不能失效或者丢失。需要保证消息与业务操作一致
2. 尽量避免消息重复消费。如果重复消费，也不能因此影响业务结果

如何保证消息与业务操作一致，不丢失？

主流的 MQ 产品都具有持久化消息的功能。如果消费者宕机或者消费失败，都可以执行重试机制的（有些 MQ 可以自定义重试次数）。

如何避免消息被重复消费造成的问题？

1. 保证消费者调用业务的服务接口的幂等性

2. 通过消费日志或者类似状态表来记录消费状态，便于判断（建议在业务上自行实现，而不依赖 MQ 产品提供该特性）

   

   缺点：1，发送方自己处理成功，连消息都没发出去。不一致

   2.消息系统挂了

   3.处理重复消费等问题。

**总结：这种方式比较常见，性能和吞吐量是优于使用关系型数据库消息表的方案。如果 MQ\**\** 自身和业务都具有高可用性，理论上是可以满足大部分的业务场景的。不过在没有充分测试的情况下，不建议在交易业务中直接使用。**

## 1.4.3 MQ（事务消息）

举个例子，Bob 向 Smith 转账，那我们到底是先发送消息，还是先执行扣款操作？

好像都可能会出问题。如果先发消息，扣款操作失败，那么 Smith 的账户里面会多出一笔钱。反过来，如果先执行扣款操作，后发送消息，那有可能扣款成功了但是消息没发出去，Smith 收不到钱。除了上面介绍的通过异常捕获和回滚的方式外，还有没有其他的思路呢？

下面以阿里巴巴的 RocketMQ 中间件为例，分析下其设计和实现思路。

**RocketMQ 第一阶段发送 Prepared 消息时，会拿到消息的地址，第二阶段执行本地事物，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。细心的读者可能又发现问题了，如果确认消息发送失败了怎么办？RocketMQ 会定期扫描消息集群中的事物消息，这时候发现了 Prepared 消息，它会向消息发送者确认，Bob 的钱到底是减了还是没减呢？如果减了是回滚还是继续发送确认消息呢？RocketMQ 会根据发送端设置的策略来决定是回滚还是继续发送确认消息**。这样就保证了消息发送与本地事务同时成功或同时失败。如下图：

![分布式系统事务一致性解决方案](https://static001.infoq.cn/resource/image/bc/04/bcd38c3f1444890c60762bccd6752504.png)

优点： **实现了最终一致性，不需要依赖本地数据库事务**。

缺点： 实现难度大，主流MQ不支持，RocketMQ事务消息部分代码也未开源

总结：据笔者的了解，各大知名的电商平台和互联网公司，几乎都是采用**类似的设计思路来实现“最终一致性”的**。这种方式适合的业务场景广泛，而且比较可靠。不过这种方式技术实现的难度比较大。目前主流的开源 MQ（ActiveMQ、RabbitMQ、Kafka）均未实现对事务消息的支持，所以需二次开发或者新造轮子。比较遗憾的是，RocketMQ 事务消息部分的代码也并未开源，需要自己去实现。**



**最大努力通知与可靠消息一致性有什么不同**

- 可靠消息一致性，发起通知方需要保证将消息发出去，并且将消息发送到接收通知方，消息的可靠性由发起通知方保证
- 最大努力通知，发起通知方尽最大的努力将业务处理结果通知为接收通知方，但是消息可能接收不到，此时需要接收通知 方主动调用发起通知方的接口查询业务，通知可靠性关键在于接收通知方

**两者的应用场景**

- 可靠消息一致性关注的是交易过程的事务一致，以异步的方式完成交易
- 最大努力通知关注的是交易后的通知事务，即将交易结果可靠的通知出去





## 1.4.3 Saga框架

 Saga 和 TCC 一样，也是一种补偿事务，但是它没有 try 阶段，而是把分布式事务看作一组本地事务构成的事务链。
　　事务链中的每一个正向事务操作，都对应一个可逆的事务操作。Saga 事务协调器负责按照顺序执行事务链中的分支事务，分支事务执行完毕，即释放资源。如果某个分支事务失败了，则按照反方向执行事务补偿操作。 

Saga模式是一种分布式异步事务，一种最终一致性事务，是一种柔性事务，有两种不同的方式来实现saga事务，最流行的两种方式是：

**一、 事件/编排Choreography：没有中央协调器（没有单点风险）时，每个服务产生并聆听其他服务的事件，并决定是否应采取行动。**

该实现第一个服务执行一个事务，然后发布一个事件。该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布（或不发布）新的事件，当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何Saga参与者听到都意味着事务结束。

![5种分布式事务解决方案优缺点对比](https://imgconvert.csdnimg.cn/aHR0cDovL3AxLnBzdGF0cC5jb20vbGFyZ2UvcGdjLWltYWdlL2QxYWQ1OGMwYTg5MzRlMWE4NWI3NTQyMzg4MThmNzNk)

 

**处理流程：**

订单服务保存新订单，将状态设置为pengding挂起状态，并发布名为ORDER_CREATED_EVENT的事件。

支付服务监听ORDER_CREATED_EVENT，并公布事件BILLED_ORDER_EVENT。

库存服务监听BILLED_ORDER_EVENT，更新库存，并发布ORDER_PREPARED_EVENT。

货运服务监听ORDER_PREPARED_EVENT，然后交付产品。最后，它发布ORDER_DELIVERED_EVENT。

最后，订单服务侦听ORDER_DELIVERED_EVENT并设置订单的状态为concluded完成。

假设库存服务在事务过程中失败了。进行回滚：

库存服务产生PRODUCT_OUT_OF_STOCK_EVENT

订购服务和支付服务会监听到上面库存服务的这一事件：

①支付服务会退款给客户。

②订单服务将订单状态设置为失败。

**优点：**事件/编排是实现Saga模式的自然方式; 它很简单，容易理解，不需要太多的努力来构建，所有参与者都是松散耦合的，因为他们彼此之间没有直接的耦合。如果您的事务涉及2至4个步骤，则可能是非常合适的。

**二、 命令/协调orchestrator：中央协调器负责集中处理事件的决策和业务逻辑排序。**

saga协调器orchestrator以命令/回复的方式与每项服务进行通信，告诉他们应该执行哪些操作。

![5种分布式事务解决方案优缺点对比](https://imgconvert.csdnimg.cn/aHR0cDovL3AzLnBzdGF0cC5jb20vbGFyZ2UvcGdjLWltYWdlLzA2YmRhNGI2YmRjYTRhOWVhODU3ZGQ5MWU1M2NlYmMx)

 

订单服务保存pending状态，并要求订单Saga协调器（简称OSO）开始启动订单事务。

OSO向收款服务发送执行收款命令，收款服务回复Payment Executed消息。

OSO向库存服务发送准备订单命令，库存服务将回复OrderPrepared消息。

OSO向货运服务发送订单发货命令，货运服务将回复Order Delivered消息。

OSO订单Saga协调器必须事先知道执行“创建订单”事务所需的流程(通过读取BPM业务流程XML配置获得)。如果有任何失败，它还负责通过向每个参与者发送命令来撤销之前的操作来协调分布式的回滚。当你有一个中央协调器协调一切时，回滚要容易得多，因为协调器默认是执行正向流程，回滚时只要执行反向流程即可。

Saga 事务是可以保障事务的三个特性：

- 原子性：Saga 协调器可以协调事务链中的本地事务要么全部提交，要么全部回滚。

- 一致性：Saga 事务可以实现最终一致性。

- 持久性：基于本地事务，所以这个特性可以很好实现。


　　但是 **Saga 不保证事务隔离性的**，本地事务提交后变更就对其他事务可见了。其他事务如果更改了已经提交成功的数据，可能会导致补偿操作失败。比如扣款失败，但是钱已经花掉了，业务设计上需要考虑这种场景并从业务设计上规避这种问题。
　　Saga 事务和 TCC 事务一样，对业务实现要求高，要求业务设计实现上遵循三个策略：

- 允许空补偿：网络异常导致事务的参与方只收到了补偿操作指令，因为没有执行过正常操作，因此要进行空补偿。

- 保持幂等性：事务的正向操作和补偿操作都可能被重复触发，因此要保证操作的幂等性。

- 防止资源悬挂：网络异常导致事务的正向操作指令晚于补偿操作指令到达，则要丢弃本次正常操作，否则会出现资源悬挂问题。


　虽然 Saga 和 TCC 都是补偿事务，但是由于提交阶段不同，所以两者也是有不同的：

- Saga 是不完美补偿，补偿操作会留下之前原始事务操作的痕迹，需要考虑对业务上的影响。

- TCC 是完美补偿，补偿操作会彻底清理之前的原始事务操作，用户是感知不到事务取消之前的状态信息的。

- TCC 的事务可以更好的支持异步化，但是 Saga 模式一般在补偿阶段比较适合异步化。


　　Saga 模式非常适合于业务流程长的长事务的场景，实现上对业务侵入低，所以非常适合微服务架构的场景。同时 Saga 采用的是一阶段提交模式，不会对资源长时间加锁，不存在“木桶效应”，所以采用这种模式架构的系统性能高、吞吐高。
　　阿里巴巴的 Seata 开源项目和华为的 ServiceComb 开源项目都支持 Saga 模式

**优点：**

避免服务之间的循环依赖关系，因为saga协调器会调用saga参与者，但参与者不会调用协调器。

集中分布式事务的编排。

只需要执行命令/回复(其实回复消息也是一种事件消息)，降低参与者的复杂性。

在添加新步骤时，事务复杂性保持线性，回滚更容易管理。

如果在第一笔交易还没有执行完，想改变有第二笔事务的目标对象，则可以轻松地将其暂停在协调器上，直到第一笔交易结束。

**缺点：**

1、**缺少预留动作，是优势也是缺点**，导致补偿动作的实现比较麻烦：Ti就是commit，比如一个业务是发送邮件，在TCC模式下，先保存草稿（Try）再发送（Confirm），撤销的话直接删除草稿（Cancel）就行了。而Saga则就直接发送邮件了（Ti），如果要撤销则得再发送一份邮件说明撤销（Ci），实现起来有一些麻烦。

2、saga不保证ACID,只保持**服务的基本可用和数据的最终一致性，事务隔离性差，**要保证数据不被脏读需要在业务上进行相应的逻辑处理

 Apache ServiceComb Saga 是华为开源的微服务应用的数据最终一致性解决方案，已经进入apache项目孵化，是Apache ServiceComb微服务架构中的一员 

# 2.成熟的解决方案

## 2.1 LCN分布式事务框架

1.支持LCN模式

2.支持TXC模式

照快照，然后回滚。缺点：性能低，

3.支持TCC模式

### LCN总结

优点:

- 性能优秀
- 可靠性强
- LCN实现的分布式事务处理模式，编码复杂性和入侵代码量低

缺点:

- 需额外部署tx-manager服务节点
- 由于需要lock资源这种处理方式，如果集中更新某几个热门商品时，LCN的性能衰减量大于TCC模式
- 服务超时时，会造成其他服务的资源被锁住，比如支付服务超时过程中，相关商品库存会一直无法操作
- 不支持SpringCloud 2.0.0及以上版本（目前已通过修改源码实现支持）

## 2.2 阿里的GTS（Seata）

演进历史

1. TXC：Taobao Transaction Constructor，阿里巴巴中间件团队自 2014
   年起启动该项目，以满足应用程序架构从单一服务变为微服务所导致的分布式事务问题。
2. GTS：Global Transaction Service，2016 年 TXC 作为阿里中间件的产品，更名为 GTS 发布。
3. FESCAR：2019 年开始基于 TXC/GTS 开源 FESCAR。
4. 后更名为Seata

1、亮点
相比与其它分布式事务框架，Seata架构的亮点主要有几个：

- 应用层基于SQL解析实现了自动补偿，从而最大程度的降低业务侵入性；
- 将分布式事务中TC（事务协调者）独立部署，负责事务的注册、回滚；
- 通过全局锁实现了写隔离与读隔离。


这些特性的具体实现机制其官网以及github上都有详细介绍，这里不展开介绍。

2、性能损耗
我们看看Seata增加了哪些开销（纯内存运算类的忽略不计）：

一条Update的SQL，则需要全局事务xid获取（与TC通讯）、before image（解析SQL，查询一次数据库）、after image（查询一次数据库）、insert undo log（写一次数据库）、before commit（与TC通讯，判断锁冲突），这些操作都需要一次远程通讯RPC，而且是同步的。

另外undo log写入时blob字段的插入性能也是不高的。 **每条写SQL都会增加这么多开销,粗略估计会增加5倍响应时间**（二阶段虽然是异步的，但其实也会占用系统资源，网络、线程、数据库）。

前后镜像如何生成？
通过druid解析SQL，然后复用业务SQL中的where条件，然后生成Select SQL执行。


3、性价比
为了进行自动补偿，需要对所有交易生成前后镜像并持久化，可是在实际业务场景下，这个是成功率有多高，或者说分布式事务失败需要回滚的有多少比率？这个比例在不同场景下是不一样的，考虑到执行事务编排前，很多都会校验业务的正确性，所以发生回滚的概率其实相对较低。按照二八原则预估， **即为了20%的交易回滚，需要将80%的成功交易的响应时间增加5倍，这样的代价相比于让应用开发一个补偿交易是否是值得？** **值得我们深思。**

业界还有种思路，通过数据库binlog恢复SQL执行前后镜像，这样省去了同步undo log生成记录，减少了性能损耗，同时对业务零侵入，个人感觉是一种更好的方式。


4、全局锁
**1）热点数据**

Seata在每个分支事务中会携带对应的锁信息，在before commit阶段会依次获取锁(因为需要将所有SQL执行完才能拿到所有锁信息，所以放在commit前判断)。相比XA，Seata 虽然在一阶段成功后会释放数据库锁，但一阶段在commit前全局锁的判定也拉长了对数据锁的占有时间，这个开销比XA的prepare低多少需要根据实际业务场景进行测试。全局锁的引入实现了隔离性，但带来的问题就是阻塞，降低并发性，尤其是热点数据，这个问题会更加严重。

**2）回滚锁释放时间**

Seata在回滚时，需要先删除各节点的undo log，然后才能释放TC内存中的锁，所以如果第二阶段是回滚，释放锁的时间会更长。

**3）死锁问题**

**Seata的引入全局锁会额外增加死锁的风险，但如果实现死锁，会不断进行重试，最后靠等待全局锁超时，这种方式并不优雅，也延长了对数据库锁的占有时间。**

「Seata的引入全局锁会额外增加死锁的风险」参考链接：[https://github.com/seata/awesome-seata/blob/master/wiki/en-us/Fescar-AT.md](https://link.zhihu.com/?target=https%3A//github.com/seata/awesome-seata/blob/master/wiki/en-us/Fescar-AT.md)

5、其他问题
1）对于部分采用Seata的应用，如何保证数据不脏读、幻读？

Seata提供了一个@GlobalLock的注解，可以提供轻量级全局锁判定的功能（不生成undo log），但还是需要集成使用Seata。


2）TC在逻辑上是单点，如何做到高可用、高性能还是需要后续版本不断优化。

3）单机多数据源跨服务目前不支持。



### GTS总结

优点:

- 性能优秀(有淘宝双十一作为示例）
- 可靠性强
- 代码入侵性小（相比LCN多一点）
- 支持SpringCloud 2.0.0及以上版本

缺点:

- 无法在本地进行测试
- 只能在阿里云内网使用，或者购买专有云

## 2.3 Atomikos事务

优点：

\1.  全面崩溃 / 重启恢复

\2. 兼容标准的SUN公司JTA API

\3. 嵌套事务

\4. 为XA和非XA提供内置的JDBC适配器

缺点：

\1.  Atomikos从池里取得connection时，每次都会去进行select test，这个对获取连接的影响很大，取消这个测试，TPS大概能提高近1倍；

\2.  Atomilos对池中connection的管理效率随着连接数的上升，呈现指数级的下降，测试环境中，连接最大配置为300，但实际上最大值没有超过70，线程dump发现连接池管理对象上存在激烈的锁竞争，导致很多线程等待前面的线程释放锁对象；



\3.  由于Atomikos支持JTA事务，而c3p0则不支持，这导致atomikos在获取connection时，首先需要从线程上下文去检索是否已经存在着connection，这个检测从atomikos的实现上看，会遍历连接池中所有connection对象，所以当连接数上升时，连接池的效率显著下降



## 2.4分布式事务Saga框架

## 2.5 ByteTCC

 # 3 **分布式事务的取舍**

 严格的ACID事务对隔离性的要求很高，在事务执行中必须将所有的资源锁定， 对于长事务来说，整个事务期间对数据的独占，将严重影响系统并发性能。因此，在高并发场景中，对ACID的部分特性进行放松从而提高性能，这便产生了BASE柔性事务。柔性事务的理念则是通过业务逻辑将互斥锁操作从资源层面上移至业务层面。通过放宽对强一致性要求，来换取系统吞吐量的提升。另外提供自动的异常恢复机制，可以在发生异常后也能确保事务的最终一致。

基于XA的分布式事务如果要严格保证ACID，实际需要事务隔离级别为SERLALIZABLE。

由上可见柔性事务需要应用层进行参与，因此这类分布式事务框架一个首要的功能就是怎么最大程度降低业务改造成本，然后就是尽可能提高性能（响应时间、吞吐），最好是保证隔离性。

一个好的分布式事务框架应用尽可能满足以下特性：



- 业务改造成本低；
- 性能损耗低；
- 隔离性保证完整。


但如同CAP，这三个特性是相互制衡的，往往只能满足其中两个，我们可以画一个三角约束：



![img](https://picb.zhimg.com/80/v2-f353a284ea471ba2752cbda8da9945e2_720w.jpg)



基于业务补偿的Saga满足1.2；TCC满足2.3；Seata满足1.3。

当然如果我们要自己设计一个分布式事务框架，还需要考虑很多其它特性，在明确目标场景偏好后进行权衡取舍，这些特性包括但不限于以下：



- 业务侵入性（基于注解、XML，补偿逻辑）；
- 隔离性（写隔离/读隔离/读未提交，业务隔离/技术隔离）；
- TM/TC部署形态（单独部署、与应用部署一起）；
- 错误恢复（自动恢复、手动恢复）；
- 性能（回滚的概率、付出的代价,响应时间、吞吐）；
- 高可用（注册中心、数据库）；
- 持久化（数据库、文件、多副本一致算法）；
- 同步/异步（2PC执行方式）；
- 日志清理(自动、手动)；
- ......


**结语**

分布式事务一直是业界难题，难在于CAP定理，在于分布式系统8大错误假设，在于FLP不可能原理，在于我们习惯于单机事务ACID做对比。无论是数据库领域XA、Google percolator或Calvin模型，还是微服务下Saga、TCC、可靠消息等方案，都没有完美解决分布式事务问题，它们不过是各自在性能、一致性、可用性等方面做取舍，寻求某些场景偏好下的权衡。

 ![img](http://img.blog.itpub.net/blog/2019/12/30/830db1a8b8a0e76c.png?x-oss-process=style/bb) 









