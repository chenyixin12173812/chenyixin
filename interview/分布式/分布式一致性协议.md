# 0 分布式一致性协议

- consistent hashing [with virtual node]：一致性哈希，数据分布
- vector clock：时钟向量，多版本数据修改
- Quorum W+R>N [with vector clock]：抽屉原理，数据一致性的另一种解决方案。时钟向量，多版本数据修改。
- Merkle tree [with anti-entropy]：数据复制
- MVCC：copy-on-write与snapshot
- 2PC/3PC：分布式事务
- Paxos：强一致性协议
- Symmetry and Decentralization：对称性和去中心化。对称性(symmetry)简化了系统的配置和维护。去中心化是对对称性的延伸，可以避免master单点，同时方便集群scale out。
- Map-Reduce：分而治之；移动数据不如移动计算。将计算尽量调度到与存储节点在同一台物理机器上的计算节点上进行，这称之为本地化计算。本地化计算是计算调度的一种重要优化。
- Gossip协议：节点管理
- Lease机制



# 1 Lease机制  [liːs]

https://blog.csdn.net/kailuan2zhong/article/details/87628597

 https://blog.csdn.net/u012428012/article/details/80572071 

 **Lease 机制是最重要的分布式协议**，广泛应用于各种实际的分布式系统中。即使在某些系统中相似的设计不被称为 lease。



# 1.4特点：

 1.Lease是颁发者对一段时间内数据一致性的承诺；

 2.颁发者发出Lease后，不管是否被接收，只要Lease不过期，颁发者都会按照协议遵守承诺；

 3.Lease的持有者只能在Lease的有效期内使用承诺，一旦Lease超时，持有者需要放弃执行，重新申请Lease 

4 颁发者一旦发出 lease，则无论接受方是否收到，也无论后续接收方处于何种状态，只要 lease 不过期，颁发者一定严守承诺；另一方面，接收方在 lease的有效期内可以使用颁发者的承诺，但一旦 lease 过期，接收方一定不能继续使用颁发者的承诺。

5Lease 机制具有很高的容错能力。首先，通过引入有效期，Lease 机制能否非常好的容错网络异常。再者，Lease 机制能较好的容错节点宕机。最后，lease 机制不依赖于存储。

6 Lease 机制依赖于有效期，这就要求颁发者和接收者的时钟是同步的。对于这种时钟不同步，实践中的通常做法是将颁发者的有效期设置得比接收者的略大，只需大过时钟误差就可以避免对 lease 的有效性的影响

## 1.5 lease 的有效期时间选择

如果 lease 的时长太短，例如 1s，一旦出现网络抖动 lease 很容易丢失，从而造成节点失去 lease，使得依赖 lease 的服务停止；如果 lease 的时长太大，例如 1 分钟，则一旦接受者异常，颁发者需要过长的时间收回 lease 承诺。例如，使用 lease 确定节点状态时，若 lease 时间过短，有可能造成网络瞬断时节点收不到 lease 从而引起服务不稳定，若 lease 时间过长，则一旦某节点宕机异常，需要较大的时间等待 lease 过期才能发现节点异常。

工程中，常选择的 lease 时长是 **10 秒级别**，这是一个经过验证的经验值，实践中可以作为参考并综合选择合适的时长。

## 1.6存在的问题和解决办法

### 1.6.1 服务器修改元数据时，需要阻塞所有的读请求，此时服务器不能发出新的Lease。以防止新发出的Lease保证的数据与服务器刚才修改的数据不一致。 

解决方法：读请求到来时，直接返回数据，不颁发Lease ，让客户端重试。

### 1.6.2 服务器需要等待直至所有的Client的Lease都过期后，才颁发新“修改”后的Lease。

因此，此时服务器上的数据修改了，生成了一个新的Lease版本，需要等到Client上所有的老Lease过期后，该新Lease版本才能颁布给Client。 

解决方法：**服务器主动通知持久Lease的Client放弃当前的Lease，并请求新Lease**

### 1.6.3 双主问题

通过一个例子来讨论这个问题：在一个 primary-secondary 架构的系统中，有三个节点 A、B、C 互为副本，其中有一个节点为 primary，且同一时刻只能有一个 primary 节点。另有一个节点 Q 负责判断节点 A、B、C的状态，一旦 Q 发现 primary 异常，节点 Q 将选择另一个节点作为 primary。假设最开始时节点 A为 primary，B、C 为 secondary。节点 Q 需要判断节点 A、B、C 的状态是否正常。 节点 A、B、C 可以周期性的向 Q 发送心跳信息，如果节点 Q 超过一段时间收不到某个节点的心跳则认为这个节点异常。这种方法的问题是假如节点 Q 收不到节点 A 的心跳，除了节点 A 本身的异常外，也有可能是因为节点 Q 与节点 A 之间的网络中断导致的。在工程实践中，更大的可能性不是网络中断，而是节点 Q 与节点 A 之间的网络拥塞造成的所谓“闪断”，“闪断”往往很快可以恢复。另一种原因甚至是节点 Q 的机器异常，以至于处理节点 A 的心跳被延迟了，以至于节点 Q 认为节点 A 没有发送心跳。假设节点 A 本身工作正常，但 Q 与节点 A 之间的网络暂时中断，节点 A 与节点 B、C 之间的网络正常。此时节点 Q 认为节点 A 异常，重新选择节点 B 作为新的 primary，并通知节点 A、B、C 新的 primary 是节点 B。由于节点 Q 的通知消息到达节点 A、B、C 的顺序无法确定，假如先到达 B，则在这一时刻，系统中同时存在两个工作中的 primary，一个是 A、另一个是 B。假如此时 A、B 都接收外部请求并与 C 同步数据，会产生严重的数据错误。上述即所谓“双主”问题。

### 双主问题的解决

 由中心节点向其他节点发送 lease，若某个节点持有有效的 lease，则认为该节点正常可以提供服务。用于例 2.3.1 中，节点 A、B、C 依然周期性的发送 heart beat 报告自身状态，节点 Q 收到 heart beat后发送一个 lease，表示节点 Q 确认了节点 A、B、C 的状态，并允许节点在 lease 有效期内正常工作。节点 Q 可以给 primary 节点一个特殊的 lease，表示节点可以作为 primary 工作。一旦节点 Q 希望切换新的 primary，则只需等前一个 primary 的 lease 过期，则就可以安全的颁发新的 lease 给新的primary 节点，而不会出现“双主”问题 

 **在实际系统中，若用一个中心节点作为配置中心发送lease也有很大的风险。实际系统总是使用多个中心节点互为副本，成为一个小的集群，该小集群具有高可用性，对外提供颁发lease的功能。chubby和zookeeper都是基于这样的设计**。 

## 总结



# 2 Quorum 机制

## 2.1  **Quorum机制介绍** 

 在分布式系统中有个CAP理论，对于P（分区容忍性）而言，是实际存在 从而无法避免的。因为，分布系统中的处理不是在本机，而是网络中的许多机器相互通信，故网络分区、网络通信故障问题无法避免。因此，只能尽量地在C 和 A 之间寻求平衡。对于数据存储而言，**为了提高可用性（Availability），采用了副本备份** 。 但是，问题来了，当需要修改数据时，就需要更新**所有**的副本数据，这样才能保证数据的一致性（Consistency）。因此，就需要在 C(Consistency) 和 A(Availability) 之间权衡 。

在介绍Quorum之前，先看一个极端的情况：WARO机制

 WARO(Write All Read one)是一种简单的副本控制协议，当Client请求向某副本写数据时(更新数据)，只有当所有的副本都更新成功之后，这次写操作才算成功，否则视为失败。 这里可以看出两点：①写操作很脆弱，因为只要有一个副本更新失败，此次写操作就视为失败了。②读操作很简单，因为，所有的副本更新成功，才视为更新成功，从而保证所有的副本一致。这样，只需要读任何一个副本上的数据即可。**假设有N个副本，N-1个都宕机了，剩下的那个副本仍能提供读服务；但是只要有一个副本宕机了，写服务就不会成功** 

WARO牺牲了更新服务的可用性，最大程度地增强了读服务的可用性。而Quorum就是更新服务和读服务之间进行一个折衷。

Quorum机制是“抽屉原理”的一个应用。定义如下：假设有N个副本，更新操作wi 在W个副本中更新成功之后，才认为此次更新操作wi 成功。称成功提交的更新操作对应的数据为：“成功提交的数据”。对于读操作而言，至少需要读R个副本才能读到此次更新的数据。**其中，W+R>N ，即W和R有重叠。**一般，W+R=N+1

![img](data:image/png;base64,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)

假设系统中有5个副本，W=3，R=3。初始时数据为(V1，V1，V1，V1，V1）--成功提交的版本号为1

**当某次更新操作在3个副本上成功后，就认为此次更新操作成功**。数据变成：(V2，V2，V2，V1，V1）--成功提交后，版本号变成2

因此，最多只需要读3个副本，一定能够读到V2(此次更新成功的数据)。而在后台，可对剩余的V1 同步到V2，而不需要让Client知道。

**Quorum机制分析**

①Quorum机制无法保证强一致性

所谓强一致性就是：任何时刻任何用户或节点都可以读到**最近一次成功提交的副本数据**。强一致性是程度最高的一致性要求，也是实践中最难以实现的一致性。

 因为，仅仅通过Quorum机制无法确定最新已经成功提交的版本号。

比如，上面的V2 成功提交后（已经写入W=3份），尽管读取3个副本时一定能读到V2，如果刚好读到的是(V2，V2，V2），则此次读取的数据是最新成功提交的数据，因为W=3，而此时刚好读到了3份V2。如果读到的是（V2，V1，V1），则无法确定是一个成功提交的版本，还需要继续再读，直到读到V2的达到3份为止，这时才能确定V2 就是已经成功提交的最新的数据。

1）如何读取最新的数据？---在已经知道最近成功提交的数据版本号的前提下，最多读R个副本就可以读到最新的数据了。

2）如何确定 最高版本号 的数据是一个成功提交的数据？---继续读其他的副本，直到读到的 最高版本号副本 出现了W次。

 

②基于Quorum机制选择 primary

中心节点(服务器)读取R个副本，**选择R个副本中版本号最高的副本作为新的primary**。

新选出的primary**不能**立即提供服务，还需要与至少与W个副本*完成同步*后，才能提供服务---为了保证Quorum机制的规则：W+R>N

至于如何处理同步过程中冲突的数据，则需要视情况而定。

 比如，(V2，V2，V1，V1，V1），R=3，如果读取的3个副本是：(V1，V1，V1)则高版本的 V2需要丢弃。

如果读取的3个副本是（V2，V1，V1），则低版本的V1需要同步到V2

 

## 2.2 Quorum机制应用实例

**HDFS高可用性实现**

 HDFS的运行依赖于NameNode，如果NameNode挂了，那么整个HDFS就用不了了，因此就存在单点故障(single point of failure)；其次，如果需要升级或者维护停止NameNode，整个HDFS也用不了。为了解决这个问题，采用了QJM机制(Quorum Journal Manager)实现HDFS的HA（High Availability）。注意，一开始采用的“共享存储”机制，关于共享存储机制的不足，[可参考：（还提到了QJM的优点）](http://blog.cloudera.com/blog/2012/10/quorum-based-journaling-in-cdh4-1/)

```
In a typical HA cluster, two separate machines are configured as NameNodes.
At any point in time, exactly one of the NameNodes is in an Active state, and the other is in a Standby state. 
The Active NameNode is responsible for all client operations in the cluster, while the Standby is simply acting as a slave, maintaining enough state to provide a fast failover if necessary.
```

为了实现HA，需要两台NameNode机器，一台是Active NameNode，负责Client请求。另一台是StandBy NameNode，负责与Active NameNode**同步数据**，从而快速 failover。

那么，这里就有个问题，StandBy NameNode是如何同步Active NameNode上的数据的呢？主要同步是哪些数据呢？

数据同步就用到了Quorum机制。同步的数据 主要是[EditLog](http://blog.cloudera.com/blog/2014/03/a-guide-to-checkpointing-in-hadoop/)。

```
In order for the Standby node to keep its state synchronized with the Active node, 
both nodes communicate with a group of separate daemons called “JournalNodes” (JNs). 
```

数据同步用到了一个第三方”集群“：Journal Nodes。Active NameNode 和 StandBy NameNode 都与JournalNodes通信，从而实现同步。

''''''''''''''''''''''''''''''''''

每次 NameNode 写 EditLog 的时候，除了向本地磁盘写入 EditLog 之外，也会并行地向 JournalNode 集群之中的每一个 JournalNode 发送写请求，只要大多数 (majority) 的 JournalNode 节点返回成功就认为向 JournalNode 集群写入 EditLog 成功。如果有 2N+1 台 JournalNode，那么根据大多数的原则，最多可以容忍有 N 台 JournalNode 节点挂掉。

**这就是：Quorum机制。每次写入JournalNode的机器数目达到大多数(W)时，就认为本次写操作成功了。**

'''''''''''''''''''''''''''''''''

这样，每次对Active NameNode中的元数据进行修改时，都会将该修改写入JournalNode集群的大多数机器中，才认为此次修改成功。

当Active NameNode宕机时，StandBy NameNode 向JournalNode同步EditLog，从而保证了HA。

```
Active NameNode 向 JournalNode 集群提交 EditLog 是同步的
但 Standby NameNode 采用的是定时从 JournalNode 集群上同步 EditLog 的方式，那么 Standby NameNode 内存中文件系统镜像有很大的可能是落后于 Active NameNode 的，
所以 Standby NameNode 在转换为 Active NameNode 的时候需要把落后的 EditLog 补上来。
```

具体的同步过程可参考： [Hadoop NameNode 高可用 (High Availability) 实现解析](https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/)

 

```
In order to provide a fast failover, it is also necessary that the Standby node have up-to-date information
regarding the location of blocks in the cluster. In order to achieve this, the DataNodes are configured with the location of both NameNodes, 
and send block location information and heartbeats to both.
```

此外，为了**实现快速failover**，StandBy NameNode 需要实时地与各个DataNode通信以获得每个**数据块的地址**信息。为咐要这样？

因为：每个数据块的地址信息不属于“元信息”，并没有保存在 FsImage、CheckPoint...，这是因为地址信息变化比较大。比如说，一台DataNode下线了，其上面的数据块地址信息就全无效了，而且为了达到指定的数据块“复制因子”，还需要在其他机器上复制该数据块。

而快速failover，是指Active NameNode宕机后，StandBy NameNode立即就能提供服务。因此，DataNode也需要实时向 StandBy NameNode 发送 block report

另外，还有手动failover 和 自动 failover，自动failover需要Zookeeper的支持，具体可参考官网：[HDFS High Availability Using the Quorum Journal Manager](https://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html)

 

**如何避免“Split Brain”(脑裂)问题？**

Split Brain 是指在同一时刻有两个认为自己处于 Active 状态的 NameNode。

```
when a NameNode sends any message (or remote procedure call) to a JournalNode, it includes its epoch number as part of the request. 
Whenever the JournalNode receives such a message, it compares the epoch number against a locally stored value called the promised epoch. 
If the request is coming from a newer epoch, then it records that new epoch as its promised epoch.
 If instead the request is coming from an older epoch, then it rejects the request. This simple policy avoids split-brain
```

**简单地理解如下：每个NameNode 与 JournalNodes通信时，需要带一个 epoch numbers(epoch numbers 是唯一的且只增不减)。而每个JournalNode 都有一个本地的promised epoch。拥有值大的epoch numbers 的NameNode会使得JournalNode提升自己的 promised epoch，从而占大多数，而epoch numbers较小的那个NameNode就成了少数派(Paxos协议思想)**。

从而**epoch number值大的NameNode才是真正的Active NameNode**，拥有写JournalNode的权限。注意：（任何时刻只允许一个NameNode拥有写JournalNode权限）

```
when using the Quorum Journal Manager, only one NameNode will ever be allowed to write to the JournalNodes,
so there is no potential for corrupting the file system metadata from a split-brain scenario.
```



# 3raft协议

etcd和consul

 https://docs.qq.com/doc/DY0VxSkVGWHFYSlZJ 

 https://www.jianshu.com/p/ddbe4209be0f 

 **一、复制状态机(replicated state machine)** 

 一个分布式的复制状态机系统由多个复制单元组成，每个复制单元均是一个状态机，它的状态保存在一组状态变量中，状态机的变量只能通过外部命令来改变。简单理解的话，可以想象成是一组服务器，每个服务器是一个状态机，服务器的运行状态只能通过一行行的命令来改变。每一个状态机存储一个包含一系列指令的日志，严格按照顺序逐条执行日志中的指令，如果所有的状态机都能按照相同的日志执行指令，那么它们最终将达到相同的状态。因此，在复制状态机模型下，只要保证了操作日志的一致性，我们就能保证该分布式系统状态的一致性。 

 ![img](https://pic2.zhimg.com/80/v2-d93d7390b649a171d3e5b649ef73420d_720w.jpg) 

在上图中，服务器中的一致性模块(Consensus Modle)接受来自客户端的指令，并写入到自己的日志中，然后通过一致性模块和其他服务器交互，确保每一条日志都能以相同顺序写入到其他服务器的日志中，即便服务器宕机了一段时间。一旦日志命令都被正确的复制，每一台服务器就会顺序的处理命令，并向客户端返回结果。

为了让一致性协议变得简单可理解，Raft协议主要使用了两种策略。一是将复杂问题进行分解，在Raft协议中，一致性问题被分解为：**leader election、log replication、safety**三个简单问题；二是减少状态空间中的状态数目。

**Raft一致性算法**

在Raft体系中，有一个强leader，由它全权负责接收客户端的请求命令，并将命令作为日志条目复制给其他服务器，在确认安全的时候，将日志命令提交执行。当leader故障时，会选举产生一个新的leader。在强leader的帮助下，Raft将一致性问题分解为了三个子问题：

1. leader选举：当已有的leader故障时必须选出一个新的leader。
2. 日志复制：leader接受来自客户端的命令，记录为日志，并复制给集群中的其他服务器，并强制其他节点的日志与leader保持一致。
3. 安全safety措施：通过一些措施确保系统的安全性，如确保所有状态机按照相同顺序执行相同命令的措施。

 一个Raft集群拥有多个服务器，典型值是5，这样可以容忍两台服务器出现故障。服务器可能会处于如下三种角色：leader、candidate、follower，正常运行的情况下，会有一个leader，其他全为follower，follower只会响应leader和candidate的请求，而客户端的请求则全部由leader处理，即使有客户端请求了一个follower也会将请求重定向到leader。c**andidate代表候选人，出现在选举leader阶段，选举成功后candidate将会成为新的leader**。可能出现的状态转换关系如下图： 

 ![img](https://pic3.zhimg.com/80/v2-b0b6674feec00e7e1fabdca312aaaa56_720w.jpg) 

 从状态转换关系图中可以看出，集群刚启动时，所有节点都是follower，之后在time out信号的驱使下，follower会转变成candidate去拉取选票，获得大多数选票后就会成为leader，这时候如果其他候选人发现了新的leader已经诞生，就会自动转变为follower；而如果另一个time out信号发出时，还没有选举出leader，将会重新开始一次新的选举。可见，time out信号是促使角色转换得关键因素，类似于操作系统中得中断信号 。

**任期（term）**

Raft 算法将时间划分成为任意不同长度的任期（term）。任期用连续的数字进行表示。每一个任期的开始都是一次选举（election），一个或多个候选人会试图成为领导人。如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始另一个任期，并且立刻开始下一次选举。Raft 算法保证在给定的一个任期最多只有一个领导人。

 ![img](https://pic1.zhimg.com/80/v2-fe29432971c9fbe72eb644ffcfa01290_720w.jpg) 

server之间的交流是通过RPC进行的。只需要实现两种RPC就能构建一个基本的Raft集群：

- **RequestVote RPC：它由选举过程中的candidate发起，用于拉取选票**
- **AppendEntries RPC：它由leader发起，用于复制日志或者发送心跳信号。**

它们的定义如下图所示：

![img](https://pic4.zhimg.com/80/v2-449a1ca480a17047b56f2af41bc714f7_720w.jpg)

![img](https://pic3.zhimg.com/80/v2-e7004caff5fc03a1edc3df27c9658056_720w.jpg)





**leader选举过程**

Raft通过心跳机制发起leader选举。节点都是从follower状态开始的，如果收到了来自leader或candidate的RPC，那它就保持follower状态，避免争抢成为candidate。Leader会发送空的AppendEntries RPC作为心跳信号来确立自己的地位，如果follower一段时间(election timeout)没有收到心跳，它就会认为leader已经挂了，发起新的一轮选举。

选举发起后，一个follower会增加自己的当前term编号并转变为candidate。它会首先投自己一票，然后向其他所有节点并行发起RequestVote RPC，之后candidate状态将可能发生如下三种变化:

- **赢得选举,成为leader**: 如果它在一个term内收到了大多数的选票，将会在接下的剩余term时间内称为leader，然后就可以通过发送心跳确立自己的地位。(每一个server在一个term内只能投一张选票，并且按照先到先得的原则投出)
- **其他server成为leader：**在等待投票时，可能会收到其他server发出AppendEntries RPC心跳信号，说明其他leader已经产生了。这时通过比较自己的term编号和RPC过来的term编号，如果比对方大，说明leader的term过期了，就会拒绝该RPC,并继续保持候选人身份; 如果对方编号不比自己小,则承认对方的地位,转为follower.
- **选票被瓜分,选举失败:** 如果没有candidate获取大多数选票, 则没有leader产生, candidate们等待超时后发起另一轮选举. 为了防止下一次选票还被瓜分,必须采取一些额外的措施, raft采用随**机election timeout的机制防止选票被持续瓜分。通过将timeout随机设为一段区间上的某个值, 因此很大概率会有某个candidate率先超时然后赢得大部分选票**.

### 3.3.1日志复制过程

一旦leader被选举成功，就可以对客户端提供服务了。客户端提交每一条命令都会被按顺序记录到leader的日志中**，每一条命令都包含term编号和顺序索引，然后向其他节点并行发送AppendEntries RPC用以复制命令(如果命令丢失会不断重发)，当复制成功也就是大多数节点成功复制后，leader就会提交命令**，即执行该命令并且将执行结果返回客户端，raft保证已经提交的命令最终也会被其他节点成功执行。leader会保存有当前已经提交的最高日志编号。顺序性确保了相同日志索引处的命令是相同的，而且之前的命令也是相同的**。当发送AppendEntries RPC时，会包含leader上一条刚处理过的命令，接收节点如果发现上一条命令不匹配，就会拒绝执行**。

###### 接受命令的过程：



```undefined
1.  领导者接受客户端请求；

2.  领导者把指令追加到日志；

3.  发送AppendEntries RPC到追随者；

4.  领导者收到大多数追随者的确认后，领导者Commit该日志，把日志在状态机中执行，并返回结果给客户端；
```

###### 提交过程：



```undefined
1.  在下一个心跳阶段，领导者再次发送AppendEntries RPC给追随者，日志已经commited；

2.  追随者收到Commited日志后，将日志在状态机中执行。
```





在这个过程中可能会出现一种特殊故障：如果leader崩溃了，它所记录的日志没有完全被复制，会造成日志不一致的情况，follower相比于当前的leader可能会丢失几条日志，也可能会额外多出几条日志，这种情况可能会持续几个term。如下图所示：

![img](https://pic4.zhimg.com/80/v2-0f386bc51d6cd36d3e654ba6ec1c21b7_720w.jpg)

在上图中，框内的数字是term编号，a、b丢失了一些命令，c、d多出来了一些命令，e、f既有丢失也有增多，这些情况都有可能发生。比如f可能发生在这样的情况下：f节点在term2时是leader，在此期间写入了几条命令，然后在提交之前崩溃了，在之后的term3中它很快重启并再次成为leader，又写入了几条日志，在提交之前又崩溃了，等他苏醒过来时新的leader来了，就形成了上图情形。**在Raft中，leader通过强制follower复制自己的日志来解决上述日志不一致的情形，那么冲突的日志将会被重写**。为了让日志一致，**先找到最新的一致的那条日志(如f中索引为3的日志条目)**，然后把follower之后的日志全部删除，leader再把**自己在那之后的日志一股脑推送给follower，这样就实现了一致**。而寻找该条日志，可以通过AppendEntries RPC，该RPC中包含着下一次要执行的命令索引，如果能和follower的当前索引对上，那就执行，否则拒绝，然后leader将会逐次递减索引，直到找到相同的那条日志。

然而这样也还是会有问题，比**如某个follower在leader提交时宕机了，也就是少了几条命令，然后它又经过选举成了新的leader，这样它就会强制其他follower跟自己一样，使得其他节点上刚刚提交的命令被删除，导致客户端提交的一些命令被丢失了**。Raft通过为选举过程添加一个限制条件，解决了上面提出的问题，该限制确保leader包含之前term已经提交过的所有命令。**Raft通过投票过程确保只有拥有全部已提交日志的candidate能成为leader**。由于candidate为了拉选票需要通过RequestVote RPC联系其他节点**，而之前提交的命令至少会存在于其中某一个节点上,因此只要candidate的日志至少和其他大部分节点的一样新就可以了**, follower如果收到了不如自己新的candidate的RPC,就会将其丢弃.

**还可能会出现另外一个问题, 如果命令已经被复制到了大部分节点上,但是还没来的及提交就崩溃了,这样后来的leader应该完成之前term未完成的提交. Raft通过让leader统计当前term内还未提交的命令已经被复制的数量是否半数以上, 然后进行提交**.





领导人通过强制追随者们复制它的日志来处理日志的不一致。这就意味着，在追随者上的冲突日志会被领导者的日志覆盖。（下面几节会证明为什么这么做是安全的）

为了使得追随者的日志同自己的一致，领导人需要找到追随者同它的日志一致的地方，然后删除追随者在该位置之后的条目，然后将自己在该位置之后的条目发送给追随者。这些操作都在 AppendEntries RPC 进行一致性检查时完成。

***领导者永远不会覆盖自己已经存在的日志条目；\***

***日志永远只有一个流向：从领导者到追随者；\***

### 3.3.2 选举约束

- master选举最终安全性目标： ***被选举出来的leader必须要包含所有已经提交的entries\***
   如leader针对复制过半的entry提交了，但是某些follower可能还没有这些entry，当leader挂了，该follower如果被选举成leader的时候，就可能会覆盖掉了上述的entry了，造成不一致的问题，所以新选出来的leader必须要满足上述约束。
- raft简单实现：只要当前server的log比半数server的log都新就可以，具体到每一个node的比对就是上述说的***“谁的lastLog的term越大谁越新，如果term相同，谁的lastLog的index越大谁越新”\***

正是这个实现并不能完全实现约束，才会产生下面4.3.3中另外一个问题，一会会详细案例来说明这个问题， 我们先来看看到现在为止整个系统是安全的么？

###### leader挂掉时机：



```bash
a、 尚未打log： 完全无影响

b、 自己写了log， 但还未发requestRPC ：不会对client返回处理成功， 但是会在自己服务器中保留一份log， 未来新选的master会刷掉这份log（也就是3.3.1中设置的条件）

c、 发了requestRPC 尚未commit ： 收到消息的follow都会保留一份log， 但因为还未commit 所以不会对client返回处理成功， 但是此处是存有疑问的。

d、 commit 之后： 已经commit了， 也就是说client认为已经处理成功了， 此时挂了的话剩下的机器中有一多半都已经保存了数据log， 他们竞争master时也会保留已经提交的数据（参见3.3..2）。
```

最终会剩下一个问题， 也就是c中新接手的master怎么处理之前尚未commit的数据， 再来看之前的选举限制：

***“lastLog的term越大谁越新，如果term相同，谁的lastLog的index越大谁越新”\***

在这种情况下我们选举master其实只是关注了log新旧， 并没有关注commit与否， 在3.3.3 中例子可以发现现在的约束是无法实现master选举的最终安全性目标的

### 3.3.3 如何处理任期之前的日志条目

在Raft算法中，当一个日志被安全的复制到绝大多数的机器上面，即AppendEntries RPC在绝大多数服务器正确返回了，那么这个日志就是被提交了，然后领导者会更新commit index。

![img](https:////upload-images.jianshu.io/upload_images/3271185-6b70e949255c9e86.png?imageMogr2/auto-orient/strip|imageView2/2/w/800/format/webp)

image.png

详细解释如下：



```swift
a场景：s1是leader,此时处于term2，并且将index为2的entry复制到s2上

b场景：s1挂了，s5利用s3,s4,s5当选为leader，处于term3,s5在index为2的位置上接收到了新的entry

c场景：s5挂了，s1当选为leader，处于term4，s1将index为2,term为2的entry复制到了s3上，此时已经满足过半数了
```

***重点就在这里：此时处于term4,但是之前处于term2的entry达到过半数了，s1是提交该entry呢还是不提交呢？\***

- 假如s1提交的话，则index为2，term为2的entry就被应用到状态机中了，是不可改变了，此时s1如果挂了，来到term5，s5是可以被选为leader的，因为按照之前的log比对策略来说，s5的最后一个log的term是3比s2 s3 s4的最后一个log的term都大。一旦s5被选举为leader，即d场景，s5会复制index为2,term为3的entry到上述机器上，这时候就会造成之前s1已经提交的index为2的位置被重新覆盖，因此违背了一致性。
- 假如s1不提交，而是等到term4中有过半的entry了，然后再将之前的term的entry一起提交（这就是所谓的间接提交，即使满足过半，但是必须要等到当前term中有过半的entry才能跟着一起提交），即处于e场景，s1此时挂的话，s5就不能被选为leader了，因为s2 s3的最后一个log的term为4比s5的3大，所以s5获取不到投票，进而s5就不可能去覆盖上述的提交

从这个案例中我们得到的一个新约束就是：

***当前term的leader不能“直接”提交之前term的entries 必须要等到当前term有entry过半了，才顺便一起将之前term的entries进行提交\***

所以raft靠着这2个约束来进一步保证一致性问题。

再来仔细分析这个案例，其问题就是出在：***上述leader选举上，s1如果在c场景下将index为2、term为2的entry提交了，此时s5也就不包含所有的commitLog了，但是s5按照log最新的比较方法还是能当选leader。\***

那就是说log最新的比较方法并不能保证2中的选举约束即
 ***被选举出来的leader必须要包含所有已经提交的entries\***
 所以可以理解为：正是由于上述选举约束实现上的简单实现并不靠谱， 才导致又加了这么一个不能直接提交之前term的entries的约束。

##### 3.3.4 安全性论证讨论

###### Leader Completeness： 如果一个entry被提交了，那么在之后的leader中，必然存在该entry。

经过上述2个约束，就能得出Leader Completeness结论。正是由于上述***“不能直接提交之前term的entries”\***的约束，所以任何一个entry的提交必然存在当前term下的entry的提交。那么此时所有的server中有过半的server都含有当前term(也是当前最大的term)的entry，假设serverA将来会成为leader，此时serverA的lastlog的term必然是不大于当前term的，它要想成为leader，即和其他server pk 谁的log最新，必然是需要满足log的index比他们大的，所以必然含有已提交的entry。

##### client端

在client看来如果client发送一个请求，leader返回ok响应，那么client认为这次请求成功执行了，那么这个请求就需要被真实的落地，不能丢。

如果leader没有返回ok，那么client可以认为这次请求没有成功执行，之后可以通过重试方式来继续请求。

###### leader挂

一旦你给客户端回复OK的话，然后挂了，那么这个请求对应的entry必须要保证被应用到状态机，即需要别的leader来继续完成这个应用到状态机。

一旦leader在给客户端答复之前挂了，那么这个请求对应的entry就不能被应用到状态机了，如果被应用到状态机就造成客户端认为执行失败，但是服务器端缺持久化了这个请求结果，这就有点不一致了。

这个原则同消息队列也是一致的。再来说说什么叫消息队列的消息丢失（很多人还没真正搞明白这个问题）：client向服务器端发送消息，服务器端回复OK了，之后因为服务器端自己的内部机制的原因导致该消息丢失了，这种情况才叫消息队列的消息丢失。如果服务器端没有给你回复OK，那么这种情况就不属于消息队列丢失消息的范畴。

再来看看raft是否能满足这个原则：

- leader在某个entry被过半复制了，认为可以提交了，就应用到状态机了，然后向客户端回复OK，之后leader挂了，是可以保证该entry在之后的leader中是存在的
- leader在某个entry被过半复制了，然后就挂了，即没有向客户端回复OK，raft的机制下，后来的leader是可能会包含该entry并提交的，或可能直接就覆盖掉了该entry。如果是前者，则该entry是被应用到了状态机中，那么此时就出现一个问题：client没有收到OK回复，但是服务器端竟然可以成功保存了， 为了掩盖这种情况，就需要在客户端做一次手脚，即客户端对那么没有回复OK的都要进行重试，客户端的请求都带着一个唯一的请求id，重试的时候也是拿着之前的请求id去重试的服务器端发现该请求id已经存在提交log中了，那么直接回复OK，如果不在的话，那么再执行一次该请求。

###### follower挂

follower挂了，只要leader还满足过半条件就一切正常。他们挂了又恢复之后，leader是会不断进行重试的，该follower仍然是能恢复正常的

follower在接收AppendEntries RPC的时候是幂等操作



## 3.4集群成员变更

集群成员的变更和成员的宕机与重启不同，因为前者会修改成员个数进而影响到领导者的选取和决议过程，因为在分布式系统这对于majority这个集群中成员大多数的概念是极为重要的。

 两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。 

两阶段方法保证安全性：

- 在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致***（joint consensus）\***；
   一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合。
- 共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程中依然响应服务器请求。

一个领导人接收到一个改变配置从 C-old 到 C-new 的请求，他会为了共同一致存储配置（图中的 C-old,new），以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定。**领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。当C-old,new日志条目被提交以后，领导人在使用相同的策略提交C-new**，如下图所示，C-old 和 C-new 没有任何机会同时做出单方面的决定，这就保证了安全性。



![img](https:////upload-images.jianshu.io/upload_images/3271185-a6db3f30360b8eef.png?imageMogr2/auto-orient/strip|imageView2/2/w/800/format/webp)

image.png

一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的条目，实线表示最后被提交的日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old,new 的大多数和 C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在 C-new 和 C-old 可以同时做出决定的时间点。



## 3.5日志压缩

随着日志大小的增长，会占用更多的内存空间，处理起来也会耗费更多的时间，对系统的可用性造成影响，因此必须想办法压缩日志大小。**Snapshotting是最简单的压缩方法，系统的全部状态会写入一个snapshot保存起来，然后丢弃截止到snapshot时间点之前的所有日志**。Raft中的snapshot内容如下图所示：

![img](https://pic1.zhimg.com/80/v2-d32ebd3a894539c6c9787c1ad00fa86c_720w.jpg)

**每一个server都有自己的snapshot，它只保存当前状态，如上图中的当前状态为x=0,y=9，而last included index和last included term代表snapshot之前最新的命令，用于AppendEntries的状态检查。**

**虽然每一个server都保存有自己的snapshot，但是当follower严重落后于leader时，leader需要把自己的snapshot发送给follower加快同步，此时用到了一个新的RPC：InstallSnapshot RPC。follower收到snapshot时，需要决定如何处理自己的日志**，如果收到的snapshot包含有更新的信息，它将丢弃自己已有的日志，按snapshot更新自己的状态，如果snapshot包含的信息更少，那么它会丢弃snapshot中的内容，但是自己之后的内容会保存下来。RPC的定义如下：

![img](https://pic2.zhimg.com/80/v2-eebe205ded385b141cebdffaf9d73985_720w.jpg)





# 4 Paxos

# 5 zab协议

# 6  数据分布方式

### 1. 哈希方式

哈希方式是最常见的数据分布方式，其方法是按照数据的某一特征计算哈希值，并将哈希值与机器中的机器建立映射关系，从而将不同哈希值的数据分布到不同的机器上。

- 哈希分布数据的缺点同样明显，突出表现为可扩展性不高，一旦集群规模需要扩展，则几乎所有的数据需要被迁移并重新分布。
- 哈希分布数据的另一个缺点是，一旦某数据特征值的数据严重不均，容易出现“数据倾斜”（dataskew）问题。

### 2. 按数据范围方式

按数据范围分布是另一个常见的数据分布式，将数据按特征值的值域范围划分为不同的区间，使得集群中每台（组）服务器处理不同区间的数据。

- 工程中，为了数据迁移等负载均衡操作的方便，往往利用动态划分区间的技术，使得每个区间中服务的数据量尽量的一样多。当某个区间的数据量较大时，通过将区间“分裂”的方式拆分为两个区间，使得每个数据区间中的数据量都尽量维持在一个较为固定的阈值之下。
- 使用范围分布数据的方式的最大优点就是可以灵活的根据数据量的具体情况拆分原有数据区间，拆分后的数据区间可以迁移到其他机器，一旦需要集群完成负载均衡时，与哈希方式相比非常灵活。另外，当集群需要扩容时，可以随意添加机器，而不限为倍增的方式，只需将原机器上的部分数据分区迁移到新加入的机器上就可以完成集群扩容。
- 按范围分布数据方式的缺点是需要维护较为复杂的元信息。随着集群规模的增长，元数据服务器较为容易成为瓶颈，从而需要较为负责的多元数据服务器机制解决这个问题。（一般的，往往需要使用专门的服务器在内存中维护数据分布信息，称这种数据的分布信息为一种元信息。）

### 3. 按数据量方式

另一类常用的数据分布方式则是按照数据量分布数据。与哈希方式和按数据范围方式不同，数据量分布数据与具体的数据特征无关，而是将数据视为一个顺序增长的文件，并将这个文件按照某一较为固定的大小划分为若干数据块（chunk），不同的数据块分布到不同的服务器上。

- 由于与具体的数据内容无关，按数据量分布数据的方式一般没有数据倾斜的问题，数据总是被均匀切分并分布到集群中。当集群需要重新负载均衡时，只需通过迁移数据块即可完成。集群扩容也没有太大的限制，只需将部分数据库迁移到新加入的机器上即可以完成扩容。
- 按数据量划分数据的缺点是需要管理较为复杂的元信息，与按范围分布数据的方式类似，当集群规模较大时，元信息的数据量也变得很大，高效的管理元信息成为新的课题。

### 4. 一致性哈希

一致性哈希（consistent hashing）是另一个种在工程中使用较为广泛的数据分布方式。一致性哈希最初在 P2P 网络中作为分布式哈希表（DHT）的常用数据分布算法。一致性哈希的基本方式是使用一个哈希函数计算数据或数据特征的哈希值，令该哈希函数的输出值域为一个封闭的环，即哈希函数输出的最大值是最小值的前序。将节点随机分布到这个环上，每个节点负责处理从自己开始顺时针至下一个节点的全部哈希值域上的数据。

- 哈希分布数据的方式在集群扩容时非常复杂，往往需要倍增节点个数，与此相比，一致性哈希的优点在于可以任意动态添加、删除节点，每次添加、删除一个节点仅影响一致性哈希环上相邻的节点。
- 上述最基本的一致性哈希算法有很明显的缺点，随机分布节点的方式使得很难均匀的分布哈希值域，尤其在动态增加节点后，即使原先的分布均匀也很难保证继续均匀，由此带来的另一个较为严重的缺点是，当一个节点异常时，该节点的压力全部转移到相邻的一个节点，当加入一个新节点时只能为一个相邻节点分摊压力。
- 为此一种常见的改进算法是引入虚节点（virtual node）的概念，系统初始时就创建许多虚节点，虚节点的个数一般远大于未来集群中机器的个数，将虚节点均匀分布到一致性哈希值域环上，其功能与基本一致性哈希算法中的节点相同。为每个节点分配若干虚节点。操作数据时，首先通过数据的哈希值在环上找到对应的虚节点，进而查找元数据找到对应的真实节点。使用虚节点改进有多个优点。首先，一旦某个节点不可用，该节点将使得多个虚节点不可用，从而使得多个相邻的真实节点负载失效节点的压里。同理，一旦加入一个新节点，可以分配多个虚节点，从而使得新节点可以负载多个原有节点的压力，从全局看，较容易实现扩容时的负载均衡。

### 5. 副本与数据分布

分布式系统容错、提高可用性的基本手段就是使用副本。对于数据副本的分布方式主要影响系统的可扩展性。

- 一种基本的数据副本策略是以**机器**为单位，若干机器互为副本，副本机器之间的数据完全相同。这种策略适用于上述各种数据分布方式。其优点是非常简单，其缺点是恢复数据的效率不高、可扩展性也不高、不利于系统容错。
- 更合适的做法不是以机器作为副本单位，而是将数据拆为较合理的数据段，以**数据段**为单位作为副本。一旦将数据分为数据段，则可以以数据段为单位管理副本，从而副本与机器不再硬相关，每台机器都可以负责一定数据段的副本。
- 工程中，完全按照数据段建立副本会引起需要管理的元数据的开销增大，副本维护的难度也相应增大。一种折中的做法是将某些数据段组成一个数据段分组，按数据段分组为粒度进行副本管理。这样做可以将副本粒度控制在一个较为合适的范围内。

### 6. 本地化计算

在分布式系统中计算节点和保存计算数据的存储节点可以在同一台物理机器上，也可以位于不同的物理机器。如果计算节点和存储节点位于不同的物理机器则计算的数据需要通过网络传输，此种方式的开销很大，甚至网络带宽会成为系统的总体瓶颈。另一种思路是，将计算尽量调度到与存储节点在同一台物理机器上的计算节点上进行，这称之为***本地化计算\***。本地化计算是计算调度的一种重要优化，其体现了一种重要的分布式调度思想：“*移动数据不如移动计算*”。

### 7. 数据分布方式的选择

在实际工程实践中，可以根据需求及实施复杂度合理选择数据分布方式。另外，上述数据分布方式是如果可以灵活组合使用，往往可以兼备各种方式的优点，收到较好的综合效果。



# 8 避免集群脑类问题

 ping网关ip，



# 10  chubby 与 zk区别



![1602177063549](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\1602177063549.png)

# 11 对比

| 功能点               | euerka                       | Consul                 | zookeeper             | etcd              |
| -------------------- | ---------------------------- | ---------------------- | --------------------- | ----------------- |
| 服务健康检查         | 可配支持                     | 服务状态，内存，硬盘等 | (弱)长连接，keepalive | 连接心跳          |
| 多数据中心           | —                            | 支持                   | —                     | —                 |
| kv 存储服务          | —                            | 支持                   | 支持                  | 支持              |
| 一致性               | —                            | raft                   | ZAB                   | raft              |
| cap                  | ap（高可用、分区容错）       | ca（数据一致、高可用） | cp                    | cp                |
| 使用接口(多语言能力) | http（sidecar）              | 支持 http 和 dns       | 客户端                | http/grpc         |
| watch 支持           | 支持 long polling/大部分增量 | 全量/支持long polling  | 支持                  | 支持 long polling |
| 自身监控             | metrics                      | metrics                | —                     | metrics           |
| 安全                 | —                            | acl /https             | acl                   | https 支持（弱）  |
| spring cloud 集成    | 已支持                       | 已支持                 | 已支持                | 已支持            |



# 12 keepalived

keepalived与zookeeper都可以用来实现高可用，另外常见的还有DNS。先看看优缺点，就可以看出在实现高可用时的区别。高可用一般跟负载均衡会一起考虑，所以下面的比较也会提到负载均衡能力。
1、Keepalived：
优点：简单，基本不需要业务层面做任何事情，就可以实现高可用，主备容灾。而且容灾的宕机时间也比较短。
缺点：也是简单，因为VRRP、主备切换都没有什么复杂的逻辑，所以无法应对某些特殊场景，比如主备通信链路出问题，会导致脑裂。同时，keepalived也不容易做负载均衡。
2、zookeeper：
优点：可以支持高可用，负载均衡。本身是个分布式的服务。
缺点：跟业务结合的比较紧密。需要在业务代码中写好ZK使用的逻辑，比如注册名字。拉取名字对应的服务地址等。