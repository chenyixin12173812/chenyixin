

# 0常用NOSQL比较

| 对比参数       | memcache                                                     | redis                                                        | mongodb                                                      |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 数据库类型     | 纯粹的key-value数据库,数据结构单一                           | 结构化数据库                                                 | 对象数据库                                                   |
| 支持数据类型   | string                                                       | String，List，Hash，Set，ZSet，没有bitmap呀。没错，实际上bitmap的本质还是String | 索引，类似于关系型数据库                                     |
| 可用性         | 没有数据冗余机制，使用一致性hash增加可用性                   | 支持ms,mss结构，slave重连主节点会导致一次全量同步产生，影响性能和效率。可以实现读写分离，slave重连使用全量数据，性能和效率会有问题，不支持自动sharding，需要程序上实现一致性hash | 支持ms,支持replication set，set可以自动故障转换，支持autosharding |
| 持久化支持     | 数据完全放在内存中，没有持久化支持                           | 支持持久化，快照持久化和aof持久化                            | 1.8版本开始采用binlog方式支持持久化的可靠性                  |
| 内存空间优化   | 最大内存限制，LRU算法淘汰（可选）                            | 独立的vm机制,最大内存限制，数据ttl过期设置，内存淘汰（可选） | 依赖于操作系统的vm管理机制,使用内存映射文件，把剩余内存作为缓存使用，没有最大内存限制，数据存在文件系统上和内存 |
| 是否多线程     | 是，可以通过-t控制进线程数                                   | 单线程                                                       | 多线程                                                       |
| 性能           | 15W/s的GET,11W/s的SET                                        | 单个实例qps:8.5W左右（GET/SET）（RH2285）                    | 单个qps:3.5W左右（GET/SET）（RH2285）                        |
| 事务支持       | 并发场景下，用cas保证一致性                                  | 事务支持比较弱，保证每个事务操作连续执行，如果一个操作失败，不会回滚。使用乐观锁实现cas。 | 不支持事务                                                   |
| 数据分析       | 简单的get查询功能                                            | 简单查询功能,支持对集合和hash的操作等                        | 查询方便，有类似于sql的语法，支持条件查询                    |
| 应用场景       | 常作为前端缓存                                               | 缓存和数据存储，队列                                         | 大数据量存储                                                 |
| 特点           | -                                                            | 支持使用pipeline减少查询次数                                 | auto sharding，故障自动切换，mapreduce支持，大文件下的GridFs文件系统 |
| 安全问题       | 目前没有身份验证                                             | 支持密码验证（requirepass）                                  | 支持collection级别的身份验证（auth）                         |
| 数据备份和还原 | 数据存放于内存中，不方便备份和还原（stats cachedump）        | 可以使用持久化做备份和还原                                   | mongodump倍份,mogorestore还原。数据导出：mongoexport,mongoimport,导出数据支持csv格式 |
| slowlog相关    | 没有slowlog相关的设置                                        | 支持slowlog，slowlog存在于数据库中，使用slowlog get获取相关日志，slowlog的大小有限制，超过后会删除旧的 | 支持slowlog（profiling），slowlog存在于system.profile（capped collection）的collection中 |
| 状态查看       | stats                                                        | info                                                         | mongostat,db.serverStatus(),db.stats(),rs.statsu()等         |
| tunning        | 1.object size不要太大（默认只支持1M）2.object 的expires设置（缓存应该具有超时的特点）3.适合数据处理后的缓存，不适合缓存后的处理输出 | 1.开启vm，将不常用的value值给交换到磁盘上 2.尽量将数据存放在内存中 3.前端使用proxy或persistence hash来实现均衡访问 4.使用master-slave结构，做读写分离 5.大数据量时持久化数据dump时影响服务，应该放在slave端做6.使用pipeline聚合访问7.网卡bonding | 1.索引相关(读多写少时)  2.explain解析查询 3.限定返回条目（limit) 4.只查看指定需要字段，不查询所有字段 5.使用capped collection （特殊业务）6.使用replsets,扩展整体集群能力 |

1. 类型——memcacheheredis都是将数据存放在内存，所以是内存数据库。当然，memcache也可用于缓存其他东西，例如图片等等。
2. 数据类型——Memcache 在添加数据时就要指定数据的字节长度,而 redis 不需要。
3. 虚拟内存——当物理内存用完时，可以将一些很久没用到的 value 交换到磁盘。
4. 过期策略——memcache 在 set 时就指定，例如 set key1 0 0 8,即永不过期。Redis 可以通过例如 expire 设定，例如 expire name 10。
5. 分布式——设定 memcache 集群，利用 magent 做一主从;redis可以做一主多从。都可以一主一从。
6. 存储数据安全——memcache 断电就断了，数据没了；redis 可以定期 save 到磁盘。
7. 灾难恢复——memcache 同上，redis 丢了后可以通过 aof 恢复。

| 数据库    | 优点                                                         | 缺点                                                         | 适用场景                                                     |
| :-------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| HBase     | 1、存储容量大，一个表可以容纳上亿行，上百万列 2、可通过版本进行检索，能搜到所需的历史版本数据 3、负载高时，可通过简单的添加机器来实现水平切分扩展，跟Hadoop的无缝集成保障了其数据可靠性HDFS和海量数据分析的高性MapReduce、 可有效避免单点故障的发生 | 1、依赖项较多、配置麻烦，缺乏文档 2、占用内存很大，且鉴于建立在为批量分析而优化的HDFS上，导致读取性能不高 3、API相比其它 NoSql 的相对笨拙 | 1、bigtable类型的数据存储 2、对数据有版本查询需求，并且需要对大数据进行随机、实时访问的场合 3、应对超大数据量要求扩展简单的需求 |
| Hive      | 1、Hive 使用类SQL 查询语法, 最大限度的实现了和SQL标准的兼容，大大降低了传统数据分析人员学习的曲线 2、使用JDBC 接口/ODBC接口，开发人员更易开发应用 3、以MR 作为计算引擎、HDFS 作为存储系统，为超大数据集设计的计算/ 扩展能力 4、统一的元数据管理（Derby、MySql等），并可与Pig 、Presto 等共享； | 1、Hive 的HQL 表达的能力有限，有些复杂运算用HQL 不易表达 2、由于Hive自动生成MapReduce 作业， HQL 调优困难 3、粒度较粗，可控性差 | 通过类SQL的语言实现在大规模数据集上快速的数据查询等操作，而不需要开发相应的MapReduce程序，所以Hive特别适合数据仓库的统计分析 |
| Redis     | 1、非常丰富的数据结构 2、Redis提供了事务的功能，可以保证一串 命令的原子性，中间不会被任何操作打断 3、数据存在内存中，读写非常的高速，可以达到10w/s的频率 | 1、持久化功能体验不佳——通过快照方法实现的话，需要每隔一段时间将整个数据库的数据写到磁盘上，代价非常高；而aof方法只追踪变化的数据，类似于mysql的binlog方法，但追加log可能过大，同时所有操作均要重新执行一遍，恢复速度慢 2、 由于是内存数据库，所以，单台机器，存储的数据量，跟机器本身的内存大小。虽然redis本身有key过期策略，但是还是需要提前预估和节约内存。如果内存增长过快，需要定期删除数据。 | 1、会话缓存 2、全页缓存 3、当做消息队列的工具使用 4、排行榜/计数器 5、 发布/订阅的脚本触发器 总的来说适用于数据变化快且数据库大小可预见(适合内存容量)的应用程序 |
| LevelDB   | 1、操作接口简单，基本操作包括写记录，读记录和删除记录，也支持针对多条操作的原子批量操作 2、写入性能远强于读取性能 3、数据量增大后，读写性能下降趋平缓。 | 1、随机读性能一般 2、 对分布式事务的支持还不成熟。而且机器资源浪费率高 | 适用于对写入需求远大于读取需求的场景                         |
| MongoDB   | 1、 强大的自动化 shading 功能 2、 全索引支持，查询非常高效 3、 面向文档*（BSON）*存储，数据模式简单而强大 4、 支持动态查询，查询指令也使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组 5、 支持 javascript 表达式查询，可在服务器端执行任意的 javascript函数 | 1、 单个文档大小限制为16M，32位系统上，不支持大于2.5G的数据 2、 对内存要求比较大，至少要保证热数据*（索引，数据及系统其它开销）*都能装进内存 3、 非事务机制，无法保证事件的原子性 | 1、 适用于实时的插入、更新与查询的需求，并具备应用程序实时数据存储所需的复制及高度伸缩性 2、 非常适合文档化格式的存储及查询 3、 高伸缩性的场景:MongoDB 非常适合由数十或者数百台服务器组成的数据库 4、 对性能的关注超过对功能的要求 |
| Couchbase | 1、 高并发性，高灵活性，高拓展性，容错性好 2、 以 vBucket 的概念实现更理想化的自动分片以及动态扩容 | 1、Couchbase 的存储方式为 Key/Value，但 Value 的类型很为单一，不支持数组。另外也不会自动创建doc id，需要为每一文档指定一个用于存储的 Document Indentifer 2. 各种组件拼接而成，都是c++实现，导致复杂度过高，遇到奇怪的性能问题排查比较困难,文档比较欠缺 3. 采用缓存全部key的策略，需要大量内存。节点宕机时 failover 过程有不可用时间，并且有部分数据丢失的可能，在高负载系统上有假死现象 4. 逐渐倾向于闭源，社区版本和商业版本之间差距比较大 | 1、适合对读写速度要求较高，但服务器负荷和内存花销可预见的需求 2、需要支持 memcached 协议的需求 |
| Kudu      | 1、提供快速的全量数据分析与实时处理(olap)功能 2、结构化的数据模型，支持标准SQL语法，支持数据的增删改查 3、集成Impala，利用Imapla SQL语法可操作Kudu数据 4、与mapreduce、spark以及其它hadoop生态系统集成 5、高可用。Tablet Servers and Masters利用Raft Consensus Algorithm，确保只要有一半的副本可用，则tablet可用（可读写） 6、对数据顺序扫描(scan)和随机访问(random access)同时具有高性能，简化用户复杂的混合架构。 | 1、2016年新起的项目，成熟度不够 2、开发语言是C++ 3、不像HBase，可以动态无限扩展列，列必须实现定好，也可以通过修改元信息增加列 | 1、实时更新的应用。刚刚到达的数据就马上要被终端用户使用访问到 2、时间序列相关的应用，需要同时支持，包括根据海量历史数据查询和必须非常快地返回关于单个实体的细粒度查询两种类型 3、实时预测模型的应用，支持根据所有历史数据周期地更新模型 |





 ![å¨è¿éæå¥å¾çæè¿°](https://img-blog.csdnimg.cn/20200825151138144.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Z1emhvbmdtaW4wNQ==,size_16,color_FFFFFF,t_70#pic_center) 





# 1用途

注册中心

幂等校验

缓存

分布式

# 2.缓存雪崩和缓存穿透问题解决方案

# 2.0缓存穿透、缓存雪崩、缓存击穿。

1  **缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力**。缓存击穿指并发查同一条数据

   解决方案：

1. 设置热点数据永远不过期。
2. 加互斥锁

2   **缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，    缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。**

   解决方案：

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。
3. 设置热点数据永远不过期

3　**缓存穿透（大量查询一个不存在的key）定义：缓存穿透，是指查询一个数据库中不一定存在的数据；**

　　正常使用缓存查询数据的流程是，依据key去查询value，数据查询先进行缓存查询，如果key不存在或者key已经过期，再对数据库进行查询，并把查询到的对象，放进缓存。如果数据库查询对象为空，则不放进缓存。

如果每次都查询一个不存在value的key，由于缓存中没有数据，所以每次都会去查询数据库；当对key查询的并发请求量很大时，每次都访问DB，很可能对DB造成影响；并且由于缓存不命中，每次都查询持久层，那么也失去了缓存的意义。

 　解决方法

　　第一种是缓存层缓存空值

　　　　将数据库中的空值也缓存到缓存层中，这样查询该空值就不会再访问DB，而是直接在缓存层访问就行。

　　　　但是这样有个弊端就是缓存太多空值占用了更多的空间，可以通过给缓存层空值设立一个较短的过期时间来解决，例如60s。

　　第二种是布隆过滤器

　　　　将数据库中所有的查询条件，放入布隆过滤器中，

　　　　当一个查询请求过来时，先经过布隆过滤器进行查，如果判断请求查询值存在，则继续查；如果判断请求查询不存在，直接丢弃。

# 2.1.Redis雪崩了解吗？

- 我了解，目前电商首页以及热点数据都会去做缓存，一般缓存都是定时任务去刷新，或者查不到之后去更新缓存的，定时任务刷新就有一个问题。
- 举个例子：如果首页所有Key的失效时间都是12小时，中午12点刷新的，我零点有个大促活动大量用户涌入，假设每秒6000个请求，本来缓存可以抗住每秒5000个请求，但是缓存中所有Key都失效了。此时6000个/秒的请求全部落在了数据库上，数据库必然扛不住，真实情况可能DBA都没反应过来直接挂了，此时，如果没什么特别的方案来处理，DBA很着急，重启数据库，但是数据库立马又被新流量给打死了。这就是我理解的缓存雪崩。

## 2.2.如何应对Redis雪崩？

处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效。

```text
setRedis（key, value, time+Math.random()*10000）;
```

- 如果Redis是集群部署，将热点数据均匀分布在不同的Redis库中也能避免全部失效。
- 或者设置热点数据永不过期，有更新操作就更新缓存就好了（比如运维更新了首页商品，那你刷下缓存就好了，不要设置过期时间），电商首页的数据也可以用这个操作，保险。

## **3.了解缓存穿透和击穿么，可以说说他们跟雪崩的区别吗？**

- 先说下缓存穿透吧，缓存穿透是指缓存和数据库中都没有的数据，而用户（黑客）不断发起请求，举个例子：我们数据库的id都是从1自增的，如果发起id=-1的数据或者id特别大不存在的数据，这样的不断攻击导致数据库压力很大，严重会击垮数据库。
- 至于缓存击穿，这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停地扛着大量的请求，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发直接落到了数据库上，就在这个Key的点上击穿了缓存。

## **4.如何解决缓存穿透和击穿？**

- 对于缓存穿透，我会在接口层增加校验，比如用户鉴权，参数做校验，不合法的校验直接return，比如id做基础校验，id<=0直接拦截。
- 采用布隆过滤器（Bloom Filter） 这个也能很好的预防缓存穿透的发生，他的原理就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查DB刷新KV再return。
- 对于缓存击穿， 设置热点数据永不过期，或者 加上互斥锁 就搞定了。

```text
public static String getData(String key) throws InterruptedException {
        //从Redis查询数据
        String result = getDataByKV(key);
        //参数校验
        if (StringUtils.isBlank(result)) {
            try {
                //获得锁
                if (reenLock.tryLock()) {
                    //去数据库查询
                    result = getDataByDB(key);
                    //校验
                    if (StringUtils.isNotBlank(result)) {
                        //插进缓存
                        setDataToKV(key, result);
                    }
                } else {
                    //睡一会再拿
                    Thread.sleep(100L);
                    result = getData(key);
                }
            } finally {
                //释放锁
                reenLock.unlock();
            }
        }
        return result;
    }
```



处理缓存雪崩简单，在批量往`Redis`存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效，我相信，Redis这点流量还是顶得住的。

```text
setRedis（Key，value，time + Math.random() * 10000）；
```

如果Redis是集群部署，将热点数据均匀分布在不同的Redis库中也能避免全部失效的问题，不过本渣我在生产环境中操作集群的时候，单个服务都是对应的单个Redis分片，是为了方便数据的管理，但是也同样有了可能会失效这样的弊端，失效时间随机是个好策略。

或者设置热点数据永远不过期，有更新操作就更新缓存就好了（比如运维更新了首页商品，那你刷下缓存就完事了，不要设置过期时间），电商首页的数据也可以用这个操作，保险。

### **那你了解缓存穿透和击穿么，可以说说他们跟雪崩的区别么？**

嗯，了解，我先说一下缓存穿透吧，缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。

小点的单机系统，基本上用postman就能搞死，比如我自己买的阿里云服务 

![img](https://pic1.zhimg.com/80/v2-e846d8c3371c5eef80cf4185bcec15c4_720w.jpg)


像这种你如果不对参数做校验，数据库id都是大于0的，我一直用小于0的参数去请求你，每次都能绕开Redis直接打到数据库，数据库也查不到，每次都这样，并发高点就容易崩掉了。

至于缓存击穿嘛，这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。

eturn，比如：id 做基础校验，id <=0的直接拦截等。

这里我想提的一点就是，我们在开发程序的时候都要有一颗“不信任”的心，就是不要相信任何调用方，比如你提供了API接口出去，你有这几个参数，那我觉得作为被调用方，任何可能的参数情况都应该被考虑到，做校验，因为你不相信调用你的人，你不知道他会传什么参数给你。举个简单的例子，你这个接口是分页查询的，但是你没对分页参数的大小做限制，调用的人万一一口气查 Integer.MAX_VALUE 一次请求就要你几秒，多几个并发你不就挂了么？是公司同事调用还好大不了发现了改掉，但是如果是黑客或者竞争对手呢？在你双十一当天就调你这个接口会发生什么，就不用我说了吧。这是之前的Leader跟我说的，我觉得大家也都应该了解下。

这样可以防止攻击用户反复用同一个id暴力攻击，但是我们要知道正常用户是不会在单秒内发起这么多次请求的，那网关层Nginx本渣我也记得有配置项，可以让运维大大对单个IP每秒访问次数超出阈值的IP都拉黑。

## 那你还有别的办法么？

还有我记得Redis还有一个高级用法布隆过滤器（Bloom Filter）这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。

从缓存取不到的数据，在数据库中也没有取到，这时也可以将对应Key的Value对写为null、位置错误、稍后重试这样的值具体取啥问产品，或者看具体的场景，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。

那又有小伙伴说了如果黑客有很多个IP同时发起攻击呢？这点我一直也不是很想得通，但是一般级别的黑客没这么多肉鸡，再者正常级别的Redis集群都能抗住这种级别的访问的，小公司我想他们不会感兴趣的。把系统的高可用做好了，集群还是很能顶的。

缓存击穿的话，设置热点数据永远不过期。或者加上互斥锁就能搞定了作为暖男，代码我肯定帮你们准备好了。

```java
   /**
     * 获取数据
     * @param Key                     查询参数
     * @return data                   数据
     * @throws InterruptedException   异常
     * @author 敖丙
     */
    public static String getData(String Key) throws InterruptedException {
        // 从redis查询数据
        String result = getDataByKV(Key);
        // 参数校验
        if (StringUtils.isBlank(result)) {
            // 获取锁
            if (reenLock.tryLock()) {
                // 去数据库查询
                result = getDataByDB(Key);
                // 校验
                if (StringUtils.isNotBlank(result)) {
                    // 搞进缓存
                    setDataToKV(Key, result);
                }
                // !!!释放锁 正常会在finally里面释放
                reenLock.unLock();
            } else {
                // 睡一会再拿
                Thread.sleep(100L);
                result = getData(Key);
            }
        }
        return result;
    }
// 这里面的锁都是单机玩玩，分布式锁还是得靠lua脚本这样的
```

# 3.获取全部key

# 4  谈谈Redis相关的集群有哪些成熟方案 



# 5 



# 6 Redis哨兵、集群的设计原理和区别？

# 7 Redis缓存和数据库会存在一致性问题吗？怎么解决

# 8与数据库双写一致

修改：先删redis，修改书库，再删数据库。

新增直接写库

删除：先删除数据库。

查询：

 https://www.cnblogs.com/starcrm/p/12984368.html 

# 9 redis 分片

一致性hash。多个机房同步，机房之间同步

# 10 redis zsort

1000万积分排序，



1. Redis的5大结构
2. Zset的底层结构



# 11 redis 变慢了



# 类型变更

# 采用随机数，不能使用缓存池





### 使用复杂度高的命令

如果在使用Redis时，发现访问延迟突然增大，如何进行排查？

首先，第一步，建议你去**查看一下Redis的慢日志。Redis提供了慢日志命令的统计功能，我们通过以下设置，就可以查看有哪些命令在执行时延迟比较大**。

首先设置Redis的慢日志阈值，只有超过阈值的命令才会被记录，这里的单位是微妙，例如设置慢日志的阈值为5毫秒，同时设置只保留最近1000条慢日志记录：

```
# 命令执行超过5毫秒记录慢日志CONFIG SET slowlog-log-slower-than 5000# 只保留最近1000条慢日志CONFIG SET slowlog-max-len 1000
```

设置完成之后，所有执行的命令如果延迟大于5毫秒，都会被Redis记录下来，我们执行`SLOWLOG get 5`查询最近5条慢日志：

```
127.0.0.1:6379> SLOWLOG get 51) 1) (integer) 32693       # 慢日志ID   2) (integer) 1593763337  # 执行时间   3) (integer) 5299        # 执行耗时(微妙)   4) 1) "LRANGE"           # 具体执行的命令和参数      2) "user_list_2000"      3) "0"      4) "-1"2) 1) (integer) 32692   2) (integer) 1593763337   3) (integer) 5044   4) 1) "GET"      2) "book_price_1000"...
```

通过查看慢日志记录，我们就可以知道在什么时间执行哪些命令比较耗时，如果你的业务**经常使用`O(n)`以上复杂度的命令**，例如`sort`、`sunion`、`zunionstore`，或者在执行`O(n)`命令时操作的数据量比较大，这些情况下Redis处理数据时就会很耗时。

如果你的服务请求量并不大，但Redis实例的CPU使用率很高，很有可能是使用了复杂度高的命令导致的。

解决方案就是，不使用这些复杂度较高的命令，并且一次不要获取太多的数据，每次尽量操作少量的数据，让Redis可以及时处理返回。

### 存储大key

如果查询慢日志发现，并不是复杂度较高的命令导致的，例如都是`SET`、`DELETE`操作出现在慢日志记录中，那么你就要怀疑是否存在Redis写入了大key的情况。

Redis在写入数据时，需要为新的数据分配内存，当从Redis中删除数据时，它会释放对应的内存空间。

如果一个key写入的数据非常大，Redis在**分配内存时也会比较耗时**。同样的，当删除这个key的数据时，**释放内存也会耗时比较久**。

你需要检查你的业务代码，是否存在写入大key的情况，需要评估写入数据量的大小，业务层应该避免一个key存入过大的数据量。

那么有没有什么办法可以扫描现在Redis中是否存在大key的数据吗？

Redis也提供了扫描大key的方法：

```
redis-cli -h $host -p $port --bigkeys -i 0.01
```

使用上面的命令就可以扫描出整个实例key大小的分布情况，它是以类型维度来展示的。

需要注意的是当我们在线上实例进行大key扫描时，Redis的QPS会突增，为了降低扫描过程中对Redis的影响，我们需要控制扫描的频率，使用`-i`参数控制即可，它表示扫描过程中每次扫描的时间间隔，单位是秒。

使用这个命令的原理，其实就是Redis在内部执行`scan`命令，遍历所有key，然后针对不同类型的key执行`strlen`、`llen`、`hlen`、`scard`、`zcard`来获取字符串的长度以及容器类型(list/dict/set/zset)的元素个数。

而对于容器类型的key，只能扫描出元素最多的key，但元素最多的key不一定占用内存最多，这一点需要我们注意下。不过使用这个命令一般我们是可以对整个实例中key的分布情况有比较清晰的了解。

针对大key的问题，Redis官方在4.0版本推出了`lazy-free`的机制，用于异步释放大key的内存，降低对Redis性能的影响。即使这样，我们也不建议使用大key，大key在集群的迁移过程中，也会影响到迁移的性能，这个后面在介绍集群相关的文章时，会再详细介绍到。

### 集中过期

有时你会发现，平时在使用Redis时没有延时比较大的情况，但在某个时间点突然出现一波延时，而且**报慢的时间点很有规律，例如某个整点，或者间隔多久就会发生一次**。

如果出现这种情况，就需要考虑是否存在大量key集中过期的情况。

如果有大量的key在某个固定时间点集中过期，在这个时间点访问Redis时，就有可能导致延迟增加。

Redis的过期策略采用主动过期+懒惰过期两种策略：

- 主动过期：Redis内部维护一个定时任务，默认每隔100毫秒会从过期字典中随机取出20个key，删除过期的key，如果过期key的比例超过了25%，则继续获取20个key，删除过期的key，循环往复，直到过期key的比例下降到25%或者这次任务的执行耗时超过了25毫秒，才会退出循环
- 懒惰过期：只有当访问某个key时，才判断这个key是否已过期，如果已经过期，则从实例中删除

注意，**Redis的主动过期的定时任务，也是在Redis主线程中执行的**，也就是说如果在执行主动过期的过程中，出现了需要大量删除过期key的情况，那么在业务访问时，必须等这个过期任务执行结束，才可以处理业务请求。此时就会出现，业务访问延时增大的问题，最大延迟为25毫秒。

而且这个访问延迟的情况，**不会记录在慢日志里**。慢日志中**只记录真正执行某个命令的耗时**，Redis主动过期策略执行在操作命令之前，如果操作命令耗时达不到慢日志阈值，它是不会计算在慢日志统计中的，但我们的业务却感到了延迟增大。

此时你需要检查你的业务，是否真的存在集中过期的代码，一般集中过期使用的命令是`expireat`或`pexpireat`命令，在代码中搜索这个关键字就可以了。

如果你的业务确实需要集中过期掉某些key，又不想导致Redis发生抖动，有什么优化方案？

解决方案是，**在集中过期时增加一个随机时间，把这些需要过期的key的时间打散即可。**

伪代码可以这么写：

```
# 在过期时间点之后的5分钟内随机过期掉redis.expireat(key, expire_time + random(300))
```

这样Redis在处理过期时，不会因为集中删除key导致压力过大，阻塞主线程。

另外，除了业务使用需要注意此问题之外，还可以通过运维手段来及时发现这种情况。

做法是我们需要把Redis的各项运行数据监控起来，执行`info`可以拿到所有的运行数据，在这里我们需要重点关注`expired_keys`这一项，它代表整个实例到目前为止，累计删除过期key的数量。

我们需要对这个指标监控，当在**很短时间内这个指标出现突增**时，需要及时报警出来，然后与业务报慢的时间点对比分析，确认时间是否一致，如果一致，则可以认为确实是因为这个原因导致的延迟增大。

### 实例内存达到上限

有时我们把Redis当做纯缓存使用，就会给实例设置一个内存上限`maxmemory`，然后开启LRU淘汰策略。

当实例的内存达到了`maxmemory`后，你会发现之后的每次写入新的数据，有可能变慢了。

导致变慢的原因是，当Redis内存达到`maxmemory`后，每次写入新的数据之前，必须先踢出一部分数据，让内存维持在`maxmemory`之下。

这个踢出旧数据的逻辑也是需要消耗时间的，而具体耗时的长短，要取决于配置的淘汰策略：

- allkeys-lru：不管key是否设置了过期，淘汰最近最少访问的key
- volatile-lru：只淘汰最近最少访问并设置过期的key
- allkeys-random：不管key是否设置了过期，随机淘汰
- volatile-random：只随机淘汰有设置过期的key
- allkeys-ttl：不管key是否设置了过期，淘汰即将过期的key
- noeviction：不淘汰任何key，满容后再写入直接报错
- allkeys-lfu：不管key是否设置了过期，淘汰访问频率最低的key（4.0+支持）
- volatile-lfu：只淘汰访问频率最低的过期key（4.0+支持）

具体使用哪种策略，需要根据业务场景来决定。

我们最常使用的一般是`allkeys-lru`或`volatile-lru`策略，它们的处理逻辑是，每次从实例中随机取出一批key（可配置），然后淘汰一个最少访问的key，之后把剩下的key暂存到一个池子中，继续随机取出一批key，并与之前池子中的key比较，再淘汰一个最少访问的key。以此循环，直到内存降到`maxmemory`之下。

如果使用的是`allkeys-random`或`volatile-random`策略，那么就会快很多，因为是随机淘汰，那么就少了比较key访问频率时间的消耗了，随机拿出一批key后直接淘汰即可，因此这个策略要比上面的LRU策略执行快一些。

但以上这些逻辑都是在访问Redis时，**真正命令执行之前执行的**，也就是它会影响我们访问Redis时执行的命令。

另外，如果此时Redis实例中有存储大key，那么**在淘汰大key释放内存时，这个耗时会更加久，延迟更大**，这需要我们格外注意。

如果你的业务访问量非常大，并且必须设置`maxmemory`限制实例的内存上限，同时面临淘汰key导致延迟增大的的情况，要想缓解这种情况，除了上面说的避免存储大key、使用随机淘汰策略之外，也可以考虑**拆分实例**的方法来缓解，拆分实例可以把一个实例淘汰key的压力**分摊到多个实例**上，可以在一定程度降低延迟。

### fork耗时严重

如果你的Redis开启了自动生成RDB和AOF重写功能，那么有可能在后台生成RDB和AOF重写时导致Redis的访问延迟增大，而等这些任务执行完毕后，延迟情况消失。

遇到这种情况，一般就是执行生成RDB和AOF重写任务导致的。

生成RDB和AOF都需要父进程`fork`出一个子进程进行数据的持久化，**在`fork`执行过程中，父进程需要拷贝内存页表给子进程，如果整个实例内存占用很大，那么需要拷贝的内存页表会比较耗时，此过程会消耗大量的CPU资源，在完成`fork`之前，整个实例会被阻塞住，无法处理任何请求，如果此时CPU资源紧张，那么`fork`的时间会更长，甚至达到秒级。这会严重影响Redis的性能**。

具体原理也可以参考我之前写的文章：Redis持久化是如何做的？RDB和AOF对比分析。

**我们可以执行`info`命令**，查看最后一次`fork`执行的耗时`latest_fork_usec`，单位微妙。这个时间就是整个实例阻塞无法处理请求的时间。

除了因为备份的原因生成RDB之外，**在主从节点第一次建立数据同步时**，主节点也会生成RDB文件给从节点进行一次全量同步，这时也会对Redis产生性能影响。

要想避免这种情况，我们需要规划好数据备份的周期，建议在**从节点上执行备份，而且最好放在低峰期执行**。如果对于丢失数据不敏感的业务，那么不建议开启AOF和AOF重写功能。

另外，`fork`的耗时也与系统有关，如果把Redis部署在虚拟机上，那么这个时间也会增大。所以使用Redis时建议部署在物理机上，降低`fork`的影响。

### 绑定CPU

很多时候，我们在部署服务时，为了提高性能，降低程序在使用多个CPU时上下文切换的性能损耗，一般会采用进程绑定CPU的操作。

但在使用Redis时，我们不建议这么干，原因如下。

**绑定CPU的Redis，在进行数据持久化时，`fork`出的子进程，子进程会继承父进程的CPU使用偏好，而此时子进程会消耗大量的CPU资源进行数据持久化，子进程会与主进程发生CPU争抢，这也会导致主进程的CPU资源不足访问延迟增大。**

所以在部署Redis进程时，如果需要开启RDB和AOF重写机制，一定不能进行CPU绑定操作！

### 开启AOF

上面提到了，当**执行AOF文件重写时会因为`fork`执行耗时导致Redis延迟增**大，除了这个之外，如果开启AOF机制，设置的策略不合理，也会导致性能问题。

开启AOF后，Redis会把写入的命令实时写入到文件中，但写入文件的过程是先写入内存，等内存中的数据超过一定阈值或达到一定时间后，内存中的内容才会被真正写入到磁盘中。

AOF为了保证文件写入磁盘的安全性，提供了3种刷盘机制：

- `appendfsync always`：每次写入都刷盘，对性能影响最大，占用磁盘IO比较高，数据安全性最高
- `appendfsync everysec`：1秒刷一次盘，对性能影响相对较小，节点宕机时最多丢失1秒的数据
- `appendfsync no`：按照操作系统的机制刷盘，对性能影响最小，数据安全性低，节点宕机丢失数据取决于操作系统刷盘机制

当使用第一种机制`appendfsync always`时，Redis每处理一次写命令，都会把这个命令写入磁盘，而且**这个操作是在主线程中执行的**。

内存中的的数据写入磁盘，这个会加重磁盘的IO负担，操作磁盘成本要比操作内存的代价大得多。如果写入量很大，那么每次更新都会写入磁盘，此时机器的磁盘IO就会非常高，拖慢Redis的性能，因此我们不建议使用这种机制。

与第一种机制对比，`appendfsync everysec`会每隔1秒刷盘，而`appendfsync no`取决于操作系统的刷盘时间，安全性不高。**因此我们推荐使用`appendfsync everysec`这种方式**，在最坏的情况下，只会丢失1秒的数据，但它能保持较好的访问性能。

当然，对于有些业务场景，对丢失数据并不敏感，也可以不开启AOF。

### 使用Swap

如果你发现Redis突然变得非常慢，**每次访问的耗时都达到了几百毫秒甚至秒级**，那此时就检查Redis是否使用到了Swap，这种情况下Redis基本上已经无法提供高性能的服务。

我们知道，操作系统提供了Swap机制，目的是为了当内存不足时，可以把一部分内存中的数据换到磁盘上，以达到对内存使用的缓冲。

但当内存中的数据被换到磁盘上后，访问这些数据就需要从磁盘中读取，这个速度要比内存慢太多！

**尤其是针对Redis这种高性能的内存数据库来说，如果Redis中的内存被换到磁盘上，对于Redis这种性能极其敏感的数据库，这个操作时间是无法接受的。**

我们需要检查机器的内存使用情况，确认是否确实是因为内存不足导致使用到了Swap？

如果确实使用到了Swap，**要及时整理内存空间，释放出足够的内存供Redis使用，然后释放Redis的Swap**，让Redis重新使用内存。

释放**Redis的Swap过程通常要重启实例，为了避免重启实例对业务的影响，一般先进行主从切换，然后释放旧主节点的Swap，重新启动服务，待数据同步完成后，再切换回主节点即可**。

可见，当Redis使用到Swap后，此时的Redis的高性能基本被废掉，所以我们需要提前预防这种情况。

**我们需要对Redis机器的内存和Swap使用情况进行监控，在内存不足和使用到Swap时及时报警出来，及时进行相应的处理。**

### 网卡负载过高

如果以上产生性能问题的场景，你都规避掉了，而且Redis也稳定运行了很长时间，但在某个时间点之后开始，访问Redis开始变慢了，而且一直持续到现在，这种情况是什么原因导致的？

之前我们就遇到这种问题，**特点就是从某个时间点之后就开始变慢，并且一直持续**。这时你需要检查一下机器的网卡流量，是否存在网卡流量被跑满的情况。

**网卡负载过高，在网络层和TCP层就会出现数据发送延迟、数据丢包等情况。Redis的高性能除了内存之外，就在于网络IO，请求量突增会导致网卡负载变高。**

如果出现这种情况，你需要排查这个机器上的哪个Redis实例的流量过大占满了网络带宽，然后确认流量突增是否属于业务正常情况，如果属于那就需要及时扩容或迁移实例，避免这个机器的其他实例受到影响。

运维层面，我们需要对机器的各项指标增加监控，包括网络流量，在达到阈值时提前报警，及时与业务确认并扩容。

### 总结

以上我们总结了Redis中常见的可能导致延迟增大甚至阻塞的场景，这其中既涉及到了业务的使用问题，也涉及到Redis的运维问题。

可见，要想保证Redis高性能的运行，其中涉及到CPU、内存、网络，甚至磁盘的方方面面，其中还包括操作系统的相关特性的使用。

作为开发人员，我们需要了解Redis的运行机制，例如各个命令的执行时间复杂度、数据过期策略、数据淘汰策略等，使用合理的命令，并结合业务场景进行优化。

作为DBA运维人员，需要了解数据持久化、操作系统`fork`原理、Swap机制等，并对Redis的容量进行合理规划，预留足够的机器资源，对机器做好完善的监控，才能保证Redis的稳定运行。

# 12 实现幂等

# 13[redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)的数据结构

**String**的实际应用场景比较广泛的有：

- **缓存功能：String**字符串是最常用的数据类型，不仅仅是**Redis**，各个语言都是最基本类型，因此，利用**Redis**作为缓存，配合其它数据库作为存储层，利用**Redis**支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。
- **计数器：**许多系统都会使用**Redis**作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。
- **共享用户Session：**用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存**Cookie**，但是可以利用**Redis**将用户的**Session**集中管理，在这种模式只需要保证**Redis**的高可用，每次用户**Session**的更新和获取都可以快速完成。大大提高效率。

**Hash：**

这个是类似 **Map** 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是**这个对象没嵌套其他的对象**）给缓存在 **Redis** 里，然后每次读写缓存的时候，可以就操作 **Hash** 里的**某个字段**。

但是这个的场景其实还是多少单一了一些，因为现在很多对象都是比较复杂的，比如你的商品对象可能里面就包含了很多属性，其中也有对象。我自己使用的场景用得不是那么多。

**List：**

**List** 是有序列表，这个还是可以玩儿出很多花样的。

比如可以通过 **List** 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。

比如可以通过 **lrange** 命令，读取某个闭区间内的元素，可以基于 **List** 实现分页查询，这个是很棒的一个功能，基于 **Redis** 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。

比如可以搞个简单的消息队列，从 **List** 头怼进去，从 **List** 屁股那里弄出来。

**List**本身就是我们在开发过程中比较常用的数据结构了，热点数据更不用说了。

- **消息队列：Redis**的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过**Lpush**命令从左边插入数据，多个数据消费者，可以使用**BRpop**命令阻塞的“抢”列表尾部的数据。
- 文章列表或者数据分页展示的应用。

比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用**Redis**的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。

**Set：**

**Set** 是无序集合，会自动去重的那种。

直接基于 **Set** 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 **JVM** 内存里的 **HashSet** 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于**Redis**进行全局的 **Set** 去重。

可以基于 **Set** 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？对吧。

反正这些场景比较多，因为对比很快，操作也简单，两个查询一个**Set**搞定。

**Sorted Set：**

**Sorted set** 是排序的 **Set**，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。

有序集合的使用场景与集合类似，但是set集合不是自动有序的，而**Sorted set**可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择**Sorted set**数据结构作为选择方案。

- 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。
- 用**Sorted Sets**来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。

微博热搜榜，就是有个后面的热度值，前面就是名称







# 14、[redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)的sds

# 15、zset的跳表结构

# 16、Redis内存数据库的内存指的是共享内存么

# 17、Redis的持久化方式

**1、RDB 方式**

1）介绍

（1）RDB 是 Redis **默认**采用的持久化方式。

（2）RDB 方式是通过**快照**（snapshotting）完成的，当**符合一定条件**时 Redis 会自动将内存中的数据进行快照并持久化到硬盘。

（3）Redis会在**指定的情况**下触发快照

- 符合自定义配置的快照规则
- 执行 save 或者 bgsave 命令
- 执行 flushall 命令
- 执行主从复制操作
- 在 redis.conf 中设置自定义快照规则

2）RDB 持久化条件

格式：save <seconds> <changes>

**示例：**

save 900 1 ： 表示15分钟（900秒钟）内至少1个键被更改则进行快照。

save 300 10 ： 表示5分钟（300秒）内至少10个键被更改则进行快照。

save 60 10000 ：表示1分钟内至少10000个键被更改则进行快照。

这里就是 Redis 默认配置信息，可以配置多个条件（每行配置一个条件），每个条件之间是“或”的关系。

（1）打开 redis.conf 配置文件，找到 202 行，可以看到 Redis 默认配置

![img](https://pic2.zhimg.com/80/v2-6d06cb822c46870d3279c37ceae00b4d_720w.jpg)

（2）配置 dir 指定 rdb 快照文件的位置，找到 247 行，默认位置为 redis/bin 目录下

![img](https://pic1.zhimg.com/80/v2-26c5b73e439063d336ff0f3dd4e32b30_720w.jpg)

![img](https://pic3.zhimg.com/80/v2-7388ed8022bf55407da089d6c3792b5e_720w.jpg)

（3）配置 dbfilename 指定 rdb 快照文件的名称，找到 237 行，默认文件名为 dump.rdb

![img](https://pic1.zhimg.com/80/v2-a9f4e84f3c69b0a4fbd35df79d2e132c_720w.jpg)

特别说明：

- Redi s启动后会读取 RDB 快照文件，将数据从硬盘载入到内存。
- 根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将记录一千万个字符串类型键、大小为 1GB 的快照文件载入到内存中需要花费 20～30 秒钟。

2）快照的实现原理

（1）Redis 使用 fork 函数复制一份当前进程的副本(子进程)

（2）父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件。

（3）当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此，一次快照操作完成。

![img](https://pic3.zhimg.com/80/v2-c2fa3f19db14b94aeb3fe40b88fb5b1a_720w.jpg)快照的实现原理

注意事项

- Redis 在进行快照的过程中**不会修改** RDB 文件，只有快照结束后才会将旧的文件**替换**成新的，也就是说任何时候 RDB 文件都是完整的。
- 这就使得我们可以通过定时备份 RDB 文件来实现 Redis 数据库的备份， RDB 文件是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。

**3）RDB 优缺点**

**（1）缺点**：使用 RDB 方式实现持久化，一旦 Redis 异常退出，就会丢失最后一次快照以后更改的所有数据。这个时候我们就需要根据具体的应用场景，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受范围。如果数据相对来说比较重要，希望将损失降到最小，则可以使用 AOF 方式进行持久化。

**（2）优点：** RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无需执行任何磁盘 I/O 操作。同时这个也是一个缺点，如果数据集比较大的时候，fork 可以能比较耗时，造成服务器在一段时间内停止处理客户端的请求。



**2、AOF 方式**

1）介绍

（1）默认情况下 Redis 没有开启 AOF（append only file）方式的持久化

（2）开启 AOF 持久化后每执行一条会**更改 Redis 中的数据的命令**，Redis 就会将该命令写入硬盘中的 AOF 文件，这一过程显然**会降低 Redis 的性能**，但大部分情况下这个影响是能够接受的，另外使**用较快的硬盘可以提高 AOF 的性能**（固态硬盘）。

（3）可以通过修改 redis.conf 配置文件中的 appendonly 参数开启 AOF 方式

![img](https://pic4.zhimg.com/80/v2-e29072092f4ac3eb9f5637bbe1156847_720w.jpg)

（4）AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的。

（5）默认的文件名是 appendonly.aof，可以通过 appendfilename 参数修改。

![img](https://pic2.zhimg.com/80/v2-6d9fa09c6f765312fb0eca01310d6bed_720w.jpg)

（6）开启后，重启 Redis，然后查看一下 bin 目录，就会发现多了一个 appendonly.aof 文件

![img](https://pic1.zhimg.com/80/v2-a02cfd06696ed7fee8ec4efdafce9378_720w.jpg)

2）AOF 重写原理（优化 AOF 文件）

（1）Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF进行重写**，**重写后的新 AOF 文件包含了恢复当前数据集所需的**最小命令集合**。

（2）整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。

（3）AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。

这里我们先连接上 Redis 服务，set 几个值，看一下 appendonly.aof 文件。

![img](https://pic1.zhimg.com/80/v2-ffba39587dafaadb693abab1035479d0_720w.jpg)

![img](https://pic4.zhimg.com/80/v2-679dfc906ee38d27a1b323597993c1bb_720w.jpg)

我们刚刚设置的值都是可以查看到的。

原理中的第（1）条，重写恢复时为当前数据的最小命令集合，这个怎么理解呢？下面我们对已经设置的 k2 进行修改 来看看效果

![img](https://pic3.zhimg.com/80/v2-bc83667476a3caf295b2e0caed4c7b1a_720w.jpg)

![img](https://pic3.zhimg.com/80/v2-03fac58d14953837aaf9cdef82fceb0a_720w.jpg)

可以看到，这是两条对 k2 赋值的信息，都会写入到 aof 文件中，恢复到最小命令集合时，就只会保存下面这一条数据，上面的数据就会被舍弃。

3）参数说明

（1）auto-aof-rewrite-percentage 100 表示当前 aof 文件大小超过上一次 aof 文件大小的百分之多少的时候会进行重写。如果之前没有重写过，以启动时 aof 文件大小为准。

（2）auto-aof-rewrite-min-size 64mb 限制允许重写最小 aof 文件大小，也就是文件大小小于 64mb 的时候，不需要进行优化。

4）同步磁盘数据

Redis 每次更改数据的时候， aof 机制都会将命令记录到 aof 文件，但是实际上由于操作系统的缓存机制，数据并没有实时写入到硬盘，而是进入硬盘缓存。再通过硬盘缓存机制去刷新到保存到文件。

![img](https://pic1.zhimg.com/80/v2-42152ce0eb6a7b497acd650ae0c96984_720w.jpg)

（1）appendfsync always 每次执行写入都会进行同步 ， 这个是最安全但是是效率比较低的方式

（2）appendfsync everysec 每一秒执行

（3）appendfsync no 不主动进行同步操作，由操作系统去执行，这个是最快但是最不安全的方式

5）AOF 文件损坏以后如何修复

服务器可能在程序正在对 AOF 文件进行写入时停机， 如果停机造成了 AOF 文件出错（corrupt）， 那么 Redis 在重启时会拒绝载入这个 AOF 文件， 从而确保数据的一致性不会被破坏。

当发生这种情况时， 可以用以下方法来修复出错的 AOF 文件：

（1）为现有的 AOF 文件创建一个备份。

（2）使用 Redis 附带的 **redis-check-aof** 程序，对原来的 AOF 文件进行修复。

redis-check-aof --fix

\3. 重启 Redis 服务器，等待服务器载入修复后的 AOF 文件，并进行数据恢复。



## 17.1 AOF持久化的优点

1. AOF可以更好的保护数据不丢失，每来一条数据，会写入os cache，然后linux会每隔1秒，通过一个后台线程执行一次fsync操作（fsync的功能是确保所有已修改的内容已经正确同步到硬盘上，该调用会阻塞等待直到设备报告IO完成。），最多丢失1秒钟的数据（机器宕机，如果只是redis奔溃，数据也不会丢失）。
2. AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。
3. AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewritelog的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。
4. AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝A

机制对每条**写入命令**作为日志记录，以append-only的模式写入一个日志文件中，在redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集。

## 17.2 AOF持久化的缺点

1. 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大。
2. AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件。尽管每秒一次fsync，性能也还是很高的，如果你要保证一条数据都不丢，也是可以的，AOF的fsync设置成没写入一条数据，fsync一次，那就完蛋了，redis的QPS将会更低。
3. 以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似AOF这种较为复杂的基于命令日志/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免rewrite过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。
4. 唯一的比较大的缺点，其实就是做数据恢复的时候，会比较慢，还有做冷备，定期的备份，不太方便，可能要自己手写复杂的脚本去做，做冷备不太合适。RDB恢复日志，就是一份数据文件，恢复的时候，直接加载到内存中即可。而AOF则不同，做数据恢复的时候，其实是要回放和执行所有的指令日志，来恢复出来内存中的所有数据的。







# 7 如何选择 RDB 和 AOF

（1）**一般来说,如果对数据的安全性要求非常高的话，应该同时使用两种持久化功能。**

如果可以承受数分钟以内的数据丢失，那么可以只使用 RDB 持久化。

（2）有很多用户都只使用 AOF 持久化， 但并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快 。

两种持久化策略可以同时使用，也可

17.1 RDB持久化的优点
***2\***|***3\*****RDB持久化的缺点**

1. 如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据。这个问题，也是rdb最大的缺点，就是不适合做第一优先的恢复方案，如果你依赖RDB做第一优先恢复方案，会导致数据丢失的比较多
2. RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒一般不要让RDB的间隔太长，否则每次生成的RDB文件太大了，对redis本身的性能可能会有影响的

***2\**

***3\***|***2\*****AOF持久化的优点**

1. AOF可以更好的保护数据不丢失，每来一条数据，会写入os cache，然后linux会每隔1秒，通过一个后台线程执行一次fsync操作（fsync的功能是确保所有已修改的内容已经正确同步到硬盘上，该调用会阻塞等待直到设备报告IO完成。），最多丢失1秒钟的数据（机器宕机，如果只是redis奔溃，数据也不会丢失）。
2. AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。
3. AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewritelog的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。
4. AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据。



1. 



# 18 redis原生三种集群方式

redis有三种集群方式：主从复制，哨兵模式和集群。

**1.主从复制**

**主从复制原理：**

- 从服务器连接主服务器，发送SYNC命令； 
- 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； 
- 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 
- 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 
- 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 
- 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；（**从服务器初始化完成**）
- 主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令（**从服务器初始化完成后的操作**）

**主从复制优缺点：**

**优点：**

- 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离
- 为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成
- Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力。
- Master Server是以非阻塞的方式为Slaves提供服务。所以在Master-Slave同步期间，客户端仍然可以提交查询或修改请求。
- Slave Server同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据

**缺点：**

- Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。
- 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。
- Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。

**2.\**哨兵模式\****

当主服务器中断服务后，可以将一个从服务器升级为主服务器，以便继续提供服务，但是这个过程需要人工手动来操作。 为此，Redis 2.8中提供了哨兵工具来实现自动化的系统监控和故障恢复功能。

哨兵的作用就是监控Redis系统的运行状况。它的功能包括以下两个。

  （1）监控主服务器和从服务器是否正常运行。 
  （2）主服务器出现故障时自动将从服务器转换为主服务器。

**哨兵的工作方式：**

- 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。
- 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）
- 如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态
- 当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）
- 在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。
- 当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
- 若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。

 **哨兵模式的优缺点**

**优点：**

- 哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。
- 主从可以自动切换，系统更健壮，可用性更高。

**缺点：**

- **Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂**。

**3.Redis-Cluster\**集群\****

redis的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台redis服务器都存储相同的数据，很浪费内存，所以在redis3.0上加入了cluster模式，实现的redis的分布式存储，也就是说每台redis节点上存储不同的内容。

 Redis-Cluster采用无中心结构,它的特点如下：

- 所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽。
- 节点的fail是通过集群中超过半数的节点检测失效时才生效。
- 客户端与redis节点直连,不需要中间代理层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。

**工作方式：**

在redis的每一个节点上，都有这么两个东西，一个是插槽（slot），它的的取值范围是：0-16383。还有一个就是cluster，可以理解为是一个集群管理的插件。当我们的存取的key到达的时候，redis会根据crc16的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。

为了保证高可用，redis-cluster集群引入了主从模式，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点ping一个主节点A时，如果半数以上的主节点与A通信超时，那么认为主节点A宕机了。如果主节点A和它的从节点A1都宕机了，那么该集群就无法再提供服务了。



# 19 内存淘汰机制？

例如, 要设置 100MB 的内存限制, 可以在 redis.conf 文件中这样配置：

```
maxmemory 100mb
```

redis的六种淘汰策略：

```tex
volatile-lru： 从已设置过期的数据中中随机挑选最近最少使用的多个key进行数据淘汰。
volatile-ttl： 从已设置过期的数据中挑选即将要过期的数据进行淘汰。
volatile-random：从已设置过期的数据中任意淘汰数据。
allkeys-lru： 从数据集中挑选最近最少使用的数据淘汰。
allkeys-random：从数据集中任意选择数据淘汰。
noeviction: 不进行删除，达到最大内存时，直接返回错误信息。
以上六点的配置是在redis的配置是文件中maxmemory-policy来决定具体使用哪种淘汰策略。我们可以根据业务场景的不同使用不同的淘汰策略。
```



**策略选择：**

- 如果**分为热数据与冷数据, 推荐使用 allkeys-lru** 策略。 也就是, 其中一部分key经常被读写. 如果不确定具体的业务特征, 那么 allkeys-lru 是一个很好的选择。
- 如果需**要循环读写所有的key, 或者各个key的访问频率差不多, 可以使用 allkeys-random 策略, 即读写所有元素的概率差不多**。
- 假如要让 **Redis 根据 TTL 来筛选需要删除的key, 请使用 volatile-ttl 策略**。

volatile-lru 和 volatile-random 策略主要应用场景是: 既有缓存,又有持久key的实例中。 一般来说, 像这类场景, 应该使用两个单独的 Redis 实例。

值得一提的是, **设置 expire 会消耗额外的内存, 所以使用 allkeys-lru 策略, 可以更高效地利用内存, 因为这样就可以不再设置过期时间了**。









# 20 redis常见数据结构以及使用场景分析？（String，Hash，List，Set，Sorted Set） 

 

# 21 MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据

 并将淘汰策略为volatile-lru或者allkeys-lru。 





# 23、[redis]() 和 memcached 的区别？ 



# 24、[redis]() 设置过期时间。 





# 25、[redis]() 事务。 

# 26、。 

# 27、如何解决 Redis 的并发竞争 Key 问题。 

 # 28 集群的限制

1 key 批量操作支持有限：例如 mget、mset 必须在一个 slot
2  key 事务和 Lua 支持有限：操作的 key 必须在一个节点
3 key 是数据分区的最小粒度，不支持 bigkey 分区
4 不支持多个数据库：集群模式洗啊只有一个 db：db0
a) 一般情况下，单机模式下也不建议使用多数据库模式

5 复制只支持一层：不支持树形复制结构  



# 4 Redis为什么这么快

1）完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)；

2）数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；

3）采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

4）使用多路 I/O 复用模型，非阻塞 IO；

5使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；





![img](https://pic1.zhimg.com/80/v2-4e750d52472a2e3b2dea7a247c5554b8_720w.jpg)



**数据类型**



**5、Redis有哪些数据类型**

Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求



![img](https://pic2.zhimg.com/80/v2-6ace04fd7cff6fdd57c5ac5984e37749_720w.jpg)



**6、Redis的应用场景**

- **总结一**

**计数器**：可以对 String 进行自增自减运算，从而实现计数器功能。Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。

**缓存**：将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。

**会话缓存**：可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。

**全页缓存（FPC）**：除基本的会话token之外，Redis还提供很简便的FPC平台。以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。

**查找表**：例如 DNS 记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。

**消息队列(发布/订阅功能)：**List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。不过最好使用 Kafka、RabbitMQ 等消息中间件。

**分布式锁实现：**在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。

**其它：**Set 可以实现交集、并集等操作，从而实现共同好友等功能。ZSet 可以实现有序性操作，从而实现排行榜等功能。

- **总结二**

Redis相比其他缓存，有一个非常大的优势，就是支持多种数据类型。

数据类型说明string字符串，最简单的k-v存储hashhash格式，value为field和value，适合ID-Detail这样的场景。list简单的list，顺序列表，支持首位或者末尾插入数据set无序list，查找速度快，适合交集、并集、差集处理sorted set有序的set

其实，通过上面的数据类型的特性，基本就能想到合适的应用场景了。

string——适合最简单的k-v存储，类似于memcached的存储结构，短信验证码，配置信息等，就用这种类型来存储。

**hash**——一般key为ID或者唯一标示，value对应的就是详情了。如商品详情，个人信息详情，新闻详情等。

**list**——因为list是有序的，比较适合存储一些有序且数据相对固定的数据。如省市区表、字典表等。因为list是有序的，适合根据写入的时间来排序，如：最新的***，消息队列等。

**set**——可以简单的理解为ID-List的模式，如微博中一个人有哪些好友，set最牛的地方在于，可以对两个set提供交集、并集、差集操作。例如：查找两个人共同的好友等。

**Sorted Set**——是set的增强版本，增加了一个score参数，自动会根据score的值进行排序。比较适合类似于top 10等不根据插入的时间来排序的数据。

如上所述，虽然Redis不像关系数据库那么复杂的数据结构，但是，也能适合很多场景，比一般的缓存数据结构要多。了解每种数据结构适合的业务场景，不仅有利于提升开发效率，也能有效利用Redis的性能。





**持久化**



**7、什么是Redis持久化？**

持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。

**8、Redis 的持久化机制是什么？各自的优缺点？**

Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制:

**RDB：**是Redis DataBase缩写快照

RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。



![img](https://pic2.zhimg.com/80/v2-bb6210ee7b6eaa179fef0fe34189e3c1_720w.jpg)



**优点：**

1、只有一个文件 dump.rdb，方便持久化。

2、容灾性好，一个文件可以保存到安全的磁盘。

3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能

4.相对于数据集大时，比 AOF 的启动效率更高。

**缺点：**

1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候)

2、AOF（Append-only file)持久化方式：是指所有的命令行记录以 redis 命令请 求协议的格式完全持久化存储)保存为 aof 文件。

**AOF：持久化**

AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。

当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。



![img](https://pic2.zhimg.com/80/v2-4c2c0b26896688c57675531a085086e1_720w.jpg)



- **优点：**

1、数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。

2、通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。

3、AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)

- **缺点：**

1、AOF 文件比 RDB 文件大，且恢复速度慢。

2、数据集大的时候，比 rdb 启动效率低。

**优缺点是什么？**

AOF文件比RDB更新频率高，优先使用AOF还原数据。

AOF比RDB更安全也更大

RDB性能比AOF好

如果两个都配了优先加载AOF

**9、如何选择合适的持久化方式**

- 一般来说， 如果想达到足以媲美PostgreSQL的数据安全性，你应该**同时使用两种持久化功能**。在这种情况下，当 Redis 重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。
- 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。
- 有很多用户都只使用AOF持久化，但并不推荐这种方式，因为定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免AOF程序的bug。
- 如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。

**10、Redis持久化数据和缓存怎么做扩容？**

- 如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。
- 如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。





**过期键的删除策略**



**11、Redis的过期键的删除策略**

我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。

过期策略通常有以下三种：

- **定时过期**：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。
- **惰性过期**：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。
- **定期过期**：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。

(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)

Redis中**同时使用了惰性过期和定期过期两种过期策略。**

**12、Redis key的过期时间和永久有效分别怎么设置？**

EXPIRE和PERSIST命令。

**13、我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?**

除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：

- 定时去清理过期的缓存；
- 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。

两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。





**内存相关**



**14、MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？**

redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。

**15、Redis的内存淘汰策略有哪些？**

Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。

**全局的键空间选择性移除**

- **noeviction**：当内存不足以容纳新写入数据时，新写入操作会报错。
- **allkeys-lru**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的）
- **allkeys-random**：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。

**设置过期时间的键空间选择性移除**

- **volatile-lru**：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。
- **volatile-random：**当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
- **volatile-ttl：**当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。

**总结**

Redis的内存淘汰策略的选取并不会影响过期的key的处理。内存淘汰策略用于处理内存不足时的需要申请额外空间的数据；过期策略用于处理过期的缓存数据。

**16、Redis主要消耗什么物理资源？**

内存。

**17、Redis的内存用完了会发生什么？**

如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。

**18、Redis如何做内存优化？**

可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面。





**线程模型**

**19、Redis线程模型**

Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。

- 文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。
- 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。

虽然文件事件处理器以单线程方式运行， 但通过使用 I/O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。

参考：[https://www.cnblogs.com/barrywxx/p/8570821.html](https://link.zhihu.com/?target=https%3A//www.cnblogs.com/barrywxx/p/8570821.html)



**事务**

**20、什么是事务？**

事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。

**21、Redis事务的概念**

Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。

总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。

**22、Redis事务的三个阶段**

- **事务开始 MULTI**
- **命令入队**
- **事务执行 EXEC**

事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队。

**23、Redis事务相关命令**

Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的。

Redis会将一个事务中的所有命令序列化，然后按顺序执行。

**1）**redis 不支持回滚，“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。

**2）**如果在一个事务中的命令出现错误，那么所有的命令都不会执行；

**.3）**如果在一个事务中出现运行错误，那么正确的命令会被执行。

- WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。
- MULTI命令用于开启一个事务，它总是返回OK。MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。
- EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil 。
- 通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。
- UNWATCH命令可以取消watch对所有key的监控。

**24、事务管理（ACID）概述**

**原子性（Atomicity）：**原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。

**一致性（Consistency）：**事务前后数据的完整性必须保持一致。

**隔离性（Isolation）：**多个事务并发执行时，一个事务的执行不应影响其他事务的执行。

**持久性（Durability）：**持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响

**Redis的事务总是具有ACID中的一致性和隔离性，**其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性。

**25、Redis事务支持隔离性吗？**

Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。

**26、Redis事务保证原子性吗，支持回滚吗？**

Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。

**27、Redis事务其他实现**

- 基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完
- 基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐。



**集群方案**



**28、哨兵模式**



![img](https://pic2.zhimg.com/80/v2-f7a3e44ae7085dbffe9adafaebee4a69_720w.jpg)



**哨兵的介绍：**

sentinel，中文名是哨兵。哨兵是 redis 集群机构中非常重要的一个组件，主要有以下功能：

- **集群监控**：负责监控 redis master 和 slave 进程是否正常工作。
- **消息通知**：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
- **故障转移**：如果 master node 挂掉了，会自动转移到 slave node 上。
- **配置中心**：如果故障转移发生了，通知 client 客户端新的 master 地址。

**哨兵用于实现 redis 集群的高可用**，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。

- 故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。
- 即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。

**哨兵的核心知识**

- 哨兵至少需要 3 个实例，来保证自己的健壮性。
- 哨兵 + redis 主从的部署架构，是不保证数据零丢失的，只能保证 redis 集群的高可用性。
- 对于哨兵 + redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。

**29、官方Redis Cluster 方案(服务端路由查询)**



![img](https://pic3.zhimg.com/80/v2-06f302e58d9039b793ef8c83cb42733a_720w.jpg)



redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？

**简介**

Redis Cluster是一种服务端Sharding技术，3.0版本开始正式提供。Redis Cluster并没有使用一致性hash，而是采用slot(槽)的概念，一共分成16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行

**方案说明**

- 通过哈希的方式，将数据分片，每个节点均分存储一定哈希槽(哈希值)区间的数据，默认分配了16384 个槽位
- 每份数据分片会存储在多个互为主从的多节点上
- 数据写入先写主节点，再同步到从节点(支持配置为阻塞同步)
- 同一分片多个节点间的数据不保持一致性
- 读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点
- 扩容时时需要需要把旧节点的数据迁移一部分到新节点

在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。

16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。

**节点间的内部通信机制**

（基本通信原理）集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。

**分布式寻址算法**

- hash 算法（大量缓存重建）
- 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）
- redis cluster 的 hash slot 算法

**优点**

- 无中心架构，支持动态扩容，对业务透明
- 具备Sentinel的监控和自动Failover(故障转移)能力
- 客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可
- 高性能，客户端直连redis服务，免去了proxy代理的损耗

**缺点**

- 运维也很复杂，数据迁移需要人工干预
- 只能使用0号数据库
- 不支持批量操作(pipeline管道操作)
- 分布式逻辑和存储模块耦合等

**30、基于客户端分配**



![img](https://pic4.zhimg.com/80/v2-44b431a79e59bd07af007baccf62e327_720w.jpg)



**简介**

Redis Sharding是Redis Cluster出来之前，业界普遍使用的多Redis实例集群方法。其主要思想是采用哈希算法将Redis数据的key进行散列，通过hash函数，特定的key会映射到特定的Redis节点上。Java redis客户端驱动jedis，支持Redis Sharding功能，即ShardedJedis以及结合缓存池的ShardedJedisPool

**优点**

优势在于非常简单，服务端的Redis实例彼此独立，相互无关联，每个Redis实例像单服务器一样运行，非常容易线性扩展，系统的灵活性很强

**缺点**

由于sharding处理放到客户端，规模进一步扩大时给运维带来挑战。

客户端sharding不支持动态增删节点。服务端Redis实例群拓扑结构有变化时，每个客户端都需要更新调整。连接不能共享，当应用规模增大时，资源浪费制约优化

**31、基于代理服务器分片**



![img](https://pic3.zhimg.com/80/v2-e9f132004be8b6334351ad47a6d9e76e_720w.jpg)



**简介**

客户端发送请求到一个代理组件，代理解析客户端的数据，并将请求转发至正确的节点，最后将结果回复给客户端

**特征**

- 透明接入，业务程序不用关心后端Redis实例，切换成本低
- Proxy 的逻辑和存储的逻辑是隔离的
- 代理层多了一次转发，性能有所损耗

**业界开源方案**

Twtter开源的Twemproxy

豌豆荚开源的Codis

**32、Redis 主从架构**

单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，**支撑读高并发。**



![img](https://pic3.zhimg.com/80/v2-c65f9347ed7d1bf29f8fe5a26770e912_720w.jpg)



redis replication -> 主从架构 -> 读写分离 -> 水平扩容支撑读高并发

**redis replication 的核心机制**

- redis 采用异步方式复制数据到 slave 节点，不过 redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；
- 一个 master node 是可以配置多个 slave node 的；
- slave node 也可以连接其他的 slave node；
- slave node 做复制的时候，不会 block master node 的正常工作；
- slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；
- slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。

注意，如果采用了主从架构，那么建议必须开启 master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。

另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能**确保启动的时候，是有数据的**，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。

**redis 主从复制的核心原理**

当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。

如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件。

同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先**写入本地磁盘，然后再从本地磁盘加载到内存中。**

接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。

slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。



![img](https://pic3.zhimg.com/80/v2-52013a05053dfe2bf0fddd90a5825f76_720w.jpg)



**过程原理**

- 当从库和主库建立MS关系后，会向主数据库发送SYNC命令
- 主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来
- 当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis
- 从Redis接收到后，会载入快照文件并且执行收到的缓存的命令
- 之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致

**缺点**

所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决

**33、Redis集群的主从复制模型是怎样的？**

为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有N-1个复制品

**34、生产环境中的 redis 是怎么部署的？**

redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。

机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是10g内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。

5 台机器对外提供读写，一共有 50g 内存。

因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。

你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。

其实大型的公司，会有基础架构的 team 负责缓存集群的运维。

**35、说说Redis哈希槽的概念？**

Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。

**36、Redis集群会有写操作丢失吗？为什么？**

**Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作**。

**37、Redis集群之间是如何复制的？**

异步复制

**38、Redis集群最大节点个数是多少？**

16384个

**39、Redis集群如何选择数据库？**

Redis集群目前无法做数据库选择，默认在0数据库。



**分区**







**40、Redis是单线程的，如何提高多核CPU的利用率？**

可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。

**41、为什么要做Redis分区？**

分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升，Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。

**42、你知道有哪些Redis分区实现方案？**

- 客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。
- 代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy
- 查询路由(Query routing) 的意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。

**43、Redis分区有什么缺点？**

- 涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。
- 同时操作多个key,则不能使用Redis事务.
- 分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set）
- 当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB / AOF文件。
- 分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。



**分布式问题**



**44、Redis实现分布式锁**

Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系Redis中可以使用SETNX命令实现分布式锁。

当且仅当 key 不存在，将 key 的值设为 value。若给定的 key 已经存在，则 SETNX 不做任何动作。

SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。

返回值：设置成功，返回 1 。设置失败，返回 0 。



![img](https://pic1.zhimg.com/80/v2-ed69af92e635c34678bcc040a4d61bb4_720w.jpg)



**使用SETNX完成同步锁的流程及事项如下：**

使用SETNX命令获取锁，若返回0（key已存在，锁已存在）则获取失败，反之获取成功。

为了防止获取锁后程序出现异常，导致其他线程/进程调用SETNX命令总是返回0而进入死锁状态，需要为该key设置一个“合理”的过期时间。

释放锁，使用DEL命令将锁数据删除。

**45、如何解决 Redis 的并发竞争 Key 问题**

所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！

**推荐一种方案：分布式锁**（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能）

基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。

在实践中，当然是从以可靠性为主。所以首推Zookeeper。

参考：[https://www.jianshu.com/p/8bddd381de06](https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/8bddd381de06)

**46、分布式Redis是前期做还是后期规模上来了再做好？为什么？**

既然Redis是如此的轻量（单实例只使用1M内存），为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。

一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。

这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。

**47、什么是 RedLock**

Redis 官方站提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。它可以保证以下特性：

- **安全特性：**互斥访问，即永远只有一个 client 能拿到锁
- **避免死锁**：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区
- **容错性**：只要大部分 Redis 节点存活就可以正常提供服务



**缓存异常**

**48、缓存雪崩**

缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

**解决方案：**

- 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
- 一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。
- 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。

**49、缓存穿透**

缓存穿透是指**缓存和数据库中都没有的数据，导致所有的请求都落到数据库上**，造成数据库短时间内承受大量请求而崩掉。

**解决方案：**

- 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
- 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
- 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力

**附加：**

对于空间的利用到达了一种极致，那就是Bitmap和布隆过滤器(Bloom Filter)。

**Bitmap：**典型的就是哈希表

缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。

**布隆过滤器（推荐）**

就是引入了k(k>1)k(k>1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。

它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。

Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。

Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。

Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。

**50、缓存击穿**

**缓存击穿**是**指缓存中没有但数据库中有的数据**（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

**解决方案**

- 设置热点数据永远不过期。
- 加互斥锁，互斥锁

**51、缓存预热**

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

**解决方案：**

- 直接写个缓存刷新页面，上线时手工操作一下；
- 数据量不大，可以在项目启动的时候自动进行加载；
- 定时刷新缓存；

**52、缓存降级**

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。、

**缓存降级**的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：

- 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
- **警告**：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
- **错误**：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；
- **严重错误：**比如因为特殊原因数据错误了，此时需要紧急人工降级。

服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。



**53、热点数据和冷数据**

热点数据，缓存才有价值。

对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存

对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。

数据更新前至少读取两次，缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。

那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。

**54、缓存热点key**

缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

**解决方案：**

对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询



**常用工具**



**55、Redis支持的Java客户端都有哪些？官方推荐用哪个？**

Redisson、Jedis、lettuce等等，官方推荐使用Redisson。

**56、Redis和Redisson有什么关系？**

Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。

**57、Jedis与Redisson对比有什么优缺点？**

Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。



![img](https://pic3.zhimg.com/80/v2-0d74f2ef875b180e45c704e84787266a_720w.jpg)



**其他问题**

**58、Redis与Memcached的区别**

两者都是非关系型内存键值数据库，现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！Redis 与 Memcached 主要有以下不同：



![img](https://pic1.zhimg.com/80/v2-71fb74340ec8d10b8eaaf1403925b07c_720w.jpg)



(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型

(2) redis的速度比memcached快很多

(3) redis可以持久化其数据

**59、如何保证缓存与数据库双写时的数据一致性？**

你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？

一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况

串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。

还有一种方式就是可能会暂时产生不一致的情况，但是发生的几率特别小，就是先更新数据库，然后再删除缓存。



![img](https://pic1.zhimg.com/80/v2-e63ec66463a16147a3ecaa25dd70ac60_720w.jpg)



**60、Redis常见性能问题和解决方案？**

1 Master最好不要做任何持久化工作**，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。

2 如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。

3 为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。

4 尽量避免在压力较大的主库上增加从库

Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。

为了Master的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关系为：Master<–Slave1<–Slave2<–Slave3…，这样的结构也方便解决单点故障问题，实现Slave对Master的替换，也即，如果Master挂了，可以立马启用Slave1做Master，其他不变。

**61、Redis官方为什么不提供Windows版本？**

因为目前Linux版本已经相当稳定，而且用户量很大，无需开发windows版本，反而会带来兼容性等问题。

**62、一个字符串类型的值能存储最大容量是多少？**

512M

**63、Redis如何做大量数据插入？**

Redis2.6开始**redis-cli支持一种新的被称之为pipe mode的新模式用于执行大量数据插入工作**。

**64、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？**

使用keys指令可以扫出指定模式的key列表。

对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？

这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。**这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长**。

**65、使用Redis做过异步队列吗，是如何实现的？**

使用list类型保存数据信息，rpush生产消息，lpop消费消息，当lpop没有消息时，可以sleep一段时间，然后再检查有没有信息，如果不想sleep的话，可以使用blpop, 在没有信息的时候，会一直阻塞，直到信息的到来。redis可以通过pub/sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。

**66、Redis如何实现延时队列？**

使用sortedset，使用时间戳做score, 消息内容作为key,调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理。

**67、Redis回收进程如何工作的？**

- 一个客户端运行了新的命令，添加了新的数据。
- Redis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收。
- 一个新的命令被执行，等等。
- 所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。

如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。

**68、Redis回收使用的是什么算法？**

LRU算法。



## 29 最经典的KV+DB读写模式么？

- 最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。
- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，先更新数据库，然后再删除缓存。



#  30 set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令

#  31 **使用过Redis做异步队列么，你是怎么用的？**

一般使用list结构作为队列，`rpush`生产消息，`lpop`消费消息。当lpop没有消息的时候，要适当sleep一会再重试。

### **可不可以不用sleep呢？**

list还有个指令叫`blpop`，在没有消息的时候，它会阻塞住直到消息到来。

### **如果对方接着追问能不能生产一次消费多次呢？**

使用pub/sub主题订阅者模式，可以实现 1:N 的消息队列。

### **如果对方继续追问 pub/su b有什么缺点？**

在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如`RocketMQ`等。

### **Redis如何实现延时队列？**

这一套连招下来，我估计现在你很想把面试官一棒打死（`面试官自己都想打死自己了怎么问了这么多自己都不知道的`），如果你手上有一根棒球棍的话，但是你很克制。平复一下激动的内心，然后神态自若的回答道：使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用`zrangebyscore`指令获取N秒之前的数据轮询进行处理

# 32 Pipeline有什么好处，为什么要用pipeline？

可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。

### 33 为什么是删除缓存，而不是更新缓存？

原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。

比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。

另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于**比较复杂的缓存数据计算的场景**，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，**这个缓存到底会不会被频繁访问到？**

举个栗子：一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有**大量的冷数据**。

实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。**用到缓存才去算缓存。**

其实删除缓存，而不是更新缓存，就是一个 Lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。

像 **Mybatis**，**Hibernate**，都有懒加载思想。查询一个部门，部门带了一个员工的 **List**，没有必要说每次查询部门，都里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。



### 34 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？**

使用`keys`指令可以扫出指定模式的key列表。这个时候可以使用`scan`指令，`scan`指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。

```
不过，增量式迭代命令也不是没有缺点的： 举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 。
```

### 35 数据传输的时候断网了或者服务器挂了怎么办啊？

传输过程中有什么网络问题啥的，会自动重连的，并且连接之后会把缺少的数据补上的。



### 36 为啥不扫描全部设置了过期时间的key呢？

假如Redis里面所有的key都有过期时间，都扫描一遍？那太恐怖了，而且我们线上基本上也都是会设置一定的过期时间的。全扫描跟你去查数据库不带where条件不走索引全表扫描一样，100s一次，Redis累都累死了。

### 37 如果一直没随机到很多key，里面不就存在大量的无效key了？

好问题，**惰性删除**，见名知意，惰性嘛，我不主动删，我懒，我等你来查询了我看看你过期没，过期就删了还不给你返回，没过期该怎么样就怎么样。

### 38 最后就是如果的如果，定期没删，我也没查询，那可咋整？

**内存淘汰机制**！

官网上给到的内存淘汰机制是以下几个：

- **noeviction**:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）
- **allkeys-lru**: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
- **volatile-lru**: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
- **allkeys-random**: 回收随机的键使得新添加的数据有空间存放。
- **volatile-random**: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
- **volatile-ttl**: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。

如果没有键满足回收的前提条件的话，策略**volatile-lru**, **volatile-random**以及**volatile-ttl**就和noeviction 差不多了。



# 39 Redis sharding



# 40 AOF文件过大

执行**BGREWRITEAOF**命令对redis的AOF进行重写

(1) 随着AOF文件越来越大，里面会有大部分是重复命令或者可以合并的命令（100次incr = set key 100）
(2) 重写的好处：减少AOF日志尺寸，减少内存占用，加快数据库恢复时间。

执行一个 AOF文件重写操作，重写会创建一个当前 AOF 文件的体积优化版本。
即使 BGREWRITEAOF 执行失败，也不会有任何数据丢失，因为旧的 AOF 文件在 BGREWRITEAOF 成功之前不会被修改。
从 Redis 2.4 开始，AOF 重写由 Redis 自行触发， BGREWRITEAOF 仅仅用于手动触发重写操作。但网上有网友说已经3.2.5版本了，貌似redis还是没有自动触发BGREWRITEAOF
稳妥的方法还写一个**脚本每天定时去执**



